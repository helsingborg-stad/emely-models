{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from parlai.core.agents import create_agent\n",
    "from parlai.agents.emely.emely import EmelyAgent\n",
    "from parlai.core.opt import Opt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from parlai.scripts.torchscript import export_emely\n",
    "from parlai.core.agents import create_agent\n",
    "\n",
    "# Initialize model settings\n",
    "\n",
    "model_path = Path.cwd() / 'data/models/blender/blender_90M/'\n",
    "assert model_path.is_dir()\n",
    "\n",
    "opt_path = model_path / 'model.opt'\n",
    "opt = Opt.load(opt_path)\n",
    "\n",
    "# Change opts\n",
    "opt['skip_generation'] = False\n",
    "opt['init_model'] = (model_path / 'model').as_posix()\n",
    "opt['no_cuda'] = True  # Cloud run doesn't offer gpu support\n",
    "\n",
    "# Inference options\n",
    "opt['inference'] = 'greedy' # 'beam'\n",
    "opt['beam_size'] = 1\n",
    "\n",
    "opt[\"scripted-model-file\"] = \"emely_scripted_test.pt\"\n",
    "opt[\"script-module\"] = \"parlai.torchscript.modules:TorchScriptGreedySearch\"\n",
    "opt[\"model_file\"] = opt[\"init_model\"]\n",
    "\n",
    "opt[\"temp_separator\"] = \"__space__\"\n",
    "\n",
    "opt[\"bpe_add_prefix_space\"] = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Test exporting to torchscript\n",
    "export_emely(opt)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "22:55:56 | loading dictionary from /home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model.dict\n",
      "22:55:56 | num words = 54944\n",
      "22:55:56 | \u001b[33mDEPRECATED: XLM should only be used for backwards compatibility, as it involves a less-stable layernorm operation.\u001b[0m\n",
      "22:55:57 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
      "22:55:57 | Loading existing model params from /home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ckjellson/code/emely-models/ParlAI/parlai/agents/transformer/modules/encoder.py:183: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if positions.max().item() > self.n_positions:\n",
      "/home/ckjellson/code/emely-models/ParlAI/parlai/agents/transformer/modules/attention.py:147: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert (\n",
      "/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/home/ckjellson/code/emely-models/ParlAI/parlai/agents/transformer/modules/attention.py:153: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  scale = math.sqrt(dim_per_head)\n",
      "/home/ckjellson/code/emely-models/ParlAI/parlai/agents/transformer/modules/attention.py:235: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert attn_mask.shape == dot_prod.shape\n",
      "/home/ckjellson/code/emely-models/ParlAI/parlai/agents/transformer/modules/decoder.py:145: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if positions.max().item() > self.n_positions:\n",
      "/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/jit/_trace.py:154: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
      "  if a.grad is not None:\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 3])\n",
      "2\n",
      "{'0__self_attn__prev_key': tensor([[[[ 1.7526, -0.5386, -1.2811,  ..., -1.9779, -1.0670,  0.1217],\n",
      "          [ 0.9178, -1.5451,  1.6102,  ..., -1.7043,  1.3127,  0.0156]],\n",
      "\n",
      "         [[ 0.2943,  2.2358,  3.5683,  ..., -3.8988,  0.5640,  1.3951],\n",
      "          [ 0.7878, -0.2087,  1.0752,  ..., -0.7248, -3.9533, -1.2152]],\n",
      "\n",
      "         [[ 0.0442,  0.0730,  0.2132,  ..., -0.1067, -1.1602,  0.5259],\n",
      "          [-0.1513,  0.5204, -0.8468,  ..., -0.7351, -0.4042, -1.2901]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2849,  0.3234, -1.1044,  ...,  0.6337,  2.4490, -0.5633],\n",
      "          [-1.4803,  0.4747, -3.3109,  ...,  0.9261,  0.5223,  1.6246]],\n",
      "\n",
      "         [[ 0.7337, -0.6476,  1.1465,  ...,  2.0486, -0.6465,  1.4505],\n",
      "          [-0.0802, -1.5693,  1.0851,  ..., -0.1458, -0.6731, -0.1392]],\n",
      "\n",
      "         [[ 1.1624, -0.3463,  0.1366,  ...,  0.7243,  0.9684, -1.8976],\n",
      "          [-1.4605, -0.4311, -0.1438,  ..., -1.7887,  1.4845,  0.3190]]]],\n",
      "       grad_fn=<IndexSelectBackward>), '0__self_attn__prev_value': tensor([[[[ 1.9135e-01, -2.5176e-01, -4.6295e-02,  ..., -6.3144e-03,\n",
      "           -6.8301e-01, -3.1439e-01],\n",
      "          [-1.0447e-01,  1.2376e-01,  7.5637e-02,  ...,  6.8314e-02,\n",
      "            3.7118e-02,  1.7913e-01]],\n",
      "\n",
      "         [[-1.8473e-01,  4.8833e-01, -3.4016e-01,  ...,  1.1059e-01,\n",
      "           -3.6179e-01, -5.1748e-02],\n",
      "          [-2.0425e-01, -7.3176e-02,  2.0373e-01,  ...,  2.9350e-02,\n",
      "           -3.8665e-01, -4.3043e-01]],\n",
      "\n",
      "         [[-2.1259e-01, -1.5415e-01, -1.0497e-01,  ...,  1.0382e-01,\n",
      "            1.9453e-01,  6.7920e-01],\n",
      "          [ 7.3554e-02, -3.4717e-02,  8.9191e-03,  ...,  1.6172e-01,\n",
      "            1.3484e-01, -9.8500e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.7422e-04,  6.8497e-01, -3.7018e-01,  ..., -9.7661e-01,\n",
      "            2.8539e-01,  2.2982e-01],\n",
      "          [-7.9067e-02,  5.6666e-02,  1.9172e-03,  ...,  7.8201e-02,\n",
      "           -1.4816e-01, -1.0554e-01]],\n",
      "\n",
      "         [[ 2.9474e-01, -2.6476e-01,  4.8336e-02,  ..., -3.6805e-01,\n",
      "            1.2889e-01,  6.4779e-01],\n",
      "          [ 1.5471e-01,  1.5689e-01,  8.7795e-02,  ..., -1.6735e-02,\n",
      "           -4.6890e-02,  1.8368e-01]],\n",
      "\n",
      "         [[ 5.1380e-01,  4.0577e-01, -5.0755e-01,  ..., -4.9407e-01,\n",
      "           -2.8050e-01, -3.5395e-01],\n",
      "          [-1.9061e-01, -9.6528e-02, -1.7030e-01,  ...,  3.8947e-01,\n",
      "            1.3380e-01,  1.1055e-01]]]], grad_fn=<IndexSelectBackward>), '0__self_attn__prev_mask': tensor([[[1., 0.],\n",
      "         [1., 1.]]]), '0__encoder_attn__prev_key': tensor([[[[ 5.2344e-01, -1.2170e+00, -3.7026e-01,  ..., -7.6545e-01,\n",
      "            5.9302e-01, -4.4645e-01],\n",
      "          [ 1.1479e-01, -2.3279e+00, -8.1763e-01,  ..., -4.7775e-01,\n",
      "            2.0953e-01, -1.0098e+00],\n",
      "          [ 2.7013e+00, -2.8983e+00,  1.2703e-01,  ..., -5.9575e-01,\n",
      "           -4.6163e-01, -7.8788e-01],\n",
      "          [ 8.2728e-03,  3.5391e-01, -3.2203e-02,  ...,  2.9151e-02,\n",
      "           -1.0020e-02,  1.1096e-02],\n",
      "          [-3.7554e-01, -4.1045e+00, -1.4241e-01,  ..., -1.5451e+00,\n",
      "            6.8900e-01, -1.2833e+00]],\n",
      "\n",
      "         [[-1.3185e+00, -1.9990e+00,  3.0153e-01,  ..., -3.7882e-01,\n",
      "            3.4367e+00, -1.1839e-01],\n",
      "          [-3.8001e-01, -3.7130e-01, -9.6930e-01,  ..., -5.6592e-01,\n",
      "            6.7716e-01, -7.4140e-01],\n",
      "          [-1.0140e+00, -9.4788e-01, -1.0125e+00,  ...,  6.5820e-01,\n",
      "            2.4181e+00, -1.3182e+00],\n",
      "          [-7.6440e-03,  1.1089e-01, -1.1275e-03,  ...,  2.8423e-02,\n",
      "           -1.0246e-01, -5.8541e-02],\n",
      "          [ 1.5657e-01, -1.5928e+00, -4.3026e+00,  ...,  2.1039e+00,\n",
      "           -1.0503e+00,  8.5089e-01]],\n",
      "\n",
      "         [[-9.9241e-01,  1.5492e+00, -1.5696e+00,  ..., -1.7011e+00,\n",
      "            1.8208e+00, -1.2873e+00],\n",
      "          [ 1.4966e+00,  7.4821e-01,  1.0978e+00,  ..., -2.7588e-01,\n",
      "           -7.4292e-02, -1.9301e-01],\n",
      "          [-1.6401e+00,  1.9479e+00, -3.0527e-02,  ..., -3.6031e+00,\n",
      "            3.8193e+00, -1.0441e+00],\n",
      "          [ 3.5576e-02, -2.3348e-01,  2.0689e-02,  ...,  9.6545e-02,\n",
      "           -1.1149e-01,  5.8996e-02],\n",
      "          [ 7.9325e-01,  1.5845e+00, -1.6492e+00,  ..., -4.5979e+00,\n",
      "            2.4238e+00, -1.1050e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2489e+00,  6.9877e-01,  1.5036e+00,  ..., -1.8929e-01,\n",
      "           -5.8739e-01,  1.2852e-01],\n",
      "          [ 3.3071e+00, -9.3366e-02,  2.8161e+00,  ...,  1.7207e+00,\n",
      "            8.5982e-01, -1.0196e+00],\n",
      "          [ 4.8261e+00, -7.0484e-01, -1.0824e+00,  ..., -4.5966e-01,\n",
      "            8.9705e-01, -5.1684e-01],\n",
      "          [-5.9292e-01, -1.0783e-02,  5.1643e-03,  ...,  2.5915e-02,\n",
      "            7.8029e-02, -1.6087e-02],\n",
      "          [ 5.4746e+00,  1.6284e+00,  6.9436e-01,  ...,  6.4550e-01,\n",
      "            1.5445e+00,  1.3159e+00]],\n",
      "\n",
      "         [[-1.2732e+00, -3.5589e-01, -2.6800e-01,  ..., -5.2445e-01,\n",
      "            3.6067e-01,  1.1739e-01],\n",
      "          [ 1.1186e+00, -1.1472e+00, -6.0278e-01,  ...,  9.5576e-01,\n",
      "           -9.1164e-02,  9.9381e-01],\n",
      "          [-2.6975e-01, -2.1773e-01,  1.3058e+00,  ..., -1.5389e-01,\n",
      "            1.4003e+00,  1.7182e-01],\n",
      "          [ 2.3083e-02, -3.7455e-02, -1.5573e-01,  ..., -2.3038e-02,\n",
      "           -1.8644e-02,  4.0501e-04],\n",
      "          [-2.4021e-01,  4.3232e-01,  1.9628e+00,  ...,  1.2119e+00,\n",
      "            2.5966e+00, -6.1073e-01]],\n",
      "\n",
      "         [[-1.5185e+00,  6.3031e-02, -1.0224e+00,  ...,  1.6824e-01,\n",
      "           -1.1541e-01, -2.1526e-01],\n",
      "          [-1.7760e-01, -1.0968e-01, -9.3040e-01,  ..., -1.1900e+00,\n",
      "            1.0690e+00, -7.7360e-01],\n",
      "          [-2.8027e-01, -1.2091e-01,  1.0270e+00,  ...,  8.3954e-01,\n",
      "            5.9451e-01, -1.1554e+00],\n",
      "          [-7.9846e-03, -2.6679e-02,  6.7770e-03,  ...,  2.5072e-02,\n",
      "           -3.5726e-02, -1.5167e-03],\n",
      "          [-7.5462e-01,  1.1669e-01,  4.7334e-01,  ...,  4.0248e-01,\n",
      "            4.4986e-01, -1.1515e+00]]]], grad_fn=<IndexSelectBackward>), '0__encoder_attn__prev_value': tensor([[[[-2.6066e-01,  1.0679e+00, -2.8640e-01,  ...,  1.6933e-01,\n",
      "           -4.6028e-01,  2.6488e-01],\n",
      "          [ 4.6155e-01,  7.3781e-01, -5.0476e-01,  ..., -7.3891e-01,\n",
      "            4.8089e-01,  7.8012e-01],\n",
      "          [ 1.4732e+00,  1.4835e-01,  3.9307e-01,  ..., -5.8488e-01,\n",
      "           -3.7931e-01,  1.4511e-01],\n",
      "          [-1.2433e-02,  5.1292e-02, -9.3232e-03,  ...,  7.4038e-03,\n",
      "            2.3736e-02, -6.1797e-02],\n",
      "          [-1.9615e-01,  2.4175e-01, -9.2048e-01,  ..., -2.1376e-01,\n",
      "           -1.5312e+00,  1.5574e-01]],\n",
      "\n",
      "         [[-5.3178e-03, -2.9400e-01, -1.6359e+00,  ..., -5.1965e-01,\n",
      "           -8.7764e-01,  2.3663e-01],\n",
      "          [ 2.8944e-02, -4.4645e-03, -6.5902e-01,  ...,  8.4936e-02,\n",
      "            7.7891e-02,  4.0014e-02],\n",
      "          [-9.5302e-01,  1.4072e-01, -1.0696e+00,  ..., -3.2464e-01,\n",
      "            3.4622e-01, -1.3787e-01],\n",
      "          [ 1.6472e-02, -6.2992e-03,  2.4759e-01,  ..., -2.0481e-02,\n",
      "            1.5631e-03, -6.6844e-03],\n",
      "          [-8.5959e-02,  1.5231e-01, -6.6984e-01,  ...,  3.8693e-02,\n",
      "            4.7036e-01,  8.5929e-01]],\n",
      "\n",
      "         [[-4.3703e-01,  4.6663e-01,  2.9427e-01,  ...,  6.3694e-01,\n",
      "            1.4490e-01, -5.3542e-01],\n",
      "          [-2.0555e-02,  6.8233e-01, -6.2732e-02,  ..., -3.8672e-01,\n",
      "            4.3345e-01, -3.2074e-02],\n",
      "          [ 3.2867e-01, -5.4326e-01,  5.6032e-01,  ..., -2.0808e-01,\n",
      "            1.0457e-01, -9.8620e-02],\n",
      "          [-1.3684e-02, -3.2979e-02,  7.9593e-03,  ...,  1.8314e-02,\n",
      "           -3.1618e-02,  8.9299e-03],\n",
      "          [ 6.0901e-01,  4.4431e-01,  2.7227e-02,  ..., -5.2118e-01,\n",
      "            4.4903e-01,  3.1664e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2665e-01,  4.8030e-01,  9.8349e-01,  ...,  6.6671e-01,\n",
      "           -1.1320e+00, -7.7774e-01],\n",
      "          [-2.4978e-02,  2.6419e-01,  8.6702e-01,  ...,  2.1016e-01,\n",
      "           -3.5524e-01,  5.6432e-02],\n",
      "          [-2.6411e-01,  2.6192e-01,  5.4974e-01,  ...,  5.7913e-01,\n",
      "           -1.0563e+00, -3.6506e-01],\n",
      "          [-3.4755e-03,  8.0147e-03, -2.6137e-01,  ..., -3.5765e-02,\n",
      "            3.0546e-02,  8.1987e-02],\n",
      "          [ 2.2293e-01,  1.2241e+00,  7.3235e-01,  ..., -3.5277e-01,\n",
      "            2.9191e-01,  3.3980e-01]],\n",
      "\n",
      "         [[ 2.7593e-01, -2.7471e-01,  1.8712e-01,  ...,  5.0845e-01,\n",
      "           -1.3159e-01, -6.3004e-02],\n",
      "          [-2.4769e-01, -1.0768e+00, -6.5151e-01,  ...,  3.7073e-01,\n",
      "            3.9204e-01, -3.5133e-01],\n",
      "          [ 3.5606e-01, -5.6084e-01, -6.9108e-01,  ...,  3.1831e-01,\n",
      "           -3.2084e-02,  2.2677e-01],\n",
      "          [ 6.1841e-03,  2.2556e-03,  1.3206e-02,  ...,  3.4197e-02,\n",
      "           -1.1297e-02,  2.3854e-02],\n",
      "          [-2.3787e-01, -6.7500e-01, -1.0355e+00,  ...,  9.3746e-02,\n",
      "            8.2120e-01,  1.1296e-02]],\n",
      "\n",
      "         [[ 4.1229e-01, -1.2665e+00,  2.8479e-01,  ...,  1.5306e-01,\n",
      "           -4.9863e-01, -7.4263e-01],\n",
      "          [-4.2359e-01,  8.6109e-02,  2.1367e-01,  ..., -3.9907e-01,\n",
      "            5.4348e-01,  2.2747e-01],\n",
      "          [ 1.6685e-01, -1.5320e-01, -5.6518e-02,  ..., -6.0372e-02,\n",
      "           -2.9475e-01, -1.3126e+00],\n",
      "          [ 8.4989e-03,  8.4617e-02, -1.9158e-01,  ..., -1.8510e-04,\n",
      "            4.9798e-02,  7.6488e-03],\n",
      "          [-5.8688e-01, -3.1330e-01,  5.5957e-02,  ...,  1.4797e+00,\n",
      "           -1.6761e-01, -1.2029e+00]]]], grad_fn=<IndexSelectBackward>), '0__encoder_attn__prev_mask': tensor([[True, True, True, True, True]]), '1__self_attn__prev_key': tensor([[[[-2.9902e+00, -5.1171e-01, -5.3132e-01,  ..., -3.8403e-01,\n",
      "            8.9103e-01, -2.4771e-01],\n",
      "          [-4.7741e+00, -7.4801e-02, -2.0444e+00,  ..., -3.5912e-01,\n",
      "            6.7635e-01,  2.3647e-01]],\n",
      "\n",
      "         [[-7.2400e-01,  9.4889e-01,  9.2057e-01,  ..., -5.8328e-02,\n",
      "           -4.6391e-01,  4.7458e-01],\n",
      "          [-7.9421e-01, -2.6067e-01,  2.0031e+00,  ...,  5.5308e-01,\n",
      "            6.3352e-02,  6.4367e-02]],\n",
      "\n",
      "         [[-1.2341e-01,  1.1965e+00,  1.2074e+00,  ...,  1.0756e+00,\n",
      "            8.1843e-01,  6.0107e-02],\n",
      "          [-1.6448e-01,  7.4120e-01, -5.2562e-01,  ...,  1.2053e-01,\n",
      "            4.4415e-01, -8.0563e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4574e-01, -8.9542e-02, -1.7649e-01,  ..., -1.7154e+00,\n",
      "            1.2339e-01,  1.8041e-01],\n",
      "          [-4.8845e-01,  5.7557e-02, -4.3199e-01,  ..., -2.7646e+00,\n",
      "           -1.6524e-03,  2.5647e-02]],\n",
      "\n",
      "         [[-1.0387e-01,  1.8205e-01, -1.4052e-01,  ..., -1.2451e+00,\n",
      "            1.5836e-01, -1.1322e+00],\n",
      "          [ 3.6767e-01,  5.4675e-02, -1.4057e+00,  ..., -4.4460e-01,\n",
      "           -5.6149e-02, -4.6148e-01]],\n",
      "\n",
      "         [[-3.4065e-01, -4.4567e-01, -1.0324e-01,  ...,  2.1321e-01,\n",
      "            5.4736e-01, -7.3200e-01],\n",
      "          [-1.4603e-01, -5.4254e-01, -3.0231e-01,  ..., -1.0937e-01,\n",
      "            1.3388e-01, -4.7856e-01]]]], grad_fn=<IndexSelectBackward>), '1__self_attn__prev_value': tensor([[[[-0.1101, -0.4407,  0.7101,  ..., -0.2423, -0.0829,  0.1728],\n",
      "          [-0.4506,  0.2908,  0.6079,  ...,  0.0460, -0.2841,  0.2358]],\n",
      "\n",
      "         [[-0.7629, -0.0219, -0.1129,  ..., -0.6764,  0.4992,  0.1216],\n",
      "          [-0.3899,  0.1976,  0.4236,  ..., -0.2992,  0.4973,  0.4241]],\n",
      "\n",
      "         [[-0.6443,  0.6337,  0.2621,  ...,  0.6517, -0.7044,  0.4678],\n",
      "          [-2.3324,  0.4181,  0.2714,  ...,  1.6591,  1.0857,  1.3032]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5137,  0.5874,  0.9602,  ...,  0.1092,  2.1641,  1.2215],\n",
      "          [ 0.0931, -0.0237,  1.3962,  ...,  0.0401,  0.6073,  0.3456]],\n",
      "\n",
      "         [[-0.1286,  0.0955,  0.4379,  ...,  0.0447,  0.9345,  0.0908],\n",
      "          [-1.0151, -0.4468,  0.0709,  ..., -0.0687,  0.8493, -0.5133]],\n",
      "\n",
      "         [[-0.5752,  0.5425, -0.6980,  ...,  0.7403, -0.4300, -1.0902],\n",
      "          [ 0.0141,  1.0998, -0.0699,  ...,  0.2857, -1.0269, -0.5886]]]],\n",
      "       grad_fn=<IndexSelectBackward>), '1__self_attn__prev_mask': tensor([[[1., 0.],\n",
      "         [1., 1.]]]), '1__encoder_attn__prev_key': tensor([[[[-2.4648,  3.5460, -0.5742,  ...,  1.4596, -3.9191, -2.0623],\n",
      "          [-1.1763,  1.3706, -0.8448,  ...,  0.5074, -0.5204, -1.1507],\n",
      "          [-1.4700, -0.8758,  1.4780,  ...,  1.8739,  2.4753, -0.4600],\n",
      "          [ 0.0618, -0.0205,  0.1058,  ..., -0.0405,  0.0605,  0.1800],\n",
      "          [-2.3145, -1.5730,  1.7139,  ...,  3.2272, -1.9182,  0.5154]],\n",
      "\n",
      "         [[-0.4479,  1.7756, -0.6839,  ...,  1.8893, -0.9408, -0.2974],\n",
      "          [ 0.5018,  1.8079, -0.1483,  ...,  1.7212, -0.4911, -1.0489],\n",
      "          [-0.2519,  3.4057, -0.3335,  ...,  1.1294, -1.2796, -1.6166],\n",
      "          [-0.0115, -0.4942, -0.0177,  ..., -0.2752, -0.0394, -0.0071],\n",
      "          [ 0.0238,  1.6573, -0.4262,  ...,  2.0928, -2.0088, -1.7235]],\n",
      "\n",
      "         [[ 2.5459, -0.2507,  0.3444,  ...,  0.0348,  1.6721, -0.2662],\n",
      "          [ 0.2746,  0.6710,  0.6040,  ...,  1.7471,  0.9956, -0.1528],\n",
      "          [ 2.3577,  2.5666,  0.4349,  ...,  0.7507,  2.5976,  0.8000],\n",
      "          [-0.0046,  0.0050, -0.0228,  ...,  0.0066, -0.0605, -0.0171],\n",
      "          [ 2.0299,  0.0233,  0.2004,  ..., -0.6758,  2.7522, -0.2645]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9505, -0.8805, -2.1274,  ..., -2.5338,  0.2303, -0.2119],\n",
      "          [ 0.5860, -1.8293, -0.1756,  ...,  1.6795,  0.1912, -0.5063],\n",
      "          [ 1.5499,  0.2796,  0.5668,  ...,  0.4490,  0.6280,  0.3055],\n",
      "          [-0.0201, -0.0436,  0.0041,  ..., -0.0264, -0.0315, -0.0535],\n",
      "          [ 2.0886, -0.2959, -0.0274,  ..., -0.8787, -0.1716, -1.1574]],\n",
      "\n",
      "         [[-0.2102, -1.2078, -0.8543,  ...,  1.0996, -1.6171,  0.8156],\n",
      "          [-1.0466, -1.8397, -1.4281,  ...,  0.6042, -0.5230,  0.4671],\n",
      "          [-1.3704, -2.5197,  1.5644,  ...,  1.2009, -0.9723,  0.3606],\n",
      "          [ 0.0339,  0.2527,  0.0128,  ..., -0.0143,  0.0200, -0.0363],\n",
      "          [-2.5554, -1.6327, -1.9201,  ...,  1.4775, -0.4775,  1.3397]],\n",
      "\n",
      "         [[-3.6513, -2.3586,  2.1979,  ..., -0.5697,  0.3527, -0.2875],\n",
      "          [-2.6930, -2.4637,  2.2931,  ..., -1.1616,  1.1528, -0.0821],\n",
      "          [-2.9697, -3.3908,  1.8356,  ...,  0.4178, -0.1730,  0.3107],\n",
      "          [ 0.3702,  0.2583, -0.4443,  ...,  0.1064,  0.0131, -0.0132],\n",
      "          [-2.3822, -2.9616,  3.0743,  ..., -0.6391,  0.8507,  1.3335]]]],\n",
      "       grad_fn=<IndexSelectBackward>), '1__encoder_attn__prev_value': tensor([[[[-4.2693e-01,  6.0001e-01, -1.1332e-01,  ..., -6.2515e-01,\n",
      "           -8.0868e-01,  4.7094e-01],\n",
      "          [-1.9338e-01,  6.2120e-01, -4.4672e-01,  ..., -5.4518e-01,\n",
      "            4.3915e-01,  5.5813e-01],\n",
      "          [-1.2430e-01,  1.0119e+00, -1.2265e-01,  ..., -1.8240e-01,\n",
      "           -2.0642e-02,  7.2360e-01],\n",
      "          [-6.5049e-03, -8.1248e-03,  6.5220e-03,  ..., -4.8128e-02,\n",
      "           -2.6849e-02, -2.9678e-03],\n",
      "          [-5.1223e-01, -2.8861e-02, -1.3440e-01,  ...,  1.1585e-02,\n",
      "            1.0938e-01,  1.6382e+00]],\n",
      "\n",
      "         [[-1.0265e+00,  4.0621e-01,  3.0912e-01,  ...,  3.1867e-01,\n",
      "           -7.2264e-02, -4.5579e-01],\n",
      "          [-9.5004e-01, -3.9620e-01,  6.5318e-01,  ..., -1.2419e+00,\n",
      "            2.6028e-01,  1.9033e-02],\n",
      "          [-9.4182e-01,  4.7712e-01,  7.5050e-01,  ..., -2.4116e-02,\n",
      "            4.2125e-01,  5.5419e-01],\n",
      "          [ 9.2826e-02, -1.0871e-02,  1.9537e-03,  ...,  1.2230e-01,\n",
      "            3.2010e-03, -7.8329e-03],\n",
      "          [ 3.5341e-01,  5.8144e-01,  1.3602e+00,  ...,  4.8059e-01,\n",
      "            4.3524e-01, -5.8476e-01]],\n",
      "\n",
      "         [[-4.9750e-01, -5.9196e-01, -1.8149e-01,  ..., -3.1103e-01,\n",
      "           -2.2429e-01, -3.6122e-01],\n",
      "          [-1.6046e-01, -8.2386e-01,  3.6475e-01,  ..., -3.4559e-01,\n",
      "            5.6201e-01, -7.5835e-01],\n",
      "          [-4.5815e-01,  1.8061e-01,  5.3184e-01,  ..., -1.2938e-01,\n",
      "            2.6092e-01, -4.3476e-01],\n",
      "          [-6.4345e-03,  9.2210e-02,  1.0445e-02,  ...,  2.9290e-03,\n",
      "           -1.7298e-02,  1.7990e-02],\n",
      "          [-8.1921e-01, -9.9905e-02,  7.5928e-01,  ...,  6.6084e-01,\n",
      "            4.3825e-01, -3.6886e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.7057e-01,  7.2631e-02, -1.3176e-02,  ..., -1.6355e-01,\n",
      "            1.0829e-01,  1.2332e+00],\n",
      "          [-2.1702e-01, -8.9072e-01,  3.5509e-01,  ...,  3.8722e-01,\n",
      "           -1.0433e+00,  1.1822e+00],\n",
      "          [ 3.4201e-01, -6.6771e-01,  3.7850e-01,  ...,  3.4363e-01,\n",
      "           -1.2856e-01,  6.9603e-01],\n",
      "          [ 1.4163e-02,  1.7726e-02, -1.7265e-02,  ...,  4.2581e-03,\n",
      "            2.8542e-04,  8.4318e-03],\n",
      "          [-7.7497e-01, -1.4100e-01, -3.6744e-01,  ...,  3.9676e-01,\n",
      "           -4.1863e-01,  2.4638e-01]],\n",
      "\n",
      "         [[ 1.5674e+00,  6.5890e-01,  1.0346e+00,  ...,  6.9255e-02,\n",
      "            2.7642e-01,  2.0249e+00],\n",
      "          [ 3.1130e-01,  2.9855e-01,  4.2679e-01,  ...,  8.1409e-01,\n",
      "            1.8571e-01,  7.1978e-01],\n",
      "          [-2.9361e-01,  2.1998e-01,  4.3326e-01,  ..., -1.2427e-01,\n",
      "            2.4747e-01,  8.4636e-01],\n",
      "          [-1.1959e-02,  1.4926e-02, -4.6262e-02,  ..., -1.0830e-02,\n",
      "           -1.7683e-02, -5.6850e-02],\n",
      "          [-1.9949e-01,  7.1487e-01,  8.4007e-01,  ...,  9.3431e-01,\n",
      "            3.2269e-01, -2.6989e-02]],\n",
      "\n",
      "         [[ 4.9492e-01, -1.1303e+00, -1.9184e-01,  ...,  8.1026e-01,\n",
      "            1.0976e+00, -1.3037e-01],\n",
      "          [-4.9720e-01, -1.3661e-02, -8.2944e-01,  ...,  6.8021e-01,\n",
      "            4.2550e-01,  7.3005e-02],\n",
      "          [ 3.4049e-02, -8.4050e-01,  7.2965e-01,  ...,  1.1394e+00,\n",
      "            5.4435e-01, -1.8457e-01],\n",
      "          [-1.1651e-02,  3.5044e-03,  3.9551e-02,  ..., -1.3387e-01,\n",
      "           -2.6887e-02,  1.2401e-02],\n",
      "          [-4.5363e-01, -4.9971e-01,  3.5998e-02,  ...,  1.1872e+00,\n",
      "           -2.4302e-01,  6.3465e-01]]]], grad_fn=<IndexSelectBackward>), '1__encoder_attn__prev_mask': tensor([[True, True, True, True, True]]), '2__self_attn__prev_key': tensor([[[[-3.3589e-01,  7.2552e-01,  4.3891e-02,  ..., -7.2240e-01,\n",
      "           -2.3110e+00, -1.1733e+00],\n",
      "          [-1.9643e-03,  4.2597e-01, -3.4506e-01,  ..., -1.1262e+00,\n",
      "           -2.0873e+00, -1.1864e+00]],\n",
      "\n",
      "         [[-1.2387e+00, -8.7869e-03,  1.3874e+00,  ...,  3.3512e-01,\n",
      "            6.4904e-01, -6.9090e-01],\n",
      "          [-1.1127e+00, -1.0566e+00,  1.7887e+00,  ...,  7.5993e-01,\n",
      "            3.7475e-01, -4.5085e-01]],\n",
      "\n",
      "         [[ 1.4529e-01,  5.0025e-01,  1.4961e+00,  ..., -2.8235e-01,\n",
      "           -3.6227e-01, -1.1207e+00],\n",
      "          [ 1.4782e+00,  1.4319e+00,  7.0442e-01,  ..., -3.2266e-01,\n",
      "           -9.6651e-01, -1.0610e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0286e+00, -1.3308e-02, -1.3500e+00,  ...,  1.6795e+00,\n",
      "           -1.6281e+00,  1.0007e+00],\n",
      "          [-9.2206e-01,  2.5695e+00, -2.1562e+00,  ...,  7.2231e-01,\n",
      "           -1.8987e+00, -9.8053e-01]],\n",
      "\n",
      "         [[-2.0833e+00,  2.3298e-01, -4.6143e-01,  ...,  4.1768e-01,\n",
      "           -2.4190e+00,  1.5730e-01],\n",
      "          [-1.3929e+00, -6.0399e-01, -1.1356e+00,  ...,  4.2338e-01,\n",
      "           -2.8250e+00, -2.9098e+00]],\n",
      "\n",
      "         [[-9.0489e-02, -2.1703e-02,  3.1108e-01,  ..., -7.0246e-01,\n",
      "           -7.4646e-01,  3.6220e-01],\n",
      "          [ 1.1243e-01,  3.1810e-01,  8.5363e-01,  ..., -3.3432e-02,\n",
      "           -2.0184e+00, -4.1625e-02]]]], grad_fn=<IndexSelectBackward>), '2__self_attn__prev_value': tensor([[[[ 0.7144, -0.5488, -0.7054,  ...,  0.1180,  0.2904,  0.3341],\n",
      "          [ 0.6816, -0.7769, -0.0039,  ...,  0.0781,  0.2306,  0.2895]],\n",
      "\n",
      "         [[ 0.0020, -0.7306, -0.0931,  ..., -0.6793,  0.6489,  1.0288],\n",
      "          [ 0.0652, -0.7159,  0.8255,  ..., -0.5429,  0.4178,  0.8523]],\n",
      "\n",
      "         [[ 0.3102, -0.1339, -0.2616,  ...,  0.5349, -0.3198, -0.5588],\n",
      "          [ 0.5906,  0.1412, -0.4305,  ...,  0.3935, -0.2647, -0.4816]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3362,  0.4024,  0.1350,  ..., -0.3109,  0.5260,  0.2954],\n",
      "          [-0.7520,  0.4411,  0.0414,  ..., -0.0069,  0.4290,  0.1395]],\n",
      "\n",
      "         [[ 1.3968,  0.1304,  0.2847,  ...,  0.2701, -0.2511, -0.5273],\n",
      "          [ 0.7915,  0.2061,  0.2770,  ...,  0.0182, -0.2474, -0.4643]],\n",
      "\n",
      "         [[-0.3292,  0.1559,  0.1399,  ...,  0.5483,  0.0130, -0.9590],\n",
      "          [-1.2641,  0.4349,  0.6386,  ...,  0.4843,  0.3409, -0.0477]]]],\n",
      "       grad_fn=<IndexSelectBackward>), '2__self_attn__prev_mask': tensor([[[1., 0.],\n",
      "         [1., 1.]]]), '2__encoder_attn__prev_key': tensor([[[[ 3.5936e-01, -8.6103e-01,  1.3289e+00,  ..., -7.3758e-02,\n",
      "           -2.8132e+00,  2.2372e+00],\n",
      "          [-7.9805e-01, -1.3132e+00, -1.8989e+00,  ...,  9.9855e-01,\n",
      "           -1.0146e+00,  5.5694e-01],\n",
      "          [ 8.5237e-01,  1.5680e+00, -4.5894e-01,  ..., -8.9923e-01,\n",
      "            2.0538e+00,  3.4530e+00],\n",
      "          [-6.6063e-03, -5.3463e-02,  2.0488e-01,  ..., -1.2176e-01,\n",
      "            1.3739e-01, -1.2659e-01],\n",
      "          [ 1.9728e+00, -3.5257e-01, -8.7112e-01,  ...,  7.4075e-01,\n",
      "            7.7495e-02,  7.6971e-01]],\n",
      "\n",
      "         [[ 3.6933e-01, -5.9036e-01, -3.7235e-01,  ...,  2.2937e-01,\n",
      "           -9.4829e-02, -1.2247e+00],\n",
      "          [ 2.5942e-01, -2.5283e+00, -1.2407e+00,  ...,  3.1276e+00,\n",
      "            1.3044e-01, -1.1673e+00],\n",
      "          [-8.9642e-01, -3.7856e+00, -7.4952e-01,  ...,  1.8244e+00,\n",
      "            9.6517e-01, -1.8407e+00],\n",
      "          [-2.3626e-02,  4.1448e-01, -1.2618e-02,  ..., -8.2307e-02,\n",
      "            4.0759e-02,  3.1036e-02],\n",
      "          [ 9.2118e-01, -4.0812e+00, -2.3002e+00,  ...,  1.3861e+00,\n",
      "            1.4326e+00, -1.8478e+00]],\n",
      "\n",
      "         [[-1.9727e+00, -1.3923e+00, -8.7930e-01,  ...,  1.8589e+00,\n",
      "           -1.1040e+00, -2.5662e+00],\n",
      "          [ 2.8337e-01, -4.0344e-01, -2.1983e+00,  ...,  2.0276e+00,\n",
      "            1.1882e+00, -1.7669e+00],\n",
      "          [-8.3873e-01,  7.9188e-01, -1.2839e+00,  ...,  3.0647e+00,\n",
      "            3.1441e-01, -1.7857e+00],\n",
      "          [-7.2069e-02,  5.7453e-02,  1.5440e-01,  ..., -1.1971e-01,\n",
      "           -2.1089e-02, -4.7610e-02],\n",
      "          [-7.1653e-01, -2.0406e+00, -1.6729e+00,  ...,  8.1287e-01,\n",
      "           -2.1166e+00, -3.1197e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.7847e-01, -6.0960e-01, -1.9752e+00,  ...,  1.7024e+00,\n",
      "            3.8374e+00, -2.3872e+00],\n",
      "          [ 6.3461e-01, -2.7202e-01, -4.3566e-01,  ...,  7.7425e-01,\n",
      "            4.0367e+00, -2.4257e+00],\n",
      "          [ 8.8847e-01,  3.4791e-01,  1.8549e-01,  ..., -1.3328e+00,\n",
      "            2.4655e+00,  1.6816e+00],\n",
      "          [-9.5061e-02,  7.6853e-02, -7.4214e-02,  ...,  1.1964e-02,\n",
      "           -1.2683e-01,  8.6631e-02],\n",
      "          [-5.7842e-01, -6.3459e-01,  5.2443e-02,  ..., -8.7831e-01,\n",
      "            4.2838e+00,  2.1103e+00]],\n",
      "\n",
      "         [[ 1.7435e+00,  6.6773e-02, -2.2186e+00,  ...,  1.9978e-01,\n",
      "           -3.4547e+00, -1.4480e+00],\n",
      "          [ 9.8572e-01,  4.7708e-01, -1.1415e+00,  ...,  3.5599e-01,\n",
      "           -1.3557e+00, -2.2965e+00],\n",
      "          [-2.0278e-01, -1.2427e+00, -3.3393e+00,  ..., -8.1775e-01,\n",
      "           -3.4237e+00, -1.7930e+00],\n",
      "          [-2.2857e-01,  4.3274e-04,  2.1026e-01,  ...,  1.0082e-01,\n",
      "            6.6830e-02,  2.7137e-01],\n",
      "          [ 3.9211e-01, -2.5145e+00, -2.5156e+00,  ...,  2.2782e+00,\n",
      "           -3.4911e+00, -2.9144e+00]],\n",
      "\n",
      "         [[-1.2814e+00,  5.6007e-01,  2.1054e+00,  ..., -8.5466e-01,\n",
      "           -2.4710e-01,  1.9036e+00],\n",
      "          [-1.9525e+00, -9.7694e-01,  6.9925e-01,  ..., -9.9938e-01,\n",
      "           -4.2329e-02,  9.5441e-01],\n",
      "          [ 9.2860e-01, -1.8335e-01,  2.7883e+00,  ..., -2.5863e-02,\n",
      "           -7.6203e-01,  2.7684e-01],\n",
      "          [ 5.5845e-02, -4.8915e-02, -1.3782e-01,  ...,  3.0568e-02,\n",
      "           -4.2838e-02,  6.3871e-02],\n",
      "          [ 8.3830e-01,  1.8382e-01,  3.4973e+00,  ..., -5.6020e-01,\n",
      "            2.9534e-01, -3.0108e+00]]]], grad_fn=<IndexSelectBackward>), '2__encoder_attn__prev_value': tensor([[[[-2.5935e-01, -1.2442e-01, -2.5853e-02,  ..., -2.8840e-02,\n",
      "           -4.2346e-01, -2.9806e-01],\n",
      "          [-5.6937e-01,  1.1705e-01, -9.9067e-01,  ...,  1.8711e-01,\n",
      "            3.1150e-01, -1.6250e-01],\n",
      "          [ 4.0034e-02, -1.0764e+00, -5.6243e-03,  ...,  1.6760e-01,\n",
      "           -3.5929e-02,  3.2760e-01],\n",
      "          [ 1.2359e-02,  1.4351e-02,  9.5340e-03,  ..., -1.3679e-03,\n",
      "            2.1309e-03, -1.2215e-02],\n",
      "          [ 1.3778e-01, -2.4748e-01, -4.4373e-01,  ...,  8.8546e-02,\n",
      "            9.3209e-01,  6.5654e-01]],\n",
      "\n",
      "         [[ 7.2035e-01, -7.6234e-01,  3.3331e-01,  ..., -1.8084e-01,\n",
      "            6.2629e-01, -3.2983e-01],\n",
      "          [ 8.3613e-01, -5.9860e-01,  3.4335e-01,  ...,  2.9460e-01,\n",
      "           -6.5016e-01, -1.1054e-01],\n",
      "          [ 7.4469e-01, -1.8298e-01,  5.7767e-01,  ...,  5.8955e-01,\n",
      "            7.5603e-01, -6.2361e-01],\n",
      "          [ 1.5944e-03,  1.8664e-02,  7.7999e-03,  ..., -1.1256e-02,\n",
      "            6.1000e-03,  7.5524e-03],\n",
      "          [ 7.1618e-01, -1.2174e+00,  1.2256e+00,  ...,  5.2259e-01,\n",
      "           -3.1588e-01,  7.1545e-01]],\n",
      "\n",
      "         [[-9.4837e-02,  8.1096e-02,  1.3406e-01,  ..., -2.0053e-01,\n",
      "           -3.9900e-01, -5.0250e-01],\n",
      "          [-4.4515e-01, -1.2705e-02,  2.5354e-01,  ..., -2.5393e-01,\n",
      "           -1.4032e-01, -1.4478e+00],\n",
      "          [ 4.1944e-01, -9.9628e-02,  4.5318e-01,  ..., -1.6784e-02,\n",
      "           -8.1422e-01,  3.9908e-02],\n",
      "          [ 8.7124e-03,  1.0266e-03, -1.6866e-03,  ..., -9.3485e-03,\n",
      "           -4.0888e-03,  1.9489e-02],\n",
      "          [-2.2785e-01, -4.9961e-01,  6.1244e-01,  ..., -5.2713e-01,\n",
      "           -2.2191e-01, -8.6003e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.6611e-01,  5.0673e-01, -2.2673e+00,  ...,  4.7577e-01,\n",
      "           -2.6392e-01, -7.0671e-01],\n",
      "          [-1.9535e-01,  3.9326e-01, -1.4108e+00,  ..., -2.1779e-01,\n",
      "           -3.4000e-01, -6.2553e-01],\n",
      "          [-6.4263e-01,  4.5545e-03, -7.6401e-01,  ...,  7.2808e-01,\n",
      "           -7.6862e-01, -2.3167e-01],\n",
      "          [ 1.0319e-02,  3.8189e-03,  4.1152e-03,  ...,  6.6243e-04,\n",
      "           -6.4141e-03, -1.1850e-02],\n",
      "          [-5.0776e-01, -4.7977e-01, -7.6190e-01,  ..., -4.9648e-01,\n",
      "           -1.4136e-01, -6.8101e-01]],\n",
      "\n",
      "         [[-1.4065e+00,  4.1326e-01, -1.5717e-01,  ...,  9.3696e-01,\n",
      "           -6.1296e-02, -2.5049e-01],\n",
      "          [-1.1747e+00,  1.4632e-01, -6.9937e-01,  ...,  8.9240e-01,\n",
      "           -2.8569e-01,  3.0640e-01],\n",
      "          [-1.5931e+00,  9.6646e-03, -6.0439e-01,  ...,  3.1296e-01,\n",
      "           -3.8876e-01, -8.9996e-02],\n",
      "          [ 2.7655e-02,  2.8951e-03, -1.0141e-02,  ...,  3.1923e-03,\n",
      "            2.7200e-02, -1.8123e-02],\n",
      "          [-1.4449e-01, -1.5309e-01, -9.5803e-01,  ...,  7.8304e-01,\n",
      "           -1.8593e-01,  3.9945e-01]],\n",
      "\n",
      "         [[-1.2485e-01, -1.7311e-01,  9.7669e-01,  ..., -5.5458e-01,\n",
      "           -7.5266e-01, -2.9064e-01],\n",
      "          [-1.1379e+00,  2.9424e-01,  1.3698e+00,  ..., -8.4937e-02,\n",
      "           -4.4106e-01, -4.3865e-01],\n",
      "          [-1.5326e+00, -2.3475e-01,  5.3702e-01,  ..., -1.3909e+00,\n",
      "           -9.4090e-01, -9.7259e-02],\n",
      "          [ 3.9275e-02, -2.2653e-02, -2.5070e-02,  ..., -2.1613e-03,\n",
      "            7.3943e-03, -1.0519e-02],\n",
      "          [-1.0389e+00, -6.5827e-01,  4.0068e-01,  ..., -2.7360e-01,\n",
      "           -8.6364e-01, -1.6624e+00]]]], grad_fn=<IndexSelectBackward>), '2__encoder_attn__prev_mask': tensor([[True, True, True, True, True]]), '3__self_attn__prev_key': tensor([[[[-5.8752e-01,  5.6562e-01, -3.7348e+00,  ..., -1.5380e+00,\n",
      "           -9.5083e-03,  2.5221e-01],\n",
      "          [-1.0558e+00,  1.8854e+00, -3.0677e+00,  ..., -2.6788e+00,\n",
      "            8.8423e-01,  8.7410e-02]],\n",
      "\n",
      "         [[-2.4053e-01, -5.1060e-01, -1.1297e+00,  ..., -8.7127e-01,\n",
      "            7.8429e-01, -3.3410e-01],\n",
      "          [-8.7947e-01, -8.4822e-01, -1.3277e+00,  ..., -1.4688e+00,\n",
      "            7.1014e-01,  6.2603e-01]],\n",
      "\n",
      "         [[ 4.8177e-01, -6.4359e-01, -1.0636e+00,  ...,  5.6978e-01,\n",
      "           -1.1248e+00,  1.1759e+00],\n",
      "          [ 6.8810e-01, -6.1865e-01, -4.2389e-01,  ...,  3.6866e-01,\n",
      "           -1.0329e+00,  1.0652e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0870e-01, -2.2768e-01, -1.0040e-01,  ...,  1.1902e+00,\n",
      "           -7.6703e-01,  6.5140e-01],\n",
      "          [-1.7470e-03, -6.1914e-01,  1.7018e-01,  ...,  1.6121e+00,\n",
      "           -1.1952e+00, -5.5857e-01]],\n",
      "\n",
      "         [[ 1.7063e+00, -1.9763e+00, -6.9068e-01,  ...,  2.1157e-01,\n",
      "            6.2216e-01, -1.1442e+00],\n",
      "          [ 1.3151e+00, -1.0537e+00, -1.6174e+00,  ..., -5.9398e-02,\n",
      "           -4.1713e-02, -1.2985e+00]],\n",
      "\n",
      "         [[-1.7183e-01, -3.5366e-01,  1.8971e+00,  ...,  1.1589e+00,\n",
      "            2.5341e-01,  1.0113e+00],\n",
      "          [-1.1022e+00, -8.2803e-02,  1.7322e+00,  ...,  8.3007e-01,\n",
      "            1.4701e+00,  1.1107e+00]]]], grad_fn=<IndexSelectBackward>), '3__self_attn__prev_value': tensor([[[[ 1.3912,  1.2860, -0.0068,  ..., -1.8258,  0.7324,  0.8589],\n",
      "          [ 1.2434,  0.8593,  0.2875,  ..., -1.6648,  0.9133,  0.9197]],\n",
      "\n",
      "         [[ 1.1612, -0.6299, -0.4043,  ...,  0.4358, -0.4095, -0.4030],\n",
      "          [ 1.1769, -0.3668, -0.4020,  ...,  0.5529, -0.6448, -0.1829]],\n",
      "\n",
      "         [[-0.8330, -0.4531,  1.1397,  ..., -0.1423,  0.1661,  0.8210],\n",
      "          [-0.5422, -0.1662,  1.1189,  ...,  0.1368,  0.1228,  0.8394]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1493,  0.1438, -0.5191,  ...,  0.4727, -0.0685, -0.9325],\n",
      "          [ 0.1449, -0.3770, -0.1881,  ..., -0.0672,  0.3101, -0.9375]],\n",
      "\n",
      "         [[-0.6507,  0.1180, -0.7895,  ...,  0.4286,  0.5500,  1.3736],\n",
      "          [-0.7942,  0.1309, -0.4778,  ...,  0.5347,  0.6741,  1.1789]],\n",
      "\n",
      "         [[ 0.5243,  0.5028,  0.4384,  ..., -0.7270, -1.8861,  0.3643],\n",
      "          [ 0.2899,  0.7874,  0.5593,  ..., -0.8031, -1.8028,  0.1063]]]],\n",
      "       grad_fn=<IndexSelectBackward>), '3__self_attn__prev_mask': tensor([[[1., 0.],\n",
      "         [1., 1.]]]), '3__encoder_attn__prev_key': tensor([[[[-4.4238e-01, -3.5894e-01, -3.2957e-01,  ..., -1.6209e+00,\n",
      "            8.7218e-01, -1.9031e-01],\n",
      "          [-2.3574e-01, -8.8837e-01, -6.1068e-02,  ...,  1.6922e-01,\n",
      "           -8.4314e-02,  8.8394e-01],\n",
      "          [-5.4673e-01, -4.0791e-01, -6.1257e-01,  ..., -1.3244e+00,\n",
      "            8.8696e-01, -9.7835e-01],\n",
      "          [ 3.0467e-02, -6.9816e-04,  2.9829e-04,  ...,  4.2372e-02,\n",
      "            2.8905e-02, -3.6837e-02],\n",
      "          [ 2.3924e-01,  6.2404e-02,  4.8341e-01,  ..., -1.7281e+00,\n",
      "            1.3996e+00, -1.9741e+00]],\n",
      "\n",
      "         [[ 2.9768e+00,  1.5948e+00, -2.6074e+00,  ..., -6.3418e-01,\n",
      "           -1.0316e+00, -3.0120e-01],\n",
      "          [ 2.0369e-01,  3.5730e+00, -1.2038e+00,  ..., -1.5603e+00,\n",
      "           -3.2232e+00,  9.9635e-01],\n",
      "          [ 8.2315e-01,  4.9584e+00, -3.7017e+00,  ..., -2.7063e+00,\n",
      "           -8.8639e-01, -3.1489e-01],\n",
      "          [-4.9294e-03, -6.0173e-01,  1.8120e-02,  ..., -3.1525e-02,\n",
      "            2.1825e-01, -1.1196e-01],\n",
      "          [ 1.8155e+00,  5.6703e+00, -2.9133e+00,  ..., -1.5614e+00,\n",
      "           -2.1791e+00,  1.3850e+00]],\n",
      "\n",
      "         [[-4.6607e-01,  1.7762e+00, -1.1223e+00,  ...,  2.4082e+00,\n",
      "           -3.1193e-01,  1.6223e+00],\n",
      "          [ 1.6760e-01,  6.4262e-01, -1.4788e-01,  ...,  1.5367e+00,\n",
      "           -1.1262e+00,  1.3630e+00],\n",
      "          [ 6.9240e-01, -1.5890e+00,  1.7268e+00,  ...,  3.6108e+00,\n",
      "           -1.3339e+00,  2.8286e-01],\n",
      "          [ 1.1916e-01, -1.9084e-03,  5.0092e-02,  ..., -2.9767e-01,\n",
      "           -1.2876e-02,  4.7224e-02],\n",
      "          [ 1.7641e+00, -4.6223e-01,  1.0195e+00,  ...,  3.8702e+00,\n",
      "            2.2701e-01, -5.8561e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0983e+00,  3.0131e+00, -4.1350e+00,  ...,  2.6314e-01,\n",
      "            2.1426e+00, -6.0103e-01],\n",
      "          [ 2.1158e+00,  3.6719e+00, -6.0601e-01,  ...,  8.7108e-02,\n",
      "            1.9513e+00,  1.7908e-01],\n",
      "          [ 1.1902e+00,  4.7289e+00, -1.0907e+00,  ...,  6.4950e-01,\n",
      "            1.4875e+00,  2.9347e+00],\n",
      "          [-1.5177e-01, -3.4621e-01,  2.7001e-02,  ..., -9.2071e-03,\n",
      "           -8.8362e-03,  5.8629e-02],\n",
      "          [ 3.7647e-01,  3.7221e+00, -1.7664e+00,  ...,  4.6334e-01,\n",
      "           -1.5303e+00,  1.0883e+00]],\n",
      "\n",
      "         [[ 8.7855e-01, -5.0696e+00, -2.0954e-02,  ..., -4.4894e+00,\n",
      "           -1.2649e+00,  2.6153e-01],\n",
      "          [ 9.6208e-01, -2.9015e+00,  6.4629e-01,  ..., -6.1849e-01,\n",
      "           -7.5615e-01,  7.6553e-01],\n",
      "          [-3.9283e-01, -3.6022e+00,  1.8501e+00,  ..., -6.9918e-01,\n",
      "           -1.9756e+00,  1.9469e+00],\n",
      "          [-4.9417e-02,  5.1570e-01, -5.9801e-02,  ...,  3.5016e-01,\n",
      "           -5.6694e-02, -7.9494e-02],\n",
      "          [ 1.2131e+00, -1.3296e+00,  3.7456e-01,  ..., -2.7029e+00,\n",
      "           -2.0023e+00,  3.4539e-02]],\n",
      "\n",
      "         [[ 2.9051e+00,  6.8755e-01,  1.7356e-01,  ...,  1.5626e-01,\n",
      "            1.0556e+00, -7.9249e-01],\n",
      "          [ 1.7957e+00,  1.4948e+00, -7.2787e-01,  ...,  3.1361e+00,\n",
      "           -1.3946e+00,  2.2401e+00],\n",
      "          [ 7.7606e-01, -9.5064e-01,  1.6351e-01,  ..., -1.3927e+00,\n",
      "           -1.2619e+00, -1.0293e+00],\n",
      "          [-1.3123e-02,  2.2785e-02,  1.3964e-02,  ...,  2.2783e-02,\n",
      "           -1.9532e-02,  8.6968e-03],\n",
      "          [ 1.2360e+00,  1.4292e+00, -7.5567e-02,  ..., -1.6281e+00,\n",
      "           -1.9296e+00,  1.6704e+00]]]], grad_fn=<IndexSelectBackward>), '3__encoder_attn__prev_value': tensor([[[[ 7.8824e-01,  5.6716e-01, -1.2599e+00,  ...,  1.0581e+00,\n",
      "            1.4613e-01, -8.7754e-01],\n",
      "          [ 2.6371e-01, -4.1986e-01, -5.8831e-02,  ...,  8.9887e-01,\n",
      "           -9.3022e-03, -5.7445e-01],\n",
      "          [-1.8860e-01,  1.0550e-01,  3.3362e-01,  ...,  1.1850e+00,\n",
      "           -5.5985e-01, -4.2572e-01],\n",
      "          [ 3.9166e-03, -1.7273e-02,  2.7583e-02,  ..., -6.0671e-03,\n",
      "            2.1221e-02, -2.3299e-02],\n",
      "          [-1.2678e-01, -1.0567e+00,  5.5916e-01,  ...,  1.6230e+00,\n",
      "           -5.7040e-01,  3.7920e-01]],\n",
      "\n",
      "         [[-7.2955e-02, -7.0521e-01, -3.2601e-01,  ..., -2.5795e-01,\n",
      "           -6.3355e-01, -9.2009e-02],\n",
      "          [-1.6456e-01, -2.8948e-01, -4.7199e-01,  ...,  1.1436e+00,\n",
      "            1.1444e-02,  6.6622e-02],\n",
      "          [ 9.3119e-02, -4.1204e-01, -8.5779e-01,  ...,  3.3170e-01,\n",
      "           -3.4800e-01,  3.1470e-01],\n",
      "          [-8.9087e-03, -7.9897e-03, -2.5464e-03,  ...,  6.6491e-05,\n",
      "           -9.9266e-03, -1.1521e-02],\n",
      "          [-2.7787e-01,  6.1692e-01,  8.7193e-01,  ...,  1.2773e+00,\n",
      "           -7.2988e-01,  1.1376e+00]],\n",
      "\n",
      "         [[-8.3496e-02,  4.2661e-01, -7.5055e-01,  ...,  8.8982e-02,\n",
      "            3.2705e-01,  3.8756e-01],\n",
      "          [-1.9787e-01,  2.5337e-01, -4.8897e-01,  ...,  4.9343e-01,\n",
      "            1.5375e-01,  4.5581e-01],\n",
      "          [ 3.4878e-01,  8.0536e-01, -1.1121e+00,  ..., -4.4112e-01,\n",
      "           -2.2241e-01, -1.8061e-02],\n",
      "          [ 1.9262e-03, -1.5497e-02,  1.2869e-02,  ..., -2.4495e-03,\n",
      "            8.5170e-03, -4.0647e-03],\n",
      "          [ 1.2274e-01,  3.5227e-01, -1.8609e+00,  ...,  5.1771e-01,\n",
      "            1.0620e-01,  2.0676e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2992e-01, -1.5152e-01, -1.8955e-01,  ...,  2.0474e-02,\n",
      "           -3.2286e-01,  7.2768e-02],\n",
      "          [-9.0330e-02, -2.3725e-01,  2.6436e-01,  ..., -5.4007e-01,\n",
      "           -1.4987e-01, -3.8615e-01],\n",
      "          [-8.3563e-02, -3.5696e-01,  3.3873e-01,  ...,  2.4058e-01,\n",
      "            4.5824e-01,  3.9758e-01],\n",
      "          [-2.1061e-03,  7.8615e-02,  8.7047e-04,  ...,  5.9810e-03,\n",
      "           -7.6282e-04,  1.9302e-03],\n",
      "          [-6.9601e-01, -1.0941e-02,  1.7903e-01,  ..., -7.6358e-01,\n",
      "            5.2006e-02, -7.3793e-01]],\n",
      "\n",
      "         [[-3.5231e-01,  4.8649e-01, -1.4340e-01,  ...,  2.1077e-01,\n",
      "            1.9393e+00,  8.0773e-01],\n",
      "          [-4.7352e-01, -1.4267e-01,  1.2610e-01,  ...,  7.5217e-01,\n",
      "            3.9709e-01,  3.1315e-01],\n",
      "          [ 3.5114e-01,  5.7234e-02,  5.8463e-01,  ...,  5.7610e-01,\n",
      "            1.2082e+00, -1.8677e-01],\n",
      "          [-1.8448e-03,  1.0314e-02,  1.0764e-02,  ..., -6.2677e-03,\n",
      "           -3.4993e-02, -1.5394e-02],\n",
      "          [-2.3502e-01,  6.2542e-01, -3.0024e-02,  ...,  5.3202e-01,\n",
      "            2.2077e+00, -1.9482e+00]],\n",
      "\n",
      "         [[ 1.5756e-01,  3.3847e-01,  2.3559e-01,  ..., -3.2394e-01,\n",
      "           -5.4678e-01,  1.8959e+00],\n",
      "          [ 3.7646e-01,  8.2562e-01,  7.2023e-01,  ..., -6.7948e-01,\n",
      "           -3.4884e-01,  9.9174e-01],\n",
      "          [ 2.3112e-01,  1.7633e-01, -6.3835e-01,  ..., -1.1668e+00,\n",
      "           -2.2868e-01,  2.9700e-01],\n",
      "          [ 9.3114e-03, -1.5418e-02, -6.2028e-03,  ...,  2.1120e-02,\n",
      "            4.2685e-02, -1.9195e-02],\n",
      "          [ 6.0076e-01,  8.5831e-01,  4.1797e-01,  ..., -2.5821e-01,\n",
      "           -3.5770e-01,  1.5152e+00]]]], grad_fn=<IndexSelectBackward>), '3__encoder_attn__prev_mask': tensor([[True, True, True, True, True]]), '4__self_attn__prev_key': tensor([[[[-0.3351,  0.3399, -1.1347,  ..., -0.6560, -0.2461,  0.0854],\n",
      "          [-0.0434,  1.1351, -0.9151,  ..., -0.1225, -1.0557,  0.6473]],\n",
      "\n",
      "         [[-0.2540,  1.6162, -0.5060,  ...,  1.9145, -0.3268, -0.2783],\n",
      "          [-0.2544,  0.6839, -1.1835,  ...,  0.7544,  0.6838, -0.0796]],\n",
      "\n",
      "         [[-1.3087,  0.4685,  0.7485,  ...,  2.1247, -0.2207, -0.3238],\n",
      "          [-0.6850,  0.8453,  0.4483,  ...,  1.9610,  0.2141, -0.3312]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1907,  0.9060,  0.2075,  ...,  0.2343, -0.4535, -0.2431],\n",
      "          [-0.5592,  1.1271,  0.6094,  ...,  0.2826,  0.1686,  0.6724]],\n",
      "\n",
      "         [[-0.0921,  1.7666,  1.5086,  ..., -0.5137, -1.0426, -1.4257],\n",
      "          [-0.4025,  1.5364,  1.4529,  ..., -0.9170, -0.1956, -1.1724]],\n",
      "\n",
      "         [[-1.9042,  1.1227,  1.3052,  ..., -0.0024,  0.1673, -0.6912],\n",
      "          [-1.5908, -0.2204,  0.5543,  ...,  0.2205,  0.5750, -1.0067]]]],\n",
      "       grad_fn=<IndexSelectBackward>), '4__self_attn__prev_value': tensor([[[[-0.4898, -0.2877,  0.0886,  ..., -0.8666, -1.2057,  0.2060],\n",
      "          [-0.1135, -0.1952,  0.0167,  ..., -1.1748, -1.3987,  0.1584]],\n",
      "\n",
      "         [[-0.2654,  0.1161, -0.1025,  ...,  0.5334, -0.2219, -0.2289],\n",
      "          [-0.3287,  0.0329, -0.3766,  ...,  0.5529, -0.3112, -0.0921]],\n",
      "\n",
      "         [[-0.5588, -0.0934, -0.3482,  ...,  0.2413, -0.2161,  0.3450],\n",
      "          [-0.3490, -0.2396, -0.2945,  ...,  0.5356, -0.1904,  0.3634]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0175,  0.3984, -0.8234,  ...,  0.7253, -0.1499,  0.4862],\n",
      "          [ 0.5738,  0.3142, -0.8305,  ...,  0.7521, -0.1198,  0.1264]],\n",
      "\n",
      "         [[-0.5605,  0.6091, -0.7504,  ...,  0.3904, -0.6530,  0.1908],\n",
      "          [-0.0937,  0.3820, -0.9638,  ...,  0.6781, -0.2980,  0.2306]],\n",
      "\n",
      "         [[-0.5248,  0.0722, -0.0112,  ...,  0.5165,  0.6955,  0.3965],\n",
      "          [-0.7375, -0.0997, -0.2424,  ...,  0.3739,  0.3544,  0.1729]]]],\n",
      "       grad_fn=<IndexSelectBackward>), '4__self_attn__prev_mask': tensor([[[1., 0.],\n",
      "         [1., 1.]]]), '4__encoder_attn__prev_key': tensor([[[[ 1.3262e+00, -4.6153e-01, -4.5599e+00,  ..., -2.8537e+00,\n",
      "           -4.8621e-01, -2.2549e+00],\n",
      "          [ 8.4526e-02,  8.9012e-01, -1.4654e+00,  ..., -2.0225e+00,\n",
      "           -1.2740e+00, -2.6178e+00],\n",
      "          [-4.5748e+00, -2.8237e-01, -2.3160e+00,  ..., -1.7781e+00,\n",
      "           -1.3245e+00, -4.3041e+00],\n",
      "          [ 1.0172e-01, -4.4791e-02,  1.3660e-01,  ...,  2.5326e-01,\n",
      "            6.5852e-02,  3.8534e-01],\n",
      "          [-1.0916e+00,  7.2614e-01,  2.4998e+00,  ..., -9.5068e-01,\n",
      "           -2.7694e-01, -1.3986e+00]],\n",
      "\n",
      "         [[ 3.0748e-01,  1.8435e+00,  2.6746e+00,  ..., -1.1215e+00,\n",
      "            1.4485e+00, -3.4838e-01],\n",
      "          [-3.0923e-01,  2.2985e+00,  2.9671e+00,  ...,  4.7053e-01,\n",
      "           -2.1088e-01,  1.4993e+00],\n",
      "          [ 1.2682e+00,  2.4955e+00,  3.1341e+00,  ...,  2.0473e+00,\n",
      "            2.5193e+00, -1.6817e+00],\n",
      "          [ 5.1605e-02, -5.1432e-02, -5.6487e-01,  ..., -2.6005e-02,\n",
      "           -4.4400e-02, -1.7688e-01],\n",
      "          [ 8.4500e-01,  1.5038e+00,  2.5390e+00,  ...,  4.0600e-01,\n",
      "            3.3573e+00,  2.7408e+00]],\n",
      "\n",
      "         [[ 5.5580e-01, -1.8799e+00, -8.9943e-01,  ...,  1.7941e+00,\n",
      "            4.1691e+00,  1.0666e+00],\n",
      "          [-1.3155e+00, -3.4648e-01,  4.5502e-01,  ...,  1.0668e-01,\n",
      "            1.2700e+00, -9.3962e-01],\n",
      "          [-5.6563e-01, -1.2375e+00,  7.6803e-01,  ..., -4.0699e-01,\n",
      "            4.6948e-02,  8.9975e-01],\n",
      "          [ 1.1325e-02,  1.8702e-03, -2.7608e-01,  ..., -9.0871e-03,\n",
      "           -1.9209e-01, -4.1937e-03],\n",
      "          [ 1.7831e+00, -1.8786e+00,  1.0263e+00,  ..., -6.5323e-01,\n",
      "            1.7425e+00,  1.0046e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2443e+00, -1.0232e+00,  1.3507e+00,  ..., -1.7136e+00,\n",
      "           -1.1673e+00,  2.0478e-01],\n",
      "          [ 2.2947e-01,  8.1203e-01,  2.2077e+00,  ..., -1.2142e+00,\n",
      "           -6.9149e-01, -1.6980e-01],\n",
      "          [-2.8659e+00,  1.6107e-03,  2.4706e+00,  ...,  4.0746e-01,\n",
      "            8.5327e-01,  2.2942e+00],\n",
      "          [ 8.9326e-02,  6.8696e-02, -1.8532e-01,  ..., -7.9838e-02,\n",
      "           -2.7331e-04, -1.7705e-01],\n",
      "          [-9.4769e-02, -5.1175e-01,  1.2286e+00,  ...,  9.1615e-01,\n",
      "            1.7962e+00,  6.4495e-01]],\n",
      "\n",
      "         [[ 4.0065e-01, -6.6161e-01, -1.8085e-01,  ..., -3.7310e+00,\n",
      "            3.6404e+00,  1.8825e+00],\n",
      "          [ 7.1052e-01, -1.0358e+00,  1.1329e+00,  ..., -2.7500e+00,\n",
      "            1.0664e-01,  5.3251e-01],\n",
      "          [ 2.0737e-01,  1.8533e-01, -7.3589e-01,  ..., -4.1176e+00,\n",
      "            4.7943e-01,  1.3050e+00],\n",
      "          [ 4.1839e-02, -3.6109e-03, -5.0653e-03,  ...,  2.8416e-01,\n",
      "            5.0899e-02, -8.8714e-03],\n",
      "          [ 1.3496e+00,  6.9237e-02, -1.9653e+00,  ..., -4.5248e+00,\n",
      "           -1.5723e+00, -1.5218e+00]],\n",
      "\n",
      "         [[ 8.5968e-01,  1.2931e+00,  2.8384e-01,  ...,  4.5825e+00,\n",
      "           -3.2305e-01, -2.6076e+00],\n",
      "          [ 1.0151e+00,  8.2364e-01, -2.2487e+00,  ...,  9.6392e-01,\n",
      "           -1.4276e+00, -1.6023e+00],\n",
      "          [-8.6996e-01,  7.9208e-01, -8.2243e-01,  ...,  2.0249e+00,\n",
      "            4.3300e-01, -1.4365e+00],\n",
      "          [-1.3347e-02,  8.3296e-02, -6.2764e-03,  ..., -3.9305e-01,\n",
      "            5.5453e-02,  1.2218e-01],\n",
      "          [-3.1971e+00, -1.6082e+00,  1.7315e+00,  ...,  1.2596e+00,\n",
      "           -3.8111e-01, -2.3959e+00]]]], grad_fn=<IndexSelectBackward>), '4__encoder_attn__prev_value': tensor([[[[ 7.4179e-01, -2.9876e-01, -3.6388e-01,  ..., -3.8156e-01,\n",
      "           -2.8606e-01,  2.3396e-01],\n",
      "          [-1.4257e-01,  3.8270e-01, -1.2362e-01,  ..., -2.3351e-01,\n",
      "           -5.3602e-03, -7.1920e-02],\n",
      "          [-3.0855e-01, -5.2117e-01,  1.1489e-01,  ..., -3.5613e-01,\n",
      "           -2.8735e-01, -5.5296e-01],\n",
      "          [-8.4035e-03, -1.2670e-03,  1.7589e-02,  ...,  2.3392e-03,\n",
      "           -3.7903e-03, -1.6482e-03],\n",
      "          [-3.6254e-01,  2.6056e-02, -6.1803e-01,  ..., -1.0541e+00,\n",
      "           -5.7057e-01,  7.7510e-01]],\n",
      "\n",
      "         [[ 8.4295e-01, -1.2375e-02, -1.8670e-01,  ..., -4.7250e-01,\n",
      "           -9.7701e-01, -2.9213e-01],\n",
      "          [ 1.2850e+00, -2.7057e-01, -5.0121e-01,  ..., -5.0306e-01,\n",
      "           -3.3620e-01, -2.9396e-01],\n",
      "          [ 6.8544e-01, -2.2920e-01, -1.2158e-01,  ...,  4.4035e-01,\n",
      "           -4.2918e-01,  1.2949e+00],\n",
      "          [-8.3072e-03, -1.3381e-03, -3.8270e-03,  ..., -4.8081e-03,\n",
      "            1.8955e-02,  2.6107e-02],\n",
      "          [ 3.8078e-01, -7.8544e-01, -6.1756e-01,  ...,  3.4286e-01,\n",
      "            1.0234e-02,  1.1927e+00]],\n",
      "\n",
      "         [[ 3.3156e-01, -8.2310e-01,  2.2228e-01,  ..., -8.9058e-01,\n",
      "            1.4714e-01,  1.1362e+00],\n",
      "          [ 2.7238e-01, -9.6225e-03,  2.8319e-01,  ...,  1.3215e-01,\n",
      "           -4.7063e-01,  8.5551e-01],\n",
      "          [-2.2323e-01, -2.2172e-01,  7.1064e-01,  ..., -4.0455e-01,\n",
      "            1.5801e-01,  9.7044e-01],\n",
      "          [ 8.8214e-03, -1.6274e-02, -1.7359e-02,  ...,  1.2586e-02,\n",
      "            1.9470e-02, -7.3715e-04],\n",
      "          [ 5.4685e-01, -5.1675e-01, -7.1674e-01,  ...,  2.1666e-01,\n",
      "            2.6612e-01, -2.1276e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3734e-01,  3.5844e-02,  1.1485e+00,  ..., -2.9819e-02,\n",
      "            1.0111e-01, -8.5998e-01],\n",
      "          [-2.4951e-01,  7.0484e-01,  2.1917e-02,  ..., -3.1740e-01,\n",
      "            3.0816e-01, -1.4660e-01],\n",
      "          [ 3.2249e-01,  6.2367e-01, -5.3988e-02,  ...,  2.9789e-01,\n",
      "           -5.3214e-01, -1.0543e+00],\n",
      "          [ 2.8072e-03, -2.4413e-02, -2.2646e-02,  ..., -1.1476e-02,\n",
      "            1.1717e-04,  1.8215e-02],\n",
      "          [ 1.0199e+00,  8.4655e-01, -1.1359e-01,  ...,  3.6640e-01,\n",
      "           -4.1924e-01, -3.6187e-03]],\n",
      "\n",
      "         [[ 2.0244e-01,  4.2894e-01, -9.0903e-02,  ...,  4.9139e-01,\n",
      "           -7.3783e-01,  1.0816e+00],\n",
      "          [ 7.8596e-01, -2.1125e-01, -4.8135e-01,  ...,  6.7974e-01,\n",
      "           -1.0094e+00,  9.5271e-01],\n",
      "          [ 3.2275e-01,  7.6972e-01, -4.3862e-01,  ...,  3.2442e-02,\n",
      "           -1.2914e+00,  1.0605e+00],\n",
      "          [-9.8191e-04, -1.1758e-02,  1.0106e-02,  ..., -5.2953e-03,\n",
      "           -2.8908e-03, -3.7447e-02],\n",
      "          [-3.8138e-02, -4.0305e-03, -9.9791e-01,  ..., -1.6315e-01,\n",
      "           -9.8765e-01,  6.3146e-01]],\n",
      "\n",
      "         [[ 6.3894e-01, -1.0446e+00, -1.9788e-02,  ...,  5.3697e-02,\n",
      "           -1.1100e-01, -2.2599e-01],\n",
      "          [ 3.4433e-01, -7.2478e-02,  7.7424e-02,  ...,  7.0547e-01,\n",
      "            1.7691e-01, -7.9484e-01],\n",
      "          [ 6.4954e-01,  4.3778e-01, -8.4606e-03,  ...,  1.0635e-02,\n",
      "            1.8191e-01,  5.9886e-02],\n",
      "          [ 1.7106e-02,  3.2171e-02,  4.5171e-03,  ...,  1.8686e-03,\n",
      "            1.1689e-02,  3.2313e-02],\n",
      "          [ 5.7587e-01, -2.3107e-01,  3.1624e-01,  ..., -3.3818e-01,\n",
      "           -1.1190e-01, -6.6851e-01]]]], grad_fn=<IndexSelectBackward>), '4__encoder_attn__prev_mask': tensor([[True, True, True, True, True]]), '5__self_attn__prev_key': tensor([[[[-0.7249,  1.7237, -0.2918,  ..., -0.4321,  1.5326, -0.2054],\n",
      "          [-0.6423,  1.6084, -0.5259,  ..., -0.2242,  1.7512, -0.5273]],\n",
      "\n",
      "         [[ 0.0741,  1.8177, -0.7674,  ...,  1.1134, -0.7047, -0.5296],\n",
      "          [ 0.3206,  1.6931, -0.7543,  ...,  0.5541, -0.5163, -0.1889]],\n",
      "\n",
      "         [[ 0.9165, -1.0170, -0.0322,  ..., -1.1418, -0.1884,  0.1383],\n",
      "          [ 0.8000, -1.8242, -0.0145,  ..., -0.8961, -0.0289,  0.2908]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3790,  1.9409,  1.0985,  ..., -0.2716, -0.6595, -0.3179],\n",
      "          [-0.3431,  1.7795,  1.0712,  ..., -0.3909, -0.5163, -0.3662]],\n",
      "\n",
      "         [[-0.1005,  0.8436, -0.8988,  ..., -1.1521, -0.9153, -1.0095],\n",
      "          [ 0.2082,  0.8736, -0.9776,  ..., -0.9874, -0.1379, -0.9347]],\n",
      "\n",
      "         [[-2.5826,  0.1875, -0.5099,  ...,  0.5419,  0.4958, -0.9485],\n",
      "          [-1.9742, -0.0305, -0.7037,  ..., -0.1614,  0.3449, -1.0334]]]],\n",
      "       grad_fn=<IndexSelectBackward>), '5__self_attn__prev_value': tensor([[[[ 0.9826, -0.4855, -0.5463,  ...,  1.0536,  0.4915,  0.4578],\n",
      "          [ 0.8005, -0.3588, -0.3195,  ...,  0.9008,  0.4089,  0.3727]],\n",
      "\n",
      "         [[-1.0224, -0.4601,  0.3011,  ..., -0.6459,  0.0900,  0.6190],\n",
      "          [-0.8247, -0.3141,  0.3951,  ..., -0.7358,  0.0271,  0.5458]],\n",
      "\n",
      "         [[ 1.0064, -0.7541, -1.3068,  ..., -0.1305,  0.4380,  0.2331],\n",
      "          [ 0.9633, -0.6638, -1.0214,  ..., -0.2045,  0.6995,  0.4664]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1778, -0.5008,  0.5414,  ..., -0.0285,  0.0627,  0.4847],\n",
      "          [ 0.0626, -0.5029,  0.6647,  ...,  0.1907,  0.1736,  0.3928]],\n",
      "\n",
      "         [[-0.1514, -0.6237,  0.5661,  ..., -0.1873, -0.2740,  0.0371],\n",
      "          [-0.1110, -0.5897,  0.6097,  ..., -0.1790, -0.1322,  0.2980]],\n",
      "\n",
      "         [[ 1.2955,  0.4681, -0.7645,  ...,  1.2529, -0.0563,  0.0328],\n",
      "          [ 0.9814,  0.2874, -0.1063,  ...,  1.0696, -0.2549, -0.1662]]]],\n",
      "       grad_fn=<IndexSelectBackward>), '5__self_attn__prev_mask': tensor([[[1., 0.],\n",
      "         [1., 1.]]]), '5__encoder_attn__prev_key': tensor([[[[-8.2726e-01, -1.0416e+00,  3.3773e-01,  ...,  1.2012e+00,\n",
      "            3.5560e+00,  1.4662e+00],\n",
      "          [-6.1255e-01, -1.4584e+00, -1.7805e-01,  ..., -8.3947e-01,\n",
      "            2.3030e+00,  2.9881e-01],\n",
      "          [-4.3736e-01, -2.1280e-01, -1.1278e+00,  ...,  1.1320e-01,\n",
      "            2.4637e+00, -5.7537e-02],\n",
      "          [ 2.1265e-01,  3.1668e-02, -1.7043e-01,  ...,  1.3376e-02,\n",
      "           -6.4564e-01,  2.3498e-02],\n",
      "          [-1.0427e+00, -1.4136e+00, -1.2910e+00,  ..., -1.5048e+00,\n",
      "            4.0575e+00, -6.4396e-01]],\n",
      "\n",
      "         [[ 1.9855e+00, -6.1240e-02, -1.7603e+00,  ..., -1.2992e+00,\n",
      "           -4.0677e-01,  1.0161e+00],\n",
      "          [ 2.0133e+00,  4.0506e-02, -2.5703e-01,  ..., -2.9423e-01,\n",
      "            3.5140e-01,  1.9414e-01],\n",
      "          [ 1.1009e+00,  6.0398e-01,  3.6325e-01,  ..., -2.3336e+00,\n",
      "            7.2285e-01,  3.0757e+00],\n",
      "          [-5.0078e-01,  4.4266e-02,  5.6476e-01,  ..., -2.2457e-02,\n",
      "           -6.0059e-02,  4.2022e-02],\n",
      "          [ 2.0357e+00, -5.6891e-02, -1.1857e-01,  ..., -1.8294e+00,\n",
      "            1.0902e+00, -8.6257e-01]],\n",
      "\n",
      "         [[ 4.7858e+00,  1.0406e+00,  2.4134e-01,  ...,  4.3962e-01,\n",
      "           -1.0950e+00, -7.6733e-01],\n",
      "          [ 3.8517e+00, -3.1347e-01,  1.1659e+00,  ..., -1.5198e+00,\n",
      "            1.0792e+00, -6.3355e-01],\n",
      "          [ 5.2180e+00, -9.0978e-02,  2.7140e-01,  ...,  8.2656e-02,\n",
      "            8.4198e-01, -9.0214e-01],\n",
      "          [-4.8056e-01,  1.0170e-01,  4.6374e-02,  ..., -1.5450e-03,\n",
      "            1.5831e-02,  1.6325e-03],\n",
      "          [ 4.6481e+00, -1.7255e+00,  2.3417e+00,  ...,  2.6849e-01,\n",
      "            1.1112e+00, -9.3104e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7955e+00, -2.2041e+00, -8.6561e-01,  ..., -2.4123e-01,\n",
      "            9.3633e-01, -4.6753e+00],\n",
      "          [-2.7949e-01,  1.1132e+00,  6.8823e-01,  ..., -9.8802e-01,\n",
      "            2.5453e-01, -3.2575e+00],\n",
      "          [ 9.5531e-01, -1.2454e+00, -6.8796e-02,  ...,  8.8543e-03,\n",
      "            6.9376e-02, -6.4521e+00],\n",
      "          [-8.6204e-02, -5.6866e-02,  3.5951e-03,  ...,  4.9525e-03,\n",
      "           -8.3710e-02,  3.2953e-01],\n",
      "          [ 1.9885e+00, -1.7075e+00,  1.9357e+00,  ..., -1.4751e+00,\n",
      "           -1.2131e+00, -6.6433e+00]],\n",
      "\n",
      "         [[-3.6336e-01,  5.4996e-01, -1.0645e+00,  ...,  9.6877e-01,\n",
      "            1.0779e+00, -6.1333e-01],\n",
      "          [-1.3093e+00, -1.0139e+00, -1.2619e+00,  ...,  1.1565e+00,\n",
      "            2.2968e+00, -1.8183e+00],\n",
      "          [-3.8829e-01, -1.9299e+00, -2.3493e+00,  ...,  5.7438e-01,\n",
      "            2.6353e+00, -2.9960e+00],\n",
      "          [ 1.1568e-02, -8.3214e-03,  7.0307e-03,  ...,  3.1393e-03,\n",
      "           -3.1010e-01,  3.6617e-02],\n",
      "          [-2.2716e-01, -8.0065e-01, -7.5105e-01,  ...,  1.2372e+00,\n",
      "            3.9684e+00, -4.2758e+00]],\n",
      "\n",
      "         [[ 8.4888e-01, -2.2967e+00, -4.8551e-01,  ..., -1.4584e+00,\n",
      "            2.0617e+00, -7.5917e-01],\n",
      "          [ 2.2891e-01, -2.3843e+00,  5.1129e-01,  ..., -1.9419e+00,\n",
      "            2.5169e+00,  5.0776e-02],\n",
      "          [-5.5341e-02, -1.6353e+00,  4.5431e-01,  ..., -3.5740e-03,\n",
      "            2.5065e+00, -1.0689e+00],\n",
      "          [-1.2783e-02,  3.9516e-01, -3.2645e-02,  ...,  6.6296e-02,\n",
      "           -9.2626e-02, -1.3887e-02],\n",
      "          [ 8.3548e-01, -2.3454e+00, -2.9998e-01,  ..., -2.0440e-01,\n",
      "            2.0893e+00,  8.0586e-01]]]], grad_fn=<IndexSelectBackward>), '5__encoder_attn__prev_value': tensor([[[[-2.1721e-01, -1.5126e-01,  6.3038e-01,  ..., -1.7051e-01,\n",
      "           -4.8039e-01,  7.9081e-01],\n",
      "          [-2.3470e-01,  1.6298e-01,  1.5582e-01,  ...,  9.3232e-02,\n",
      "            1.3047e-01,  2.3872e-02],\n",
      "          [-2.4549e-01,  2.4977e-01,  6.4769e-01,  ...,  2.0752e-01,\n",
      "           -4.3983e-01,  4.1100e-01],\n",
      "          [ 8.5531e-03,  1.6950e-02,  8.8270e-03,  ...,  9.9072e-03,\n",
      "            3.8505e-02, -7.3747e-03],\n",
      "          [-3.2303e-01, -1.5929e-01,  9.9903e-02,  ..., -3.9910e-02,\n",
      "           -4.8726e-01, -4.3678e-01]],\n",
      "\n",
      "         [[-4.6250e-01,  2.5235e-01,  9.7300e-01,  ...,  1.4390e-01,\n",
      "            1.4704e+00, -3.1966e-01],\n",
      "          [ 9.4433e-02, -1.2836e-01,  4.6117e-01,  ..., -1.8216e-01,\n",
      "            2.6211e-02, -1.0816e+00],\n",
      "          [-2.1813e-01,  9.4156e-02, -3.4232e-01,  ...,  6.7614e-01,\n",
      "            1.1438e+00,  1.3633e-02],\n",
      "          [ 2.1966e-03,  2.9610e-03, -1.2728e-03,  ..., -3.2315e-02,\n",
      "           -5.0070e-03,  2.5475e-02],\n",
      "          [-7.5275e-01,  2.4827e-01, -1.2692e-03,  ...,  4.2435e-01,\n",
      "            3.1436e-01,  2.2942e-01]],\n",
      "\n",
      "         [[-3.1234e-01,  2.3853e-01,  5.2127e-01,  ...,  1.4650e-01,\n",
      "            5.5153e-01, -9.7010e-02],\n",
      "          [ 4.1856e-01, -3.0988e-01,  1.0345e+00,  ...,  9.3154e-01,\n",
      "            3.8513e-01, -1.3460e-01],\n",
      "          [ 1.0192e-01, -4.3030e-01, -1.2950e-01,  ...,  1.3038e-02,\n",
      "            1.0769e-01, -2.1620e-01],\n",
      "          [ 2.2765e-03,  1.7814e-02,  8.8415e-03,  ..., -2.2036e-02,\n",
      "            1.1352e-02,  6.7140e-03],\n",
      "          [ 9.3282e-01,  7.4365e-01,  1.0922e-01,  ...,  6.6498e-01,\n",
      "            9.2072e-01, -5.1262e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2044e-02, -2.1977e-01, -5.9997e-01,  ...,  5.2025e-01,\n",
      "           -2.9360e-01,  2.0359e-01],\n",
      "          [-8.9967e-02, -1.1678e-01, -3.9581e-01,  ..., -5.4780e-01,\n",
      "           -5.4614e-01,  3.7574e-01],\n",
      "          [ 4.8898e-01, -1.0666e+00, -9.3451e-01,  ..., -5.7560e-01,\n",
      "           -2.1537e-01, -3.4227e-01],\n",
      "          [ 1.1287e-02,  1.6932e-02,  3.6352e-03,  ..., -1.8767e-02,\n",
      "           -1.6719e-03,  3.9656e-03],\n",
      "          [ 9.7094e-01,  3.4095e-01,  1.3860e-01,  ..., -6.2563e-01,\n",
      "            3.4506e-01,  1.1781e-01]],\n",
      "\n",
      "         [[ 2.4626e-01,  1.7975e-01,  5.0882e-02,  ...,  8.4062e-02,\n",
      "            1.3168e+00,  9.1353e-01],\n",
      "          [ 7.7475e-02,  7.8285e-01, -8.0990e-01,  ...,  7.0785e-01,\n",
      "            9.6067e-01,  4.0246e-03],\n",
      "          [ 4.4241e-01,  8.2381e-01, -8.5753e-03,  ...,  7.1722e-01,\n",
      "            1.1321e+00, -1.3981e-01],\n",
      "          [-1.3932e-02, -2.9827e-04,  2.2964e-02,  ..., -1.0902e-02,\n",
      "           -2.1063e-03,  2.7722e-03],\n",
      "          [ 4.4584e-01, -3.8651e-02, -1.2052e+00,  ...,  2.6291e-01,\n",
      "            1.9802e+00,  4.0413e-01]],\n",
      "\n",
      "         [[ 9.1859e-01, -1.2503e-01, -2.5971e-01,  ...,  7.4725e-01,\n",
      "           -1.2594e+00, -1.5234e+00],\n",
      "          [ 1.9281e+00, -2.6035e-01,  3.5881e-01,  ...,  1.1932e+00,\n",
      "           -1.2272e+00, -5.3000e-01],\n",
      "          [ 7.2332e-01,  9.5184e-01, -4.1460e-01,  ...,  1.1524e+00,\n",
      "           -8.8293e-01, -9.9932e-01],\n",
      "          [-2.8140e-02, -4.8690e-04,  1.4991e-02,  ..., -5.6142e-02,\n",
      "            2.0635e-02,  9.7332e-03],\n",
      "          [-4.4921e-01,  1.1392e+00,  5.6474e-01,  ..., -4.6573e-01,\n",
      "           -5.5819e-01, -7.4457e-01]]]], grad_fn=<IndexSelectBackward>), '5__encoder_attn__prev_mask': tensor([[True, True, True, True, True]]), '6__self_attn__prev_key': tensor([[[[ 0.3758,  0.8805,  0.3438,  ..., -0.1544,  0.6735, -0.0801],\n",
      "          [ 0.1797,  0.8363, -0.0087,  ..., -0.1712,  0.7956, -0.0932]],\n",
      "\n",
      "         [[-0.9404,  0.0080,  0.6180,  ...,  0.1837,  0.1204, -0.3464],\n",
      "          [-1.2537, -0.2111,  0.7381,  ...,  0.2934,  0.0686, -0.4125]],\n",
      "\n",
      "         [[ 2.6560, -0.6246, -1.2975,  ..., -0.3130,  0.0351,  0.2290],\n",
      "          [ 3.1777, -0.4636, -0.8024,  ..., -0.4783, -0.3857,  0.0462]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1677, -2.2412, -3.0517,  ...,  0.3752, -1.2102, -0.5146],\n",
      "          [ 0.1961, -1.9650, -3.0309,  ...,  0.3644, -1.4294, -0.5198]],\n",
      "\n",
      "         [[-1.5151, -0.3923,  0.7391,  ...,  2.6836, -0.7662,  0.5433],\n",
      "          [-1.7778, -0.3566,  0.7741,  ...,  2.6747, -0.7715,  0.4138]],\n",
      "\n",
      "         [[-1.2390,  1.0126, -0.0579,  ...,  0.1683, -0.9763,  2.6571],\n",
      "          [-0.5498,  1.0424, -0.0655,  ...,  0.3838, -1.0321,  2.2479]]]],\n",
      "       grad_fn=<IndexSelectBackward>), '6__self_attn__prev_value': tensor([[[[-0.4101,  1.0559,  0.3640,  ..., -0.3458,  0.5863,  0.3005],\n",
      "          [-0.6197,  1.0711,  0.3859,  ..., -0.3175,  0.6459,  0.4601]],\n",
      "\n",
      "         [[ 0.6310,  0.9407, -0.2614,  ...,  0.7195, -0.4408, -1.2345],\n",
      "          [ 0.5217,  1.0144, -0.0730,  ...,  0.6506, -0.4703, -1.0726]],\n",
      "\n",
      "         [[-0.3132, -0.4040, -0.4301,  ..., -0.2290,  0.4857,  0.0123],\n",
      "          [-0.4547, -0.0700, -0.3777,  ..., -0.2385,  0.3450,  0.0098]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3645, -0.0806, -0.7158,  ...,  0.4864, -0.2395,  1.2035],\n",
      "          [ 0.2523, -0.2302, -0.8798,  ...,  0.3634, -0.1459,  1.0887]],\n",
      "\n",
      "         [[-0.5497, -0.4699, -1.0743,  ...,  1.2439,  1.4610,  0.4592],\n",
      "          [-0.5899, -0.4935, -1.1370,  ...,  1.3571,  1.3672,  0.2401]],\n",
      "\n",
      "         [[-0.1040, -0.1777,  0.1593,  ..., -1.0436, -1.3599,  0.0231],\n",
      "          [-0.0422, -0.0832,  0.1300,  ..., -0.9762, -1.3410, -0.0241]]]],\n",
      "       grad_fn=<IndexSelectBackward>), '6__self_attn__prev_mask': tensor([[[1., 0.],\n",
      "         [1., 1.]]]), '6__encoder_attn__prev_key': tensor([[[[-1.4601e+00, -6.5321e-02, -5.1774e-01,  ..., -1.8178e+00,\n",
      "            5.1538e-03,  2.3640e-01],\n",
      "          [-2.5309e+00,  1.0689e+00,  6.9829e-01,  ..., -1.2592e+00,\n",
      "           -8.1195e-01,  3.6958e-01],\n",
      "          [-1.1162e+00,  9.3734e-02, -1.6745e-01,  ..., -3.5095e+00,\n",
      "           -5.9077e-01, -1.3575e-01],\n",
      "          [ 3.5768e-02,  8.9514e-02,  6.3063e-03,  ...,  2.1286e-01,\n",
      "           -9.1095e-03, -4.9402e-03],\n",
      "          [-7.3549e-01, -3.9318e-01,  1.2954e+00,  ..., -4.0696e+00,\n",
      "           -7.6235e-01, -5.4790e-01]],\n",
      "\n",
      "         [[-7.6212e-01, -3.9502e-02,  5.5700e-01,  ..., -8.0818e-01,\n",
      "            5.7387e-01, -1.3641e+00],\n",
      "          [ 8.4698e-01,  2.2103e-01,  3.8729e-01,  ..., -6.9852e-01,\n",
      "            1.6176e+00, -1.5610e+00],\n",
      "          [ 4.8110e-01,  2.0563e+00,  3.3124e+00,  ..., -2.3130e+00,\n",
      "            3.8132e-01, -3.2432e+00],\n",
      "          [ 2.0702e-02,  3.1506e-02, -6.0797e-02,  ...,  1.1226e-01,\n",
      "           -5.8457e-02,  4.8176e-01],\n",
      "          [-3.5372e-01,  6.3371e-01,  1.4895e+00,  ..., -4.1899e+00,\n",
      "           -1.2224e+00, -2.8658e+00]],\n",
      "\n",
      "         [[ 1.7094e+00,  1.9531e-01,  2.2854e+00,  ..., -1.6879e+00,\n",
      "           -3.8495e+00, -1.6829e+00],\n",
      "          [ 1.8837e-01, -2.9647e+00,  1.0652e+00,  ..., -2.6411e+00,\n",
      "           -2.7394e+00, -7.2048e-01],\n",
      "          [ 5.7344e-01, -1.6601e+00,  2.1297e+00,  ..., -1.7608e+00,\n",
      "           -4.0574e+00,  3.5278e-01],\n",
      "          [-1.1742e-01,  2.9136e-01, -1.1749e-01,  ...,  4.8722e-01,\n",
      "            5.2007e-01, -1.0553e-01],\n",
      "          [-2.1817e+00, -3.0494e+00,  3.0533e+00,  ..., -4.6492e-01,\n",
      "           -4.5735e+00,  1.0643e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1098e+00, -1.3993e+00, -6.4041e-01,  ...,  1.3862e+00,\n",
      "            1.8589e+00,  2.6206e+00],\n",
      "          [-5.0081e-01, -2.5990e+00, -6.0511e-01,  ...,  1.3649e+00,\n",
      "            4.0951e-01,  4.0517e+00],\n",
      "          [ 1.5227e+00, -2.2480e+00, -1.3019e+00,  ...,  1.3857e+00,\n",
      "           -2.4791e-01,  5.2506e+00],\n",
      "          [-3.9230e-02,  3.0873e-01, -3.9186e-02,  ...,  3.2549e-02,\n",
      "            4.7012e-02, -5.4446e-01],\n",
      "          [ 1.1732e+00, -2.6154e+00, -7.4511e-01,  ...,  1.5918e+00,\n",
      "           -8.9785e-01,  5.3765e+00]],\n",
      "\n",
      "         [[ 1.6488e-02, -1.1592e-03,  1.6951e+00,  ...,  2.0333e+00,\n",
      "           -1.8810e-01, -6.0648e-02],\n",
      "          [-7.3335e-01, -7.5494e-01,  1.4352e+00,  ...,  2.7908e+00,\n",
      "           -1.0110e+00, -1.9535e+00],\n",
      "          [ 1.6060e-01, -1.2675e+00,  1.9131e+00,  ...,  3.3674e+00,\n",
      "           -2.3074e+00, -8.6903e-01],\n",
      "          [-3.1907e-02, -1.1663e-02, -1.0456e-01,  ..., -3.7567e-01,\n",
      "            2.2686e-01,  4.1945e-02],\n",
      "          [-1.2898e+00, -9.8089e-01,  1.4235e+00,  ...,  3.4498e+00,\n",
      "           -4.4196e+00, -7.3088e-01]],\n",
      "\n",
      "         [[ 1.4161e+00, -1.5339e+00, -4.1701e+00,  ...,  1.9180e-01,\n",
      "            1.2204e+00, -1.1835e+00],\n",
      "          [-8.0586e-01, -9.1467e-02, -4.1442e+00,  ..., -7.2027e-01,\n",
      "            2.8934e+00, -1.2617e+00],\n",
      "          [ 2.0711e+00,  5.4678e-01, -4.8819e+00,  ..., -2.1694e+00,\n",
      "            3.0833e+00, -1.9050e+00],\n",
      "          [-2.0839e-02,  6.4290e-02,  3.2878e-01,  ...,  2.6330e-02,\n",
      "           -2.4035e-01,  1.4724e-01],\n",
      "          [ 1.7209e+00, -1.6996e+00, -9.3121e+00,  ..., -2.7825e+00,\n",
      "            2.5016e+00, -1.3739e+00]]]], grad_fn=<IndexSelectBackward>), '6__encoder_attn__prev_value': tensor([[[[ 9.7737e-01, -9.9259e-01, -1.7915e-01,  ...,  4.6994e-01,\n",
      "            9.5500e-02,  2.4052e-01],\n",
      "          [ 5.1677e-01, -8.1215e-01,  6.8715e-01,  ..., -7.0360e-01,\n",
      "            6.7980e-01, -1.0801e-01],\n",
      "          [ 5.6576e-01, -1.6074e+00,  2.9598e-01,  ..., -5.9887e-01,\n",
      "            6.0744e-01,  4.4376e-01],\n",
      "          [-8.6616e-03,  8.3049e-02,  4.5608e-04,  ...,  1.2392e-02,\n",
      "           -3.0989e-02, -1.9062e-02],\n",
      "          [-1.4916e-02, -1.5387e+00, -2.1344e-02,  ..., -2.0219e-01,\n",
      "           -3.4053e-01,  2.5980e-01]],\n",
      "\n",
      "         [[ 2.4356e-01,  3.4693e-01,  1.0629e+00,  ...,  2.9271e-02,\n",
      "           -2.5819e-01,  8.8972e-02],\n",
      "          [ 6.9336e-01,  2.7380e-01,  6.1980e-01,  ..., -5.1002e-01,\n",
      "           -3.9441e-01,  1.5593e-02],\n",
      "          [ 7.3572e-01,  8.1712e-02, -1.2694e-01,  ...,  4.5650e-02,\n",
      "            1.2268e-01,  7.0912e-01],\n",
      "          [-6.8384e-03,  4.2410e-02, -7.9309e-03,  ...,  1.5568e-02,\n",
      "           -4.8706e-03,  1.2065e-02],\n",
      "          [ 3.3479e-01,  2.6660e-01, -2.3706e-01,  ..., -7.5265e-01,\n",
      "           -3.6387e-01,  5.8886e-01]],\n",
      "\n",
      "         [[-5.1874e-01, -1.1776e-01, -2.3540e-01,  ...,  4.7514e-01,\n",
      "           -8.4697e-01,  2.1436e-01],\n",
      "          [ 5.5537e-01,  5.8919e-01, -5.3879e-02,  ...,  8.1907e-02,\n",
      "           -6.7041e-01,  2.2970e-01],\n",
      "          [-2.5312e-01,  2.9218e-01, -2.6036e-01,  ..., -5.9548e-02,\n",
      "           -1.2427e+00, -1.6180e-01],\n",
      "          [-3.4120e-02,  5.1561e-03,  2.3004e-02,  ...,  1.2542e-02,\n",
      "            3.4265e-02, -3.7325e-02],\n",
      "          [ 4.1301e-01, -1.1452e-01,  1.1197e-02,  ...,  7.3436e-01,\n",
      "           -1.4497e+00,  1.5993e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.9300e-01, -2.3003e-01, -6.3812e-02,  ...,  2.5278e-01,\n",
      "           -4.5957e-01,  5.4036e-01],\n",
      "          [ 2.4641e-01,  1.5642e-01, -3.8222e-01,  ..., -1.9820e-01,\n",
      "            9.3251e-02, -1.4596e-01],\n",
      "          [ 8.2585e-01,  3.8276e-01,  1.3724e-01,  ...,  2.2744e-01,\n",
      "            8.2997e-01, -3.8407e-01],\n",
      "          [ 1.1045e-03, -1.5486e-03, -1.6206e-02,  ...,  2.7958e-02,\n",
      "           -2.6925e-03, -2.7443e-04],\n",
      "          [ 9.0545e-01,  8.6998e-01, -5.0828e-01,  ...,  6.1552e-02,\n",
      "            6.8552e-01, -1.5350e-01]],\n",
      "\n",
      "         [[-3.9709e-01,  8.6887e-01, -1.0607e-01,  ..., -6.3676e-01,\n",
      "            7.4729e-01, -8.4614e-01],\n",
      "          [ 3.1261e-01,  1.3206e-01,  2.5194e-01,  ..., -3.4014e-01,\n",
      "            9.5339e-01, -4.8826e-01],\n",
      "          [-1.1702e-01,  8.0298e-01, -1.2873e-01,  ...,  3.5878e-01,\n",
      "            6.9935e-01, -2.6423e-01],\n",
      "          [-5.1031e-03, -3.3540e-02, -5.3112e-02,  ..., -2.9997e-02,\n",
      "           -5.2329e-03,  1.8044e-03],\n",
      "          [ 4.6843e-01, -1.2230e-02, -1.3171e-01,  ...,  2.3573e-01,\n",
      "            1.2950e+00, -1.8351e-01]],\n",
      "\n",
      "         [[-9.7519e-01,  3.8738e-01, -1.4861e-01,  ..., -3.9567e-01,\n",
      "           -7.7892e-02, -7.3970e-01],\n",
      "          [-1.2318e+00,  3.2854e-02, -3.1075e-02,  ...,  1.7746e-01,\n",
      "           -1.8298e-01, -3.0595e-01],\n",
      "          [-4.5577e-01, -2.3398e-01,  3.0753e-01,  ...,  1.4202e-01,\n",
      "           -1.9586e-01,  7.2810e-01],\n",
      "          [ 2.5297e-03, -7.6125e-02,  8.0394e-03,  ..., -3.8160e-02,\n",
      "            1.9951e-02,  3.5467e-02],\n",
      "          [-4.2801e-01,  3.2265e-01, -1.1920e+00,  ..., -2.3279e-02,\n",
      "           -1.7041e-01, -2.1803e-01]]]], grad_fn=<IndexSelectBackward>), '6__encoder_attn__prev_mask': tensor([[True, True, True, True, True]]), '7__self_attn__prev_key': tensor([[[[ 0.4868, -0.5112, -0.7662,  ...,  1.0295,  0.3782,  1.0968],\n",
      "          [ 0.3825, -0.4029, -0.9058,  ...,  1.2169,  0.3905,  1.1511]],\n",
      "\n",
      "         [[ 0.4586,  1.0890, -0.0511,  ...,  0.7061,  0.2887,  1.4786],\n",
      "          [ 0.7003,  1.3236, -0.1535,  ...,  0.6672,  0.3542,  1.6006]],\n",
      "\n",
      "         [[-1.0203,  0.9473,  0.5890,  ..., -0.1703, -0.2133,  0.8280],\n",
      "          [-1.0871,  0.7503,  0.4991,  ...,  0.1891, -0.1204,  1.1038]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4130, -0.5666, -0.2936,  ..., -0.5305, -1.7651,  0.1648],\n",
      "          [ 1.3187, -0.6009, -0.4661,  ..., -0.8430, -1.7225,  0.2076]],\n",
      "\n",
      "         [[-0.3356,  0.1041, -0.0918,  ...,  0.4240, -0.5197, -0.4573],\n",
      "          [-0.5389,  0.3135,  0.0799,  ...,  0.5790, -0.5431, -0.6037]],\n",
      "\n",
      "         [[-3.4585, -0.2322, -0.5519,  ..., -0.2926,  1.3681,  1.3178],\n",
      "          [-3.4237, -0.1558, -0.7058,  ..., -0.4531,  1.3064,  1.3825]]]],\n",
      "       grad_fn=<IndexSelectBackward>), '7__self_attn__prev_value': tensor([[[[ 0.1673,  0.6129, -0.1494,  ..., -0.1810,  0.1137,  0.8694],\n",
      "          [ 0.0083,  0.6966, -0.1497,  ..., -0.3364,  0.1426,  0.7727]],\n",
      "\n",
      "         [[-0.6871,  0.3178, -0.1474,  ...,  0.1994,  0.0133, -0.5012],\n",
      "          [-0.6819,  0.4203, -0.2084,  ...,  0.2493, -0.0693, -0.4694]],\n",
      "\n",
      "         [[ 0.1024, -0.0714, -0.0415,  ..., -0.1235,  0.4967,  0.1880],\n",
      "          [ 0.0443, -0.1052, -0.0571,  ..., -0.1821,  0.5512,  0.0919]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6348,  0.2271, -0.1638,  ..., -0.7224, -0.3428, -0.6264],\n",
      "          [ 0.6779,  0.3193, -0.0635,  ..., -0.7028, -0.1790, -0.5568]],\n",
      "\n",
      "         [[-0.1844,  0.2917,  0.3368,  ...,  0.1096, -0.8224, -0.0121],\n",
      "          [-0.1420,  0.1844,  0.3276,  ...,  0.0578, -0.8131,  0.1973]],\n",
      "\n",
      "         [[ 0.2929,  0.3154,  0.1712,  ..., -0.1886,  0.0098,  0.3388],\n",
      "          [ 0.2787,  0.2729,  0.1929,  ..., -0.3281, -0.0092,  0.4337]]]],\n",
      "       grad_fn=<IndexSelectBackward>), '7__self_attn__prev_mask': tensor([[[1., 0.],\n",
      "         [1., 1.]]]), '7__encoder_attn__prev_key': tensor([[[[ 6.3405e-01, -3.6159e+00,  1.2722e-01,  ..., -2.0223e+00,\n",
      "           -3.2174e+00,  1.5065e+00],\n",
      "          [ 1.6878e+00, -4.4559e+00, -1.5222e+00,  ...,  1.3157e+00,\n",
      "           -1.5305e+00,  9.4984e-02],\n",
      "          [-1.5209e-01, -6.4104e+00,  5.1678e-02,  ..., -6.1449e-01,\n",
      "           -2.4941e+00, -1.9268e-01],\n",
      "          [-1.3163e-01,  3.4943e-01, -7.3069e-02,  ...,  3.2072e-02,\n",
      "           -4.8927e-02,  1.5045e-01],\n",
      "          [ 9.7656e-01, -4.9544e+00,  9.6376e-01,  ..., -1.4318e+00,\n",
      "           -8.6115e-01, -3.7879e+00]],\n",
      "\n",
      "         [[-8.3556e-01, -1.7400e+00, -3.0891e+00,  ...,  1.9325e-01,\n",
      "           -3.1691e-01, -3.2949e+00],\n",
      "          [-7.1137e-01,  2.0468e-01, -1.6997e+00,  ..., -3.7707e-01,\n",
      "            2.6755e+00, -2.2439e+00],\n",
      "          [-4.1288e-01, -5.0275e-01, -9.2701e-01,  ...,  5.9234e-01,\n",
      "           -6.9937e-01, -4.0385e+00],\n",
      "          [ 5.5449e-02, -1.6167e-01, -1.8765e-02,  ...,  5.8835e-02,\n",
      "            7.5083e-02,  1.2699e-01],\n",
      "          [-1.7057e+00,  2.5255e-01, -1.3213e+00,  ...,  6.3273e-01,\n",
      "            2.1269e+00, -3.5664e+00]],\n",
      "\n",
      "         [[-1.8079e+00, -1.0517e+00, -1.8605e+00,  ..., -1.1903e-01,\n",
      "            1.2402e+00, -8.3567e-01],\n",
      "          [-1.2061e+00, -4.1275e+00,  5.0950e-01,  ..., -7.9740e-02,\n",
      "            1.9341e+00, -7.7256e-01],\n",
      "          [-7.7308e-01, -1.1772e+00, -1.9815e+00,  ...,  1.2378e+00,\n",
      "            1.6122e+00,  7.4533e-01],\n",
      "          [ 4.3312e-02,  2.4832e-02,  1.0517e-01,  ..., -1.1564e-01,\n",
      "           -1.7755e-01, -8.4101e-03],\n",
      "          [-1.2733e+00, -3.4052e+00,  8.3308e-01,  ..., -6.9744e-01,\n",
      "            1.6208e+00, -1.2924e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0787e+00, -6.8840e-01,  1.3770e+00,  ...,  2.2860e+00,\n",
      "            1.7251e+00,  1.1800e+00],\n",
      "          [-5.1298e+00,  8.9760e-02,  5.5832e-01,  ...,  2.6931e+00,\n",
      "            1.1408e+00, -7.9936e-01],\n",
      "          [-5.5329e+00, -1.2250e-01,  2.2795e+00,  ...,  4.6407e+00,\n",
      "           -1.4752e-02, -6.2759e-01],\n",
      "          [ 3.1569e-01, -1.0035e-01, -1.5551e-01,  ..., -1.8689e-01,\n",
      "            1.4520e-02,  1.2541e-01],\n",
      "          [-6.0707e+00,  4.5120e-01,  1.2894e+00,  ...,  2.6032e+00,\n",
      "           -1.7458e+00,  8.3117e-01]],\n",
      "\n",
      "         [[ 1.1868e+00,  1.3376e-01,  1.1830e+00,  ..., -1.4727e+00,\n",
      "           -2.3988e+00, -4.2508e+00],\n",
      "          [ 1.1628e+00,  4.0501e-01,  9.8790e-01,  ..., -8.8960e-01,\n",
      "           -1.7434e+00, -5.6830e+00],\n",
      "          [ 1.2657e+00,  8.4189e-01, -2.5029e-01,  ...,  1.0826e+00,\n",
      "           -2.7807e+00, -2.9702e+00],\n",
      "          [-3.6300e-02, -1.2779e-01,  5.1744e-02,  ...,  5.2536e-02,\n",
      "            5.5379e-03,  4.4744e-01],\n",
      "          [ 1.3616e+00,  1.7209e+00, -1.9440e+00,  ..., -3.5506e+00,\n",
      "           -1.6667e+00, -4.0851e+00]],\n",
      "\n",
      "         [[ 8.5440e-01, -1.0003e-01, -6.1618e-02,  ...,  2.5925e+00,\n",
      "            2.8902e+00,  1.7846e+00],\n",
      "          [-2.5594e-01, -1.1963e+00, -2.9267e-01,  ...,  2.2866e+00,\n",
      "            6.4973e-01,  2.3088e+00],\n",
      "          [ 2.4426e-01, -1.3514e+00, -5.9638e-01,  ...,  2.0924e+00,\n",
      "            1.1353e+00,  1.9129e+00],\n",
      "          [-2.2864e-01, -1.1322e-01,  2.4561e-01,  ..., -2.9194e-01,\n",
      "           -6.1373e-02, -3.6973e-01],\n",
      "          [ 2.2264e+00,  1.8299e+00, -4.1506e-02,  ...,  3.8988e+00,\n",
      "            2.9727e+00,  2.3398e+00]]]], grad_fn=<IndexSelectBackward>), '7__encoder_attn__prev_value': tensor([[[[-4.1114e-02, -2.3658e-01, -1.6712e-01,  ...,  3.4247e-01,\n",
      "            3.7681e-01, -2.1711e-01],\n",
      "          [-8.6603e-02,  4.8581e-01, -3.3732e-02,  ...,  1.9390e-01,\n",
      "            1.4925e-01, -1.0201e-01],\n",
      "          [-9.6159e-03,  2.4050e-01, -4.1712e-01,  ..., -9.8717e-03,\n",
      "           -6.2367e-01,  2.7479e-01],\n",
      "          [ 7.3209e-02, -2.6399e-02,  2.4086e-02,  ...,  1.1072e-02,\n",
      "           -1.0422e-02, -3.6056e-02],\n",
      "          [ 8.0874e-02,  2.4510e-02, -5.5766e-01,  ..., -6.4520e-01,\n",
      "           -6.6824e-01, -1.1071e+00]],\n",
      "\n",
      "         [[ 2.3804e-01,  6.4134e-01,  2.9661e-01,  ...,  4.6389e-01,\n",
      "            1.5459e-01,  6.6346e-01],\n",
      "          [ 4.5180e-02, -4.0549e-01,  2.4435e-01,  ..., -5.9500e-01,\n",
      "           -3.2494e-02,  8.8981e-02],\n",
      "          [-1.1677e+00,  1.7767e-01,  4.9638e-01,  ..., -5.1818e-01,\n",
      "           -3.5694e-01, -7.6399e-01],\n",
      "          [-1.8739e-02, -1.7919e-02, -2.4790e-02,  ..., -3.4414e-03,\n",
      "           -1.8581e-02, -9.1577e-03],\n",
      "          [-6.6849e-01,  7.2503e-01, -4.7265e-01,  ..., -9.4766e-01,\n",
      "            4.4257e-01, -1.0430e+00]],\n",
      "\n",
      "         [[ 6.9931e-01, -7.9438e-02, -1.0113e+00,  ...,  3.9204e-01,\n",
      "            1.2386e-01,  1.2242e-01],\n",
      "          [ 3.7744e-01,  1.4839e-01, -9.6952e-02,  ..., -1.8000e-01,\n",
      "           -2.1679e-01, -2.7378e-01],\n",
      "          [ 9.2701e-02, -8.9791e-01, -1.2360e-01,  ..., -7.5696e-01,\n",
      "           -4.2598e-01, -2.4252e-01],\n",
      "          [-1.2998e-02,  8.6156e-03, -6.0262e-03,  ...,  3.1297e-03,\n",
      "            7.5816e-03,  2.8478e-04],\n",
      "          [ 5.4047e-01, -5.9278e-04,  6.2730e-01,  ...,  1.9880e-01,\n",
      "            9.0477e-01,  5.3370e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.5318e-01, -5.6508e-01,  4.9839e-01,  ..., -2.7240e-01,\n",
      "            9.1354e-03,  5.1398e-01],\n",
      "          [-7.8642e-01,  1.2710e-01,  3.1706e-01,  ..., -6.0018e-01,\n",
      "           -7.3406e-01, -2.3126e-01],\n",
      "          [-1.0926e+00,  1.3344e+00, -7.6505e-01,  ...,  3.7456e-01,\n",
      "           -4.0628e-01, -7.7471e-01],\n",
      "          [-1.0751e-02, -2.0634e-02,  1.1939e-01,  ...,  4.4739e-02,\n",
      "            5.4975e-02,  3.5818e-02],\n",
      "          [-1.0858e+00, -6.8404e-01,  5.0941e-01,  ..., -1.9992e-01,\n",
      "           -1.2097e+00, -1.1311e+00]],\n",
      "\n",
      "         [[ 8.5031e-02, -4.8058e-01,  7.3175e-01,  ...,  6.8781e-01,\n",
      "            2.1995e-03,  1.2659e-01],\n",
      "          [ 5.6762e-03,  2.5884e-01,  8.1863e-01,  ...,  3.8716e-02,\n",
      "           -7.8175e-01, -2.3001e-01],\n",
      "          [ 3.6676e-03, -5.2961e-01,  6.3691e-01,  ..., -1.0774e+00,\n",
      "            3.9658e-02,  3.1479e-01],\n",
      "          [ 7.1368e-02, -4.1056e-03,  1.7633e-02,  ...,  5.4849e-02,\n",
      "           -2.1995e-03,  3.1357e-02],\n",
      "          [ 3.4746e-01, -1.3606e+00, -5.0207e-02,  ...,  6.0939e-02,\n",
      "            1.2015e+00, -9.7178e-01]],\n",
      "\n",
      "         [[ 3.5802e-01, -6.0569e-01, -1.3784e-01,  ..., -1.7791e-01,\n",
      "           -5.4938e-01,  4.8994e-01],\n",
      "          [ 6.8786e-01,  5.8585e-01, -7.7855e-01,  ...,  5.2948e-01,\n",
      "           -3.3779e-01,  4.8327e-01],\n",
      "          [ 7.2193e-01, -1.4041e-01, -9.4647e-01,  ...,  1.1393e-01,\n",
      "           -8.7672e-01,  3.7745e-01],\n",
      "          [ 5.5850e-03,  1.5181e-02,  7.2417e-02,  ..., -1.3206e-02,\n",
      "            2.2204e-02,  4.5133e-02],\n",
      "          [ 1.0005e+00,  1.0307e+00, -6.6508e-02,  ...,  3.5714e-01,\n",
      "           -1.6264e-01,  1.0531e+00]]]], grad_fn=<IndexSelectBackward>), '7__encoder_attn__prev_mask': tensor([[True, True, True, True, True]])}\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "torch.cat(): Sizes of tensors must match except in dimension 2. Got 2 and 1 in dimension 1 (The offending index is 1)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d68bd09b4414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexport_emely\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/scripts/torchscript.py\u001b[0m in \u001b[0;36mexport_emely\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0msbpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseparator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@@\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbpe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msbpe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0moriginal_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchScriptGreedySearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# Script the module and save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/torchscript/modules_emely.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, agent)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincr_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         self.decoder_later_pass = torch.jit.trace(\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mwrapped_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincr_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m         return trace_module(\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0;34m\"forward\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             module._c._create_method_from_trace(\n\u001b[0m\u001b[1;32m    953\u001b[0m                 \u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/torchscript/modules_emely.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, encoder_state, flat_incr_state)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mstructured_incr_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         tensor, new_structured_incr_state = self.module.forward(\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincr_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstructured_incr_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         )\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/agents/transformer/modules/decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, encoder_state, incr_state)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# --dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         tensor, new_incr_state = self.forward_layers(\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincr_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         )\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/agents/transformer/modules/decoder.py\u001b[0m in \u001b[0;36mforward_layers\u001b[0;34m(self, tensor, encoder_output, encoder_mask, incr_state)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 tensor, new_incr_state[idx] = layer(\n\u001b[0m\u001b[1;32m    189\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                     \u001b[0mencoder_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/agents/transformer/modules/decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, encoder_output, encoder_mask, incr_state)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;31m# don't peak into the future!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         x, final_self_attn_incr_state = self.self_attention(\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/agents/transformer/modules/attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask, incr_state, static_kv)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mincr_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prev_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mincr_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prev_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# Prepend along the key_len dimension (analogous to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# incr_state['prev_key'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch.cat(): Sizes of tensors must match except in dimension 2. Got 2 and 1 in dimension 1 (The offending index is 1)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Create model to test tokenization etc\n",
    "emely_agent = EmelyAgent(opt)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "08:12:05 | loading dictionary from /home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model.dict\n",
      "08:12:05 | num words = 54944\n",
      "08:12:06 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
      "08:12:06 | Loading existing model params from /home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from parlai.utils.bpe import SubwordBPEHelper\n",
    "from parlai.torchscript.modules_emely import ScriptableSubwordBpeHelper\n",
    "sbpe = SubwordBPEHelper(emely_agent.opt)\n",
    "joint_bpe_codes = {}\n",
    "for k in sbpe.bpe.bpe_codes.keys():\n",
    "    joint_bpe_codes[emely_agent.opt[\"temp_separator\"].join(k)] = sbpe.bpe.bpe_codes[k]\n",
    "ssbpe = ScriptableSubwordBpeHelper(True, joint_bpe_codes, sbpe.bpe.separator, emely_agent.opt[\"temp_separator\"])\n",
    "o1 = sbpe.encode(\"Hi! What is your name?\\nI'm Christoffer.\")\n",
    "o2 = ssbpe.helper_encode(\"Hi! What is your name?\\nI'm Christoffer.\")\n",
    "print(o1)\n",
    "print(o2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['H@@', 'i', '!', 'W@@', 'hat', 'is', 'your', 'name', '?', '__newln__', 'I', \"'\", 'm', 'C@@', 'h@@', 'ri@@', 'st@@', 'offer', '.']\n",
      "['H@@', 'i', '!', 'W@@', 'hat', 'is', 'your', 'name', '?', '__newln__', 'I', \"'\", 'm', 'C@@', 'h@@', 'ri@@', 'st@@', 'offer', '.']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('emelymodels': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "f8da2b72f9ac3c32718e899b9529d2abac5ccc10881893810be77cced976bf1a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}