{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from parlai.core.agents import create_agent\n",
    "from parlai.agents.emely.emely import EmelyAgent\n",
    "from parlai.core.opt import Opt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from parlai.scripts.torchscript import export_emely\n",
    "from parlai.core.agents import create_agent\n",
    "\n",
    "# Initialize model settings\n",
    "\n",
    "model_path = Path.cwd() / 'data/models/blender/blender_90M/'\n",
    "assert model_path.is_dir()\n",
    "\n",
    "opt_path = model_path / 'model.opt'\n",
    "opt = Opt.load(opt_path)\n",
    "\n",
    "# Change opts\n",
    "opt['skip_generation'] = False\n",
    "opt['init_model'] = (model_path / 'model').as_posix()\n",
    "opt['no_cuda'] = True  # Cloud run doesn't offer gpu support\n",
    "\n",
    "# Inference options\n",
    "opt['inference'] = 'beam' # 'beam' 'greedy'\n",
    "opt['beam_size'] = 10\n",
    "\n",
    "opt[\"scripted_model_file\"] = \"../../saved_models/emely_scripted_test.pt\"\n",
    "opt[\"script-module\"] = \"parlai.torchscript.modules:TorchScriptGreedySearch\"\n",
    "opt[\"model_file\"] = opt[\"init_model\"]\n",
    "\n",
    "opt[\"temp_separator\"] = \"__space__\"\n",
    "\n",
    "opt[\"bpe_add_prefix_space\"] = False\n",
    "\n",
    "opt[\"input\"] = \"Hi! What do you like to do?\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Test exporting to torchscript\n",
    "original_module, scripted_module = export_emely(opt)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16:39:42 | loading dictionary from /home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model.dict\n",
      "16:39:43 | num words = 54944\n",
      "16:39:44 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
      "16:39:44 | Loading existing model params from /home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model\n",
      "\n",
      "Generating given the original unscripted module:\n",
      " TEXT: Hi! What do you like to do?\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n/home/ckjellson/code/emely-models/ParlAI/parlai/agents/transformer/modules/attention.py(190): forward\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py(1039): _slow_forward\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py(1051): _call_impl\n/home/ckjellson/code/emely-models/ParlAI/parlai/agents/transformer/modules/decoder.py(345): forward\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py(1039): _slow_forward\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py(1051): _call_impl\n/home/ckjellson/code/emely-models/ParlAI/parlai/agents/transformer/modules/decoder.py(188): forward_layers\n/home/ckjellson/code/emely-models/ParlAI/parlai/agents/transformer/modules/decoder.py(233): forward\n/home/ckjellson/code/emely-models/ParlAI/parlai/torchscript/modules_emely.py(445): forward\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py(1039): _slow_forward\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py(1051): _call_impl\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/jit/_trace.py(952): trace_module\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/jit/_trace.py(735): trace\n/home/ckjellson/code/emely-models/ParlAI/parlai/torchscript/modules_emely.py(139): __init__\n/home/ckjellson/code/emely-models/ParlAI/parlai/scripts/torchscript.py(115): export_emely\n<ipython-input-8-89f3478722e0>(2): <module>\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3441): run_code\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3361): run_ast_nodes\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3169): run_cell_async\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/IPython/core/async_helpers.py(68): _pseudo_sync_runner\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2944): _run_cell\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2898): run_cell\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/ipykernel/zmqshell.py(536): run_cell\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/ipykernel/ipkernel.py(306): do_execute\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/tornado/gen.py(234): wrapper\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/ipykernel/kernelbase.py(543): execute_request\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/tornado/gen.py(234): wrapper\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/ipykernel/kernelbase.py(268): dispatch_shell\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/tornado/gen.py(234): wrapper\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/ipykernel/kernelbase.py(365): process_one\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/tornado/gen.py(775): run\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/tornado/gen.py(814): inner\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/tornado/ioloop.py(741): _run_callback\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/tornado/ioloop.py(688): <lambda>\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/asyncio/events.py(81): _run\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/asyncio/base_events.py(1859): _run_once\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/asyncio/base_events.py(570): run_forever\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/tornado/platform/asyncio.py(199): start\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/ipykernel/kernelapp.py(612): start\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/traitlets/config/application.py(845): launch_instance\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/ipykernel_launcher.py(16): <module>\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/runpy.py(87): _run_code\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/runpy.py(194): _run_module_as_main\nRuntimeError: shape '[160, -1, 32]' is invalid for input of size 512\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-89f3478722e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test exporting to torchscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moriginal_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscripted_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexport_emely\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/scripts/torchscript.py\u001b[0m in \u001b[0;36mexport_emely\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nGenerating given the original unscripted module:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0m_run_conversation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nGenerating given the scripted module:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0m_run_conversation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscripted_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/scripts/torchscript.py\u001b[0m in \u001b[0;36m_run_conversation\u001b[0;34m(module, inputs)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' TEXT: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LABEL: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/torchscript/modules_emely.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, context, max_len)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 )\n\u001b[1;32m    241\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                 score, incr_state = self.decoder_later_pass(\n\u001b[0m\u001b[1;32m    243\u001b[0m                     \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincr_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n/home/ckjellson/code/emely-models/ParlAI/parlai/agents/transformer/modules/attention.py(190): forward\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py(1039): _slow_forward\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py(1051): _call_impl\n/home/ckjellson/code/emely-models/ParlAI/parlai/agents/transformer/modules/decoder.py(345): forward\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py(1039): _slow_forward\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py(1051): _call_impl\n/home/ckjellson/code/emely-models/ParlAI/parlai/agents/transformer/modules/decoder.py(188): forward_layers\n/home/ckjellson/code/emely-models/ParlAI/parlai/agents/transformer/modules/decoder.py(233): forward\n/home/ckjellson/code/emely-models/ParlAI/parlai/torchscript/modules_emely.py(445): forward\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py(1039): _slow_forward\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py(1051): _call_impl\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/jit/_trace.py(952): trace_module\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/jit/_trace.py(735): trace\n/home/ckjellson/code/emely-models/ParlAI/parlai/torchscript/modules_emely.py(139): __init__\n/home/ckjellson/code/emely-models/ParlAI/parlai/scripts/torchscript.py(115): export_emely\n<ipython-input-8-89f3478722e0>(2): <module>\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3441): run_code\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3361): run_ast_nodes\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3169): run_cell_async\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/IPython/core/async_helpers.py(68): _pseudo_sync_runner\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2944): _run_cell\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2898): run_cell\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/ipykernel/zmqshell.py(536): run_cell\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/ipykernel/ipkernel.py(306): do_execute\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/tornado/gen.py(234): wrapper\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/ipykernel/kernelbase.py(543): execute_request\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/tornado/gen.py(234): wrapper\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/ipykernel/kernelbase.py(268): dispatch_shell\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/tornado/gen.py(234): wrapper\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/ipykernel/kernelbase.py(365): process_one\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/tornado/gen.py(775): run\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/tornado/gen.py(814): inner\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/tornado/ioloop.py(741): _run_callback\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/tornado/ioloop.py(688): <lambda>\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/asyncio/events.py(81): _run\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/asyncio/base_events.py(1859): _run_once\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/asyncio/base_events.py(570): run_forever\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/tornado/platform/asyncio.py(199): start\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/ipykernel/kernelapp.py(612): start\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/traitlets/config/application.py(845): launch_instance\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/ipykernel_launcher.py(16): <module>\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/runpy.py(87): _run_code\n/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/runpy.py(194): _run_module_as_main\nRuntimeError: shape '[160, -1, 32]' is invalid for input of size 512\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Create model to test tokenization etc\n",
    "emely_agent = EmelyAgent(opt)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "08:35:54 | loading dictionary from /home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model.dict\n",
      "08:35:55 | num words = 54944\n",
      "08:35:55 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
      "08:35:55 | Loading existing model params from /home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "text = \"Hi Emely, how are you?\\nI'm good thanks! What do you do for work?\\nI write code and I drink coffe.\"\n",
    "reply = emely_agent.observe_and_act(text)\n",
    "print(reply)\n",
    "reply = scripted_module(text)\n",
    "print(reply)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "that ' s cool ! i ' ve never tried coffee . i ' d love to try it though .\n",
      "that ' s cool ! i ' m a software engineer .\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "text = \"Hi Emely, how are you?\"\n",
    "print(emely_agent.dict.txt2vec(text))\n",
    "print(scripted_module.dict.txt2vec(text))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[792, 813, 3459, 6, 102, 46, 15, 20]\n",
      "[792, 813, 3459, 6, 102, 46, 15, 20]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Test performance\n",
    "from time import time\n",
    "nruns = 1\n",
    "t1 = time()\n",
    "for i in range(nruns):\n",
    "    reply = emely_agent.observe_and_act(\"\\nHi!\\n My name is something and my friend's name is something likewise.\")\n",
    "    print(reply)\n",
    "t2 = time()\n",
    "orig_time = t2-t1\n",
    "print(\"Time using original emely_agent: \", orig_time)\n",
    "for i in range(nruns):\n",
    "    reply = original_module('\\n'.join(\"Hi!\\n My name is something and my friend's name is something likewise.\"))\n",
    "    print(reply)\n",
    "t3 = time()\n",
    "orig2_time = t3-t2\n",
    "print(\"Time using original module: \", orig2_time)\n",
    "for i in range(nruns):\n",
    "    reply = scripted_module('\\n'.join(\"Hi!\\n My name is something and my friend's name is something likewise.\"))\n",
    "    print(reply)\n",
    "t4 = time()\n",
    "script_time = t4-t3\n",
    "print(\"Time using scripted model: \", script_time)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "that ' s cool . what is your name ?\n",
      "Time using original emely_agent:  0.25867152214050293\n",
      "__unk__ __unk__\n",
      "Time using original module:  0.2930910587310791\n",
      "goodbye\n",
      "Time using scripted model:  0.11691784858703613\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from parlai.core.message import Message\n",
    "dummy_message = Message()\n",
    "dummy_message['id'] = 'localHuman'\n",
    "dummy_message['text'] = 'Hi'\n",
    "dummy_message['episode_done'] = False\n",
    "dummy_message['label_candidates'] = None\n",
    "#scripted_module.observe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Test ONNX\n",
    "import torch.onnx\n",
    "#torch.onnx.export(original_module, \"Hi! What do you like to do?\", \"emely-testing.onnx\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(type(emely_agent.model.encoder))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'parlai.agents.transformer.modules.encoder.TransformerEncoder'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(emely_agent.dict.tokenize(\"Hi Emely, how are you?\"))\n",
    "print(scripted_module.dict.tokenize(\"Hi Emely, how are you?\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['hi', 'em@@', 'ely', ',', 'how', 'are', 'you', '?']\n",
      "['hi', 'em@@', 'ely', ',', 'how', 'are', 'you', '?']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('emelymodels': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "f8da2b72f9ac3c32718e899b9529d2abac5ccc10881893810be77cced976bf1a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}