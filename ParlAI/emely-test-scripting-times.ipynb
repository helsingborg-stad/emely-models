{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from parlai.core.agents import create_agent\n",
    "from parlai.agents.emely.emely import EmelyAgent\n",
    "from parlai.core.opt import Opt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from parlai.utils.io import PathManager\n",
    "from time import time\n",
    "\n",
    "model_path = Path.cwd() / 'data/models/blender/blender_90M/'\n",
    "assert model_path.is_dir()\n",
    "\n",
    "opt_path = model_path / 'model.opt'\n",
    "opt = Opt.load(opt_path)\n",
    "\n",
    "# Change opts\n",
    "opt['skip_generation'] = False\n",
    "opt['init_model'] = (model_path / 'model').as_posix()\n",
    "opt['no_cuda'] = True  # Cloud run doesn't offer gpu support\n",
    "\n",
    "# Inference options\n",
    "opt['inference'] = 'beam' # 'beam'\n",
    "opt['beam_size'] = 10\n",
    "\n",
    "emely_agent = EmelyAgent(opt)\n",
    "\n",
    "with PathManager.open(\"../../saved_models/emely_scripted_test.pt\", \"rb\") as f:\n",
    "    scripted_module = torch.jit.load(f)\n",
    "\n",
    "with PathManager.open(\"../../saved_models/emely_scripted_test_quantized.pt\", \"rb\") as f:\n",
    "    scripted_quant_module = torch.jit.load(f)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12:21:23 | loading dictionary from /home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model.dict\n",
      "12:21:24 | num words = 54944\n",
      "12:21:24 | \u001b[33mDEPRECATED: XLM should only be used for backwards compatibility, as it involves a less-stable layernorm operation.\u001b[0m\n",
      "12:21:25 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
      "12:21:25 | Loading existing model params from /home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ckjellson/code/emely-models/ParlAI/parlai/agents/emely/emely.py:29: UserWarning: Tried to add persona to agent history but EmelyAgent.persona is None\n",
      "  warnings.warn('Tried to add persona to agent history but EmelyAgent.persona is None')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "nruns = 20\n",
    "text = \"Hi Emely, how are you?\\nI'm good thanks! What do you do for work?\\nI write code and I drink coffe.\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Test emely agent\n",
    "t1 = time()\n",
    "for i in range(nruns):\n",
    "    reply = emely_agent.observe_and_act(text)\n",
    "testtime = time() - t1\n",
    "print(testtime)\n",
    "print(reply)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15.012229204177856\n",
      "that ' s cool ! what kind of code do you write ? i ' ve never written code .\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Test scripted emely agent (if the above cell has been run, restart kernel before running this cell)\n",
    "t1 = time()\n",
    "for i in range(nruns):\n",
    "    reply = scripted_module(text)\n",
    "testtime = time() - t1\n",
    "print(testtime)\n",
    "print(reply)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py:1051: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return forward_call(*input, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "18.755329370498657\n",
      "that ' s cool ! what kind of code do you write ? i ' ve never written code .\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Test scripted emely agent (if the above cell has been run, restart kernel before running this cell)\n",
    "t1 = time()\n",
    "for i in range(nruns):\n",
    "    reply = scripted_quant_module(text)\n",
    "testtime = time() - t1\n",
    "print(testtime)\n",
    "print(reply)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py:1051: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return forward_call(*input, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14.046203851699829\n",
      "that ' s great ! i drink coffee too , but i don ' t like to drink it .\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('emelymodels': conda)"
  },
  "interpreter": {
   "hash": "f8da2b72f9ac3c32718e899b9529d2abac5ccc10881893810be77cced976bf1a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}