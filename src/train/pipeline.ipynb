{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training Emely\n",
    "\n",
    "## Run this noteboook in Jupyter to work with WandB\n",
    "\n",
    "This notebook is for training Emely with different configurations.\n",
    "Use the blender_opts dictionary for the standard options.\n",
    "\n",
    "### Configuration\n",
    "\n",
    "#### Base Config\n",
    "We'll call the base configuration \"Blender base config\" and it's the blender 90M model fine tuned on the internal and external tasks\n",
    "\n",
    "### Required config for a run\n",
    "\n",
    "- task\n",
    "- multitask_weights\n",
    "- model_file\n",
    "\n",
    "### Optional config\n",
    "- mutators\n",
    "- lr\n",
    "\n",
    "\n",
    "### Different mutators for different tasks?\n",
    "--task internal:mutators=word_shuffle,internal:mutators=last_turn\n",
    "\n",
    "\n",
    "### Evaluation\n",
    "All models are evaluated on the internal and external tasks"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import json\n",
    "from parlai.scripts.train_model import TrainModel\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import shutil\n",
    "import wandb\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Enable WandB"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "wandb.init(project=\"emely-v0-4\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mckjellson\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">warm-vortex-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ckjellson/emely-v0-4\" target=\"_blank\">https://wandb.ai/ckjellson/emely-v0-4</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ckjellson/emely-v0-4/runs/101hljqv\" target=\"_blank\">https://wandb.ai/ckjellson/emely-v0-4/runs/101hljqv</a><br/>\n",
       "                Run data is saved locally in <code>/home/ckjellson/code/emely-models/src/train/wandb/run-20210924_143121-101hljqv</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<h1>Run(101hljqv)</h1><iframe src=\"https://wandb.ai/ckjellson/emely-v0-4/runs/101hljqv\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fe841299370>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Choose number of models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "n_models = 3\n",
    "\n",
    "with open(\"temp_opts/run_blender_opts.json\",\"r\") as file:\n",
    "    run_blender_opts = json.load(file)\n",
    "for i in range(n_models):\n",
    "    with open(\"temp_opts/model_\" + str(i+1) + \"_opts.json\",\"w\") as file:\n",
    "        json.dump(run_blender_opts, file, sort_keys=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Edit the options in the temp_opts files for the different models, then run training:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def run_training(model_id):\n",
    "\n",
    "    with open(\"temp_opts/default_blender_opts.json\",\"r\") as file:\n",
    "        default_blender_opts = json.load(file)\n",
    "\n",
    "    with open(\"temp_opts/model_\" + str(model_id) + \"_opts.json\",\"r\") as file:\n",
    "        run_blender_opts = json.load(file)\n",
    "\n",
    "    # Set name for file and model run on wandb\n",
    "    if run_blender_opts[\"mutators\"] is not None:\n",
    "        name = f'blender-{run_blender_opts[\"tasks\"]}-{run_blender_opts[\"weights\"]}-{run_blender_opts[\"mutators\"]}-model_{model_id}'\n",
    "\n",
    "    else:\n",
    "        name = f'blender-{run_blender_opts[\"tasks\"]}-{run_blender_opts[\"weights\"]}-model_{model_id}'\n",
    "    \n",
    "    #%env WANDB_NAME=$name\n",
    "    mf = Path.cwd().parents[1].joinpath(f'models/model-runs/{name}/model')\n",
    "    \n",
    "    # Finalize training opts\n",
    "    run_blender_opts[\"model_file\"] = mf.as_posix()\n",
    "    run_blender_opts.update(default_blender_opts)\n",
    "\n",
    "    TrainModel.main(**run_blender_opts)\n",
    "\n",
    "    with open(f\"models/model-runs/{name}/run_opts.json\",\"w\") as file:\n",
    "        json.dump(run_blender_opts, file, sort_keys=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run the training in separate cells"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "run_training(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "run_training(2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "run_training(3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models are trained, now create docker images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Some utils to change the default files used in this notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "default_blender_opts = {\n",
    "    \"activation\": \"gelu\",\n",
    "    \"attention_dropout\": 0.0,\n",
    "    \"dict_lower\": True,\n",
    "    \"dict_tokenizer\": \"bpe\",\n",
    "    \"embedding_size\": 512,\n",
    "    \"evaltask\": \"internal,external\",\n",
    "    \"ffn_size\": 2048,\n",
    "    \"fp16\": True,\n",
    "    \"gradient_clip\": 0.1,\n",
    "    \"label_truncate\": 128,\n",
    "    \"learn_positional_embeddings\": True,\n",
    "    \"lr_scheduler\": \"reduceonplateau\",\n",
    "    \"metrics\": \"ppl,bleu-4,rouge-L\",\n",
    "    \"model\": \"transformer/generator\",\n",
    "    \"n_heads\": 16,\n",
    "    \"n_layers\": 8,\n",
    "    \"n_positions\": 512,\n",
    "    \"optimizer\": \"adamax\",\n",
    "    \"relu_dropout\": 0.0,\n",
    "    \"save_after_valid\": True,\n",
    "    \"skip_generation\": False,\n",
    "    \"stim\": 60,\n",
    "    \"tensorboard_log\": True,\n",
    "    \"text_truncate\": 512,\n",
    "    \"update_freq\": 1,\n",
    "    \"variant\": \"xlm\",\n",
    "    \"veps\": 0.25,\n",
    "    \"vme\": 20000,\n",
    "    \"vmm\": \"min\",\n",
    "    \"vmt\": \"ppl\",\n",
    "    \"vp\": 15,\n",
    "    \"wblog\": True\n",
    "}\n",
    "run_blender_opts = {'init_model': 'zoo:blender/blender_90M/model',\n",
    "                'dict_file': 'zoo:blender/blender_90M/model.dict',\n",
    "                'bs': 16,\n",
    "                'betas': '0.9,0.999',\n",
    "                'lr': 1e-06,\n",
    "                'dropout': 0.1,\n",
    "                'inference': 'beam',\n",
    "                'beam_size': 10,\n",
    "                'beam_min_length': 10,\n",
    "                'beam_block_ngram': 3,\n",
    "                'wandb_project': 'parlaiemely',\n",
    "                'task': 'internal,external,external-gpt3',\n",
    "                'multitask_weights': '6,3,3',\n",
    "                'mutators': None}\n",
    "\n",
    "with open(\"temp_opts/default_blender_opts.json\",\"w\") as file:\n",
    "    json.dump(default_blender_opts,file, sort_keys=True, indent=4)\n",
    "with open(\"temp_opts/run_blender_opts.json\",\"w\") as file:\n",
    "    json.dump(run_blender_opts,file, sort_keys=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('emelymodels': conda)"
  },
  "interpreter": {
   "hash": "f8da2b72f9ac3c32718e899b9529d2abac5ccc10881893810be77cced976bf1a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}