{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training Emely\n",
    "\n",
    "## Run this noteboook in Jupyter to work with WandB\n",
    "\n",
    "This notebook is for training Emely with different configurations.\n",
    "Use the blender_opts dictionary for the standard options.\n",
    "\n",
    "### Configuration\n",
    "\n",
    "The default options for training are located in settings/default_blender_opts.json and settings/run_blender_opts.json. The default_blender_opts are assumed to stay unchanged, while the run_blender_opts can be altered for each model instance.\n",
    "\n",
    "The current options that can be varied between models with default settings are:\n",
    "\n",
    "- init_model: \"zoo:blender/blender_90M/model\",\n",
    "- dict_file: \"zoo:blender/blender_90M/model.dict\",\n",
    "- bs: 16,\n",
    "- betas: \"0.9,0.999\",\n",
    "- lr: 1e-06,\n",
    "- dropout: 0.1,\n",
    "- inference: \"beam\",\n",
    "- beam_size: 10,\n",
    "- beam_min_length: 10,\n",
    "- beam_block_ngram: 3,\n",
    "- wandb_project: \"emely-v0.X\",\n",
    "- task: \"internal,external,external-gpt3\",\n",
    "- multitask_weights: \"6,3,3\",\n",
    "- mutators: null\n",
    "\n",
    "This notebook assumes the structure\n",
    "\n",
    "- root\n",
    "    - emely-models\n",
    "    - emely-testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main options"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_models = 1\n",
    "wandb_project_name = \"emely-v0-4\"\n",
    "model_type = \"interview\"\n",
    "trainenv = \"emelymodels\"    # Name of the training environment\n",
    "testenv = \"emelytesting\"    # Name of the testing environment"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Imports\n",
    "import json\n",
    "from parlai.scripts.train_model import TrainModel\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import shutil\n",
    "import wandb\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Choose training settings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "os.system(f\"conda activate {trainenv}\")\n",
    "with open(\"temp_opts/run_blender_opts.json\",\"r\") as file:\n",
    "    run_blender_opts = json.load(file)\n",
    "for i in range(n_models):\n",
    "    with open(\"temp_opts/model_\" + str(i+1) + \"_opts.json\",\"w\") as file:\n",
    "        json.dump(run_blender_opts, file, sort_keys=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Edit the options in the temp_opts files for the different models, then run training:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initiate WandB"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "wandb.init(project=wandb_project_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define training function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def run_training(model_id):\n",
    "\n",
    "    with open(\"temp_opts/default_blender_opts.json\",\"r\") as file:\n",
    "        default_blender_opts = json.load(file)\n",
    "\n",
    "    with open(\"temp_opts/model_\" + str(model_id) + \"_opts.json\",\"r\") as file:\n",
    "        run_blender_opts = json.load(file)\n",
    "\n",
    "    # Set name for file and model run on wandb\n",
    "    if run_blender_opts[\"mutators\"] is not None:\n",
    "        name = f'blender-{run_blender_opts[\"task\"]}-{run_blender_opts[\"multitask_weights\"]}-{run_blender_opts[\"mutators\"]}-model_{model_id}'\n",
    "\n",
    "    else:\n",
    "        name = f'blender-{run_blender_opts[\"task\"]}-{run_blender_opts[\"multitask_weights\"]}-model_{model_id}'\n",
    "    \n",
    "    #%env WANDB_NAME=$name\n",
    "    mf = Path.cwd().parents[1].joinpath(f'models/model-runs/{name}/model')\n",
    "    \n",
    "    # Finalize training opts\n",
    "    run_blender_opts[\"model_file\"] = mf.as_posix()\n",
    "    run_blender_opts[\"wandb_name\"] = name\n",
    "    run_blender_opts.update(default_blender_opts)\n",
    "\n",
    "    if run_blender_opts[\"mutators\"] is None:\n",
    "        del run_blender_opts[\"mutators\"]\n",
    "    \n",
    "    TrainModel.main(**run_blender_opts)\n",
    "\n",
    "    os.system(f\"parlai vacuum -mf ../../models/model-runs/{name}/model\")\n",
    "\n",
    "    with open(f\"models/model-runs/{name}/run_opts.json\",\"w\") as file:\n",
    "        json.dump(run_blender_opts, file, sort_keys=False, indent=4)\n",
    "\n",
    "    return name\n",
    "\n",
    "model_names = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run the training in separate cells\n",
    "\n",
    "Only the models that are successfully generated will be appended to model_names, and used for testing."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_names.append(run_training(1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Remove this cell!\n",
    "model_names = [\"blender-minimal-1-model_1\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models are trained, now create docker images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "image_names = []\n",
    "for name in model_names:\n",
    "    # Store the Dockerfile that is used in the model directory\n",
    "    with open(f\"../{model_type}/Dockerfile\",\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    lines[4] = f\"COPY models/model-runs/{name} ./models/interview-model\\n\"\n",
    "    dockerfile = \"\".join(lines)\n",
    "    with open(f\"../../models/model-runs/{name}/Dockerfile\",\"w\") as file:\n",
    "        file.write(dockerfile)\n",
    "    \n",
    "    # Create docker image\n",
    "    os.system(f\"cp ../../models/model-runs/{name}/Dockerfile ../../Dockerfile\")\n",
    "    os.system(f\"docker build -t {name} .\")\n",
    "    os.system(f\"rm ../../Dockerfile\")\n",
    "\n",
    "    image_names.append(name)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.system(f\"conda activate {testenv}\")\n",
    "os.system(\"cd ../../../emely-testing\")\n",
    "for name in image_names:\n",
    "    os.system(f\"docker run --name {name} -p 8080:8080 {name}\")\n",
    "    os.system(\"python main.py\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# --- End of pipeline ---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Some utils to change the default files used in this notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "default_blender_opts = {\n",
    "    \"activation\": \"gelu\",\n",
    "    \"attention_dropout\": 0.0,\n",
    "    \"dict_lower\": True,\n",
    "    \"dict_tokenizer\": \"bpe\",\n",
    "    \"embedding_size\": 512,\n",
    "    \"evaltask\": \"internal,external\",\n",
    "    \"ffn_size\": 2048,\n",
    "    \"fp16\": True,\n",
    "    \"gradient_clip\": 0.1,\n",
    "    \"label_truncate\": 128,\n",
    "    \"learn_positional_embeddings\": True,\n",
    "    \"lr_scheduler\": \"reduceonplateau\",\n",
    "    \"metrics\": \"ppl,bleu-4,rouge-L\",\n",
    "    \"model\": \"transformer/generator\",\n",
    "    \"n_heads\": 16,\n",
    "    \"n_layers\": 8,\n",
    "    \"n_positions\": 512,\n",
    "    \"optimizer\": \"adamax\",\n",
    "    \"relu_dropout\": 0.0,\n",
    "    \"save_after_valid\": True,\n",
    "    \"skip_generation\": False,\n",
    "    \"stim\": 60,\n",
    "    \"tensorboard_log\": True,\n",
    "    \"text_truncate\": 512,\n",
    "    \"update_freq\": 1,\n",
    "    \"variant\": \"xlm\",\n",
    "    \"veps\": 0.25,\n",
    "    \"vme\": 20000,\n",
    "    \"vmm\": \"min\",\n",
    "    \"vmt\": \"ppl\",\n",
    "    \"vp\": 15,\n",
    "    \"wblog\": True\n",
    "}\n",
    "run_blender_opts = {\n",
    "    'init_model': 'zoo:blender/blender_90M/model',\n",
    "    'dict_file': 'zoo:blender/blender_90M/model.dict',\n",
    "    'bs': 16,\n",
    "    'betas': '0.9,0.999',\n",
    "    'lr': 1e-06,\n",
    "    'dropout': 0.1,\n",
    "    'inference': 'beam',\n",
    "    'beam_size': 10,\n",
    "    'beam_min_length': 10,\n",
    "    'beam_block_ngram': 3,\n",
    "    'wandb_project': 'parlaiemely',\n",
    "    'task': 'internal,external,external-gpt3',\n",
    "    'multitask_weights': '6,3,3',\n",
    "    'mutators': None\n",
    "}\n",
    "\n",
    "with open(\"temp_opts/default_blender_opts.json\",\"w\") as file:\n",
    "    json.dump(default_blender_opts,file, sort_keys=True, indent=4)\n",
    "with open(\"temp_opts/run_blender_opts.json\",\"w\") as file:\n",
    "    json.dump(run_blender_opts,file, sort_keys=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('emelymodels': conda)"
  },
  "interpreter": {
   "hash": "f8da2b72f9ac3c32718e899b9529d2abac5ccc10881893810be77cced976bf1a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}