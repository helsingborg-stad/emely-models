{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training Emely\n",
    "\n",
    "## Run this noteboook in Jupyter to work with WandB\n",
    "\n",
    "This notebook is for training Emely with different configurations.\n",
    "Use the blender_opts dictionary for the standard options.\n",
    "\n",
    "### Configuration\n",
    "\n",
    "The default options for training are located in settings/default_blender_opts.json and settings/run_blender_opts.json. The default_blender_opts are assumed to stay unchanged, while the run_blender_opts can be altered for each model instance.\n",
    "\n",
    "The current options that can be varied between models with default settings are:\n",
    "\n",
    "- init_model: \"zoo:blender/blender_90M/model\",\n",
    "- dict_file: \"zoo:blender/blender_90M/model.dict\",\n",
    "- bs: 16,\n",
    "- betas: \"0.9,0.999\",\n",
    "- lr: 1e-06,\n",
    "- dropout: 0.1,\n",
    "- inference: \"beam\",\n",
    "- beam_size: 10,\n",
    "- beam_min_length: 10,\n",
    "- beam_block_ngram: 3,\n",
    "- wandb_project: \"emely-v0.X\",\n",
    "- task: \"internal,external,external-gpt3\",\n",
    "- multitask_weights: \"6,3,3\",\n",
    "- mutators: null"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "import json\n",
    "from parlai.scripts.train_model import TrainModel\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import shutil\n",
    "import wandb\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Enable WandB"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "wandb_project_name=\"emely-v0-4\"\n",
    "wandb.init(project=wandb_project_name)\n",
    "\n",
    "model_type = \"interview\" # interview/fika"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mckjellson\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">warm-vortex-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ckjellson/emely-v0-4\" target=\"_blank\">https://wandb.ai/ckjellson/emely-v0-4</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ckjellson/emely-v0-4/runs/101hljqv\" target=\"_blank\">https://wandb.ai/ckjellson/emely-v0-4/runs/101hljqv</a><br/>\n",
       "                Run data is saved locally in <code>/home/ckjellson/code/emely-models/src/train/wandb/run-20210924_143121-101hljqv</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<h1>Run(101hljqv)</h1><iframe src=\"https://wandb.ai/ckjellson/emely-v0-4/runs/101hljqv\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fe841299370>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Choose number of models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "n_models = 1\n",
    "\n",
    "with open(\"temp_opts/run_blender_opts.json\",\"r\") as file:\n",
    "    run_blender_opts = json.load(file)\n",
    "for i in range(n_models):\n",
    "    with open(\"temp_opts/model_\" + str(i+1) + \"_opts.json\",\"w\") as file:\n",
    "        json.dump(run_blender_opts, file, sort_keys=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Edit the options in the temp_opts files for the different models, then run training:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def run_training(model_id):\n",
    "\n",
    "    with open(\"temp_opts/default_blender_opts.json\",\"r\") as file:\n",
    "        default_blender_opts = json.load(file)\n",
    "\n",
    "    with open(\"temp_opts/model_\" + str(model_id) + \"_opts.json\",\"r\") as file:\n",
    "        run_blender_opts = json.load(file)\n",
    "\n",
    "    # Set name for file and model run on wandb\n",
    "    if run_blender_opts[\"mutators\"] is not None:\n",
    "        name = f'blender-{run_blender_opts[\"task\"]}-{run_blender_opts[\"multitask_weights\"]}-{run_blender_opts[\"mutators\"]}-model_{model_id}'\n",
    "\n",
    "    else:\n",
    "        name = f'blender-{run_blender_opts[\"task\"]}-{run_blender_opts[\"multitask_weights\"]}-model_{model_id}'\n",
    "    \n",
    "    #%env WANDB_NAME=$name\n",
    "    mf = Path.cwd().parents[1].joinpath(f'models/model-runs/{name}/model')\n",
    "    \n",
    "    # Finalize training opts\n",
    "    run_blender_opts[\"model_file\"] = mf.as_posix()\n",
    "    run_blender_opts[\"wandb_name\"] = name\n",
    "    run_blender_opts.update(default_blender_opts)\n",
    "\n",
    "    if run_blender_opts[\"mutators\"] is None:\n",
    "        del run_blender_opts[\"mutators\"]\n",
    "    \n",
    "    TrainModel.main(**run_blender_opts)\n",
    "\n",
    "    with open(f\"models/model-runs/{name}/run_opts.json\",\"w\") as file:\n",
    "        json.dump(run_blender_opts, file, sort_keys=False, indent=4)\n",
    "\n",
    "    return name\n",
    "\n",
    "model_names = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run the training in separate cells"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "model_names.append(run_training(1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16:29:05 | building dictionary first...\n",
      "16:29:05 | \u001b[33mOverriding opt[\"init_model\"] to zoo:blender/blender_90M/model (previously: /home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model)\u001b[0m\n",
      "16:29:05 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n",
      "16:29:05 | \u001b[33mOverriding opt[\"wandb_project\"] to emely-v0.4 (previously: parlaiemely)\u001b[0m\n",
      "16:29:05 | \u001b[33mOverriding opt[\"multitask_weights\"] to (1.0,) (previously: [1.0])\u001b[0m\n",
      "16:29:05 | \u001b[33mOverriding opt[\"wandb_name\"] to blender-minimal-1-model_1 (previously: None)\u001b[0m\n",
      "16:29:05 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: download_path: None,verbose: False,datapath: /home/ckjellson/code/emely-models/ParlAI/data,load_from_checkpoint: True,interactive_mode: False\u001b[0m\n",
      "16:29:05 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n",
      "--wandb-name None --wandb-project parlaiemely --force-fp16-tokens False\u001b[0m\n",
      "16:29:05 | loading dictionary from /home/ckjellson/code/emely-models/models/model-runs/blender-minimal-1-model_1/model.checkpoint.dict\n",
      "16:29:05 | num words = 54944\n",
      "16:29:06 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
      "16:29:06 | Loading existing model params from /home/ckjellson/code/emely-models/models/model-runs/blender-minimal-1-model_1/model.checkpoint\n",
      "16:29:07 | Opt:\n",
      "16:29:07 |     activation: gelu\n",
      "16:29:07 |     adafactor_eps: '[1e-30, 0.001]'\n",
      "16:29:07 |     adam_eps: 1e-08\n",
      "16:29:07 |     add_p1_after_newln: False\n",
      "16:29:07 |     aggregate_micro: False\n",
      "16:29:07 |     allow_missing_init_opts: False\n",
      "16:29:07 |     attention_dropout: 0.0\n",
      "16:29:07 |     batchsize: 1\n",
      "16:29:07 |     beam_block_full_context: True\n",
      "16:29:07 |     beam_block_list_filename: None\n",
      "16:29:07 |     beam_block_ngram: 3\n",
      "16:29:07 |     beam_context_block_ngram: -1\n",
      "16:29:07 |     beam_delay: 30\n",
      "16:29:07 |     beam_length_penalty: 0.65\n",
      "16:29:07 |     beam_min_length: 10\n",
      "16:29:07 |     beam_size: 1\n",
      "16:29:07 |     betas: '(0.9, 0.999)'\n",
      "16:29:07 |     bpe_add_prefix_space: None\n",
      "16:29:07 |     bpe_debug: False\n",
      "16:29:07 |     bpe_dropout: None\n",
      "16:29:07 |     bpe_merge: None\n",
      "16:29:07 |     bpe_vocab: None\n",
      "16:29:07 |     compute_tokenized_bleu: False\n",
      "16:29:07 |     datapath: /home/ckjellson/code/emely-models/ParlAI/data\n",
      "16:29:07 |     datatype: train\n",
      "16:29:07 |     delimiter: '\\n'\n",
      "16:29:07 |     dict_class: parlai.core.dict:DictionaryAgent\n",
      "16:29:07 |     dict_endtoken: __end__\n",
      "16:29:07 |     dict_file: /home/ckjellson/code/emely-models/models/model-runs/blender-minimal-1-model_1/model.checkpoint.dict\n",
      "16:29:07 |     dict_include_test: False\n",
      "16:29:07 |     dict_include_valid: False\n",
      "16:29:07 |     dict_initpath: None\n",
      "16:29:07 |     dict_language: english\n",
      "16:29:07 |     dict_loaded: True\n",
      "16:29:07 |     dict_lower: True\n",
      "16:29:07 |     dict_max_ngram_size: -1\n",
      "16:29:07 |     dict_maxexs: -1\n",
      "16:29:07 |     dict_maxtokens: -1\n",
      "16:29:07 |     dict_minfreq: 0\n",
      "16:29:07 |     dict_nulltoken: __null__\n",
      "16:29:07 |     dict_starttoken: __start__\n",
      "16:29:07 |     dict_textfields: text,labels\n",
      "16:29:07 |     dict_tokenizer: bpe\n",
      "16:29:07 |     dict_unktoken: __unk__\n",
      "16:29:07 |     display_examples: False\n",
      "16:29:07 |     download_path: None\n",
      "16:29:07 |     dropout: 0.1\n",
      "16:29:07 |     dynamic_batching: None\n",
      "16:29:07 |     embedding_projection: random\n",
      "16:29:07 |     embedding_size: 512\n",
      "16:29:07 |     embedding_type: random\n",
      "16:29:07 |     embeddings_scale: True\n",
      "16:29:07 |     eval_batchsize: None\n",
      "16:29:07 |     eval_dynamic_batching: None\n",
      "16:29:07 |     evaltask: internal,external\n",
      "16:29:07 |     ffn_size: 2048\n",
      "16:29:07 |     force_fp16_tokens: True\n",
      "16:29:07 |     fp16: True\n",
      "16:29:07 |     fp16_impl: safe\n",
      "16:29:07 |     gpu: -1\n",
      "16:29:07 |     gradient_clip: 0.1\n",
      "16:29:07 |     hide_labels: False\n",
      "16:29:07 |     history_add_global_end_token: None\n",
      "16:29:07 |     history_reversed: False\n",
      "16:29:07 |     history_size: -1\n",
      "16:29:07 |     image_cropsize: 224\n",
      "16:29:07 |     image_mode: raw\n",
      "16:29:07 |     image_size: 256\n",
      "16:29:07 |     inference: beam\n",
      "16:29:07 |     init_model: /home/ckjellson/code/emely-models/models/model-runs/blender-minimal-1-model_1/model.checkpoint\n",
      "16:29:07 |     init_opt: None\n",
      "16:29:07 |     interactive_mode: False\n",
      "16:29:07 |     invsqrt_lr_decay_gamma: -1\n",
      "16:29:07 |     is_debug: False\n",
      "16:29:07 |     label_truncate: 128\n",
      "16:29:07 |     learn_positional_embeddings: True\n",
      "16:29:07 |     learningrate: 1e-06\n",
      "16:29:07 |     load_from_checkpoint: True\n",
      "16:29:07 |     log_every_n_secs: -1\n",
      "16:29:07 |     log_every_n_steps: 50\n",
      "16:29:08 |     loglevel: info\n",
      "16:29:08 |     lr_scheduler: reduceonplateau\n",
      "16:29:08 |     lr_scheduler_decay: 0.5\n",
      "16:29:08 |     lr_scheduler_patience: 3\n",
      "16:29:08 |     max_train_steps: -1\n",
      "16:29:08 |     max_train_time: -1\n",
      "16:29:08 |     metrics: ppl,bleu-4,rouge-L\n",
      "16:29:08 |     model: transformer/generator\n",
      "16:29:08 |     model_file: /home/ckjellson/code/emely-models/models/model-runs/blender-minimal-1-model_1/model\n",
      "16:29:08 |     model_parallel: False\n",
      "16:29:08 |     momentum: 0\n",
      "16:29:08 |     multitask_weights: (1.0,)\n",
      "16:29:08 |     mutators: None\n",
      "16:29:08 |     n_decoder_layers: -1\n",
      "16:29:08 |     n_encoder_layers: -1\n",
      "16:29:08 |     n_heads: 16\n",
      "16:29:08 |     n_layers: 8\n",
      "16:29:08 |     n_positions: 512\n",
      "16:29:08 |     n_segments: 0\n",
      "16:29:08 |     nesterov: True\n",
      "16:29:08 |     no_cuda: False\n",
      "16:29:08 |     num_epochs: -1\n",
      "16:29:08 |     num_workers: 0\n",
      "16:29:08 |     nus: [0.7]\n",
      "16:29:08 |     optimizer: adamax\n",
      "16:29:08 |     output_scaling: 1.0\n",
      "16:29:08 |     override: \"{'init_model': 'zoo:blender/blender_90M/model', 'dict_file': '/home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model.dict', 'batchsize': 1, 'betas': (0.9, 0.999), 'learningrate': 1e-06, 'dropout': 0.1, 'inference': 'beam', 'beam_size': 1, 'beam_min_length': 10, 'beam_block_ngram': 3, 'wandb_project': 'emely-v0.4', 'task': 'minimal', 'multitask_weights': (1.0,), 'model_file': '/home/ckjellson/code/emely-models/models/model-runs/blender-minimal-1-model_1/model', 'wandb_name': 'blender-minimal-1-model_1', 'activation': 'gelu', 'attention_dropout': 0.0, 'dict_lower': True, 'dict_tokenizer': 'bpe', 'embedding_size': 512, 'evaltask': 'internal,external', 'ffn_size': 2048, 'fp16': True, 'gradient_clip': 0.1, 'label_truncate': 128, 'learn_positional_embeddings': True, 'lr_scheduler': 'reduceonplateau', 'metrics': 'ppl,bleu-4,rouge-L', 'model': 'transformer/generator', 'n_heads': 16, 'n_layers': 8, 'n_positions': 512, 'optimizer': 'adamax', 'relu_dropout': 0.0, 'save_after_valid': True, 'skip_generation': False, 'save_every_n_secs': 60.0, 'tensorboard_log': True, 'text_truncate': 512, 'update_freq': 1, 'variant': 'xlm', 'validation_every_n_epochs': 0.25, 'validation_max_exs': 20000, 'validation_metric_mode': 'min', 'validation_metric': 'ppl', 'validation_patience': 15, 'wandb_log': True}\"\n",
      "16:29:08 |     parlai_home: /home/ckjellson/code/emely-models/ParlAI\n",
      "16:29:08 |     person_tokens: False\n",
      "16:29:08 |     rank_candidates: False\n",
      "16:29:08 |     relu_dropout: 0.0\n",
      "16:29:08 |     save_after_valid: True\n",
      "16:29:08 |     save_every_n_secs: 60.0\n",
      "16:29:08 |     share_word_embeddings: True\n",
      "16:29:08 |     short_final_eval: False\n",
      "16:29:08 |     skip_generation: False\n",
      "16:29:08 |     special_tok_lst: None\n",
      "16:29:08 |     split_lines: False\n",
      "16:29:08 |     starttime: Sep24_16-03\n",
      "16:29:08 |     task: minimal\n",
      "16:29:08 |     temperature: 1.0\n",
      "16:29:08 |     tensorboard_log: True\n",
      "16:29:08 |     tensorboard_logdir: None\n",
      "16:29:08 |     text_truncate: 512\n",
      "16:29:08 |     topk: 10\n",
      "16:29:08 |     topp: 0.9\n",
      "16:29:08 |     truncate: -1\n",
      "16:29:08 |     update_freq: 1\n",
      "16:29:08 |     use_reply: label\n",
      "16:29:08 |     validation_cutoff: 1.0\n",
      "16:29:08 |     validation_every_n_epochs: 0.25\n",
      "16:29:08 |     validation_every_n_secs: -1\n",
      "16:29:08 |     validation_every_n_steps: -1\n",
      "16:29:08 |     validation_max_exs: 20000\n",
      "16:29:08 |     validation_metric: ppl\n",
      "16:29:08 |     validation_metric_mode: min\n",
      "16:29:08 |     validation_patience: 15\n",
      "16:29:08 |     validation_share_agent: False\n",
      "16:29:08 |     variant: xlm\n",
      "16:29:08 |     verbose: False\n",
      "16:29:08 |     wandb_entity: None\n",
      "16:29:08 |     wandb_log: True\n",
      "16:29:08 |     wandb_name: blender-minimal-1-model_1\n",
      "16:29:08 |     wandb_project: emely-v0.4\n",
      "16:29:08 |     warmup_rate: 0.0001\n",
      "16:29:08 |     warmup_updates: -1\n",
      "16:29:08 |     weight_decay: None\n",
      "16:29:08 | Current ParlAI commit: 71e405aa551798b958648d53623698cfdc4d06e1\n",
      "16:29:08 | Current internal commit: 71e405aa551798b958648d53623698cfdc4d06e1\n",
      "16:29:08 | Current fb commit: 71e405aa551798b958648d53623698cfdc4d06e1\n",
      "16:29:08 | creating task(s): minimal\n",
      "16:29:08 | Loading ParlAI text data: /home/ckjellson/code/emely-models/ParlAI/data/minimal/train.txt\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Finishing last run (ID:1da6x9yb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 23376<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4cb8c45216a44823b26dc38286111580"
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ckjellson/code/emely-models/models/model-runs/blender-minimal-1-model_1/wandb/run-20210924_160308-1da6x9yb/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ckjellson/code/emely-models/models/model-runs/blender-minimal-1-model_1/wandb/run-20210924_160308-1da6x9yb/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>exs/train</td><td>1</td></tr><tr><td>clen/train</td><td>18.0</td></tr><tr><td>ctrunc/train</td><td>0.0</td></tr><tr><td>ctrunclen/train</td><td>0.0</td></tr><tr><td>llen/train</td><td>12.0</td></tr><tr><td>ltrunc/train</td><td>0.0</td></tr><tr><td>ltrunclen/train</td><td>0.0</td></tr><tr><td>loss/train</td><td>1.90703</td></tr><tr><td>ppl/train</td><td>6.73306</td></tr><tr><td>token_acc/train</td><td>0.5</td></tr><tr><td>token_em/train</td><td>0.0</td></tr><tr><td>exps/train</td><td>1.53874</td></tr><tr><td>ltpb/train</td><td>12.0</td></tr><tr><td>ltps/train</td><td>18.46595</td></tr><tr><td>ctpb/train</td><td>18.0</td></tr><tr><td>ctps/train</td><td>27.69933</td></tr><tr><td>tpb/train</td><td>30.0</td></tr><tr><td>tps/train</td><td>46.16527</td></tr><tr><td>ups/train</td><td>1.54173</td></tr><tr><td>gnorm/train</td><td>47.81713</td></tr><tr><td>clip/train</td><td>1.0</td></tr><tr><td>lr/train</td><td>0.0</td></tr><tr><td>total_train_updates/train</td><td>5</td></tr><tr><td>custom_step</td><td>5</td></tr><tr><td>_runtime</td><td>289</td></tr><tr><td>_timestamp</td><td>1632492481</td></tr><tr><td>_step</td><td>8</td></tr><tr><td>internal/exs/valid</td><td>127</td></tr><tr><td>exs/valid</td><td>171</td></tr><tr><td>internal/accuracy/valid</td><td>0.0</td></tr><tr><td>internal/f1/valid</td><td>0.13774</td></tr><tr><td>internal/bleu-4/valid</td><td>0.0</td></tr><tr><td>internal/clen/valid</td><td>45.01575</td></tr><tr><td>internal/ctrunc/valid</td><td>0.0</td></tr><tr><td>internal/ctrunclen/valid</td><td>0.0</td></tr><tr><td>internal/llen/valid</td><td>13.46457</td></tr><tr><td>internal/ltrunc/valid</td><td>0.0</td></tr><tr><td>internal/ltrunclen/valid</td><td>0.0</td></tr><tr><td>internal/loss/valid</td><td>2.55466</td></tr><tr><td>internal/ppl/valid</td><td>12.86686</td></tr><tr><td>internal/token_acc/valid</td><td>0.45439</td></tr><tr><td>internal/token_em/valid</td><td>0.0</td></tr><tr><td>exps/valid</td><td>2.78539</td></tr><tr><td>ltpb/valid</td><td>13.46457</td></tr><tr><td>ltps/valid</td><td>37.50404</td></tr><tr><td>ctpb/valid</td><td>45.01575</td></tr><tr><td>ctps/valid</td><td>125.38635</td></tr><tr><td>tpb/valid</td><td>58.48031</td></tr><tr><td>tps/valid</td><td>162.8904</td></tr><tr><td>lr/valid</td><td>0.0</td></tr><tr><td>total_train_updates/valid</td><td>4</td></tr><tr><td>external/exs/valid</td><td>44</td></tr><tr><td>external/accuracy/valid</td><td>0.0</td></tr><tr><td>external/f1/valid</td><td>0.12231</td></tr><tr><td>external/bleu-4/valid</td><td>0.0</td></tr><tr><td>external/clen/valid</td><td>62.36364</td></tr><tr><td>external/ctrunc/valid</td><td>0.0</td></tr><tr><td>external/ctrunclen/valid</td><td>0.0</td></tr><tr><td>external/llen/valid</td><td>15.88636</td></tr><tr><td>external/ltrunc/valid</td><td>0.0</td></tr><tr><td>external/ltrunclen/valid</td><td>0.0</td></tr><tr><td>external/loss/valid</td><td>3.09205</td></tr><tr><td>external/ppl/valid</td><td>22.02227</td></tr><tr><td>external/token_acc/valid</td><td>0.39914</td></tr><tr><td>external/token_em/valid</td><td>0.0</td></tr><tr><td>accuracy/valid</td><td>0.0</td></tr><tr><td>f1/valid</td><td>0.13002</td></tr><tr><td>bleu-4/valid</td><td>0.0</td></tr><tr><td>clen/valid</td><td>53.68969</td></tr><tr><td>ctrunc/valid</td><td>0.0</td></tr><tr><td>ctrunclen/valid</td><td>0.0</td></tr><tr><td>llen/valid</td><td>14.67547</td></tr><tr><td>ltrunc/valid</td><td>0.0</td></tr><tr><td>ltrunclen/valid</td><td>0.0</td></tr><tr><td>loss/valid</td><td>2.82335</td></tr><tr><td>ppl/valid</td><td>17.44457</td></tr><tr><td>token_acc/valid</td><td>0.42676</td></tr><tr><td>token_em/valid</td><td>0.0</td></tr><tr><td>total_exs/valid</td><td>4</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>exs/train</td><td>▁▁▁▁▁</td></tr><tr><td>clen/train</td><td>▁▁▁▁▁</td></tr><tr><td>ctrunc/train</td><td>▁▁▁▁▁</td></tr><tr><td>ctrunclen/train</td><td>▁▁▁▁▁</td></tr><tr><td>llen/train</td><td>▁▁▁▁▁</td></tr><tr><td>ltrunc/train</td><td>▁▁▁▁▁</td></tr><tr><td>ltrunclen/train</td><td>▁▁▁▁▁</td></tr><tr><td>loss/train</td><td>█▄▁▂▁</td></tr><tr><td>ppl/train</td><td>█▃▁▂▁</td></tr><tr><td>token_acc/train</td><td>▁▁███</td></tr><tr><td>token_em/train</td><td>▁▁▁▁▁</td></tr><tr><td>exps/train</td><td>▁▁█▇█</td></tr><tr><td>ltpb/train</td><td>▁▁▁▁▁</td></tr><tr><td>ltps/train</td><td>▁▁█▇█</td></tr><tr><td>ctpb/train</td><td>▁▁▁▁▁</td></tr><tr><td>ctps/train</td><td>▁▁█▇█</td></tr><tr><td>tpb/train</td><td>▁▁▁▁▁</td></tr><tr><td>tps/train</td><td>▁▁█▇█</td></tr><tr><td>ups/train</td><td>▁▁█▇█</td></tr><tr><td>gnorm/train</td><td>█▁▂█▁</td></tr><tr><td>clip/train</td><td>▁▁▁▁▁</td></tr><tr><td>lr/train</td><td>▁▁▁▁▁</td></tr><tr><td>total_train_updates/train</td><td>▁▃▅▆█</td></tr><tr><td>custom_step</td><td>▁▁▃▃▅▅▆▆█</td></tr><tr><td>_runtime</td><td>▁▃▃▄▄▆▆██</td></tr><tr><td>_timestamp</td><td>▁▃▃▄▄▆▆██</td></tr><tr><td>_step</td><td>▁▂▃▄▅▅▆▇█</td></tr><tr><td>internal/exs/valid</td><td>▁▁▁▁</td></tr><tr><td>exs/valid</td><td>▁▁▁▁</td></tr><tr><td>internal/accuracy/valid</td><td>▁▁▁▁</td></tr><tr><td>internal/f1/valid</td><td>▇█▃▁</td></tr><tr><td>internal/bleu-4/valid</td><td>▁▃█▆</td></tr><tr><td>internal/clen/valid</td><td>▁▁▁▁</td></tr><tr><td>internal/ctrunc/valid</td><td>▁▁▁▁</td></tr><tr><td>internal/ctrunclen/valid</td><td>▁▁▁▁</td></tr><tr><td>internal/llen/valid</td><td>▁▁▁▁</td></tr><tr><td>internal/ltrunc/valid</td><td>▁▁▁▁</td></tr><tr><td>internal/ltrunclen/valid</td><td>▁▁▁▁</td></tr><tr><td>internal/loss/valid</td><td>█▅▃▁</td></tr><tr><td>internal/ppl/valid</td><td>█▅▃▁</td></tr><tr><td>internal/token_acc/valid</td><td>▁▄██</td></tr><tr><td>internal/token_em/valid</td><td>▁▁▁▁</td></tr><tr><td>exps/valid</td><td>▅▇▁█</td></tr><tr><td>ltpb/valid</td><td>▁▁▁▁</td></tr><tr><td>ltps/valid</td><td>▅▇▁█</td></tr><tr><td>ctpb/valid</td><td>▁▁▁▁</td></tr><tr><td>ctps/valid</td><td>▅▇▁█</td></tr><tr><td>tpb/valid</td><td>▁▁▁▁</td></tr><tr><td>tps/valid</td><td>▅▇▁█</td></tr><tr><td>lr/valid</td><td>▁▁▁▁</td></tr><tr><td>total_train_updates/valid</td><td>▁▃▆█</td></tr><tr><td>external/exs/valid</td><td>▁▁▁▁</td></tr><tr><td>external/accuracy/valid</td><td>▁▁▁▁</td></tr><tr><td>external/f1/valid</td><td>█▆▂▁</td></tr><tr><td>external/bleu-4/valid</td><td>█▆▁▁</td></tr><tr><td>external/clen/valid</td><td>▁▁▁▁</td></tr><tr><td>external/ctrunc/valid</td><td>▁▁▁▁</td></tr><tr><td>external/ctrunclen/valid</td><td>▁▁▁▁</td></tr><tr><td>external/llen/valid</td><td>▁▁▁▁</td></tr><tr><td>external/ltrunc/valid</td><td>▁▁▁▁</td></tr><tr><td>external/ltrunclen/valid</td><td>▁▁▁▁</td></tr><tr><td>external/loss/valid</td><td>█▅▃▁</td></tr><tr><td>external/ppl/valid</td><td>█▅▃▁</td></tr><tr><td>external/token_acc/valid</td><td>▁▁▁▁</td></tr><tr><td>external/token_em/valid</td><td>▁▁▁▁</td></tr><tr><td>accuracy/valid</td><td>▁▁▁▁</td></tr><tr><td>f1/valid</td><td>█▇▂▁</td></tr><tr><td>bleu-4/valid</td><td>█▆▁▁</td></tr><tr><td>clen/valid</td><td>▁▁▁▁</td></tr><tr><td>ctrunc/valid</td><td>▁▁▁▁</td></tr><tr><td>ctrunclen/valid</td><td>▁▁▁▁</td></tr><tr><td>llen/valid</td><td>▁▁▁▁</td></tr><tr><td>ltrunc/valid</td><td>▁▁▁▁</td></tr><tr><td>ltrunclen/valid</td><td>▁▁▁▁</td></tr><tr><td>loss/valid</td><td>█▅▃▁</td></tr><tr><td>ppl/valid</td><td>█▅▃▁</td></tr><tr><td>token_acc/valid</td><td>▁▅██</td></tr><tr><td>token_em/valid</td><td>▁▁▁▁</td></tr><tr><td>total_exs/valid</td><td>▁▃▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">wobbly-star-1</strong>: <a href=\"https://wandb.ai/ckjellson/parlaiemely/runs/1da6x9yb\" target=\"_blank\">https://wandb.ai/ckjellson/parlaiemely/runs/1da6x9yb</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1da6x9yb). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">blender-minimal-1-model_1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ckjellson/emely-v0.4\" target=\"_blank\">https://wandb.ai/ckjellson/emely-v0.4</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ckjellson/emely-v0.4/runs/2sun2a6h\" target=\"_blank\">https://wandb.ai/ckjellson/emely-v0.4/runs/2sun2a6h</a><br/>\n",
       "                Run data is saved locally in <code>/home/ckjellson/code/emely-models/models/model-runs/blender-minimal-1-model_1/wandb/run-20210924_162908-2sun2a6h</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16:29:15 | training...\n",
      "16:29:16 | time:301s total_exs:5 total_steps:5 epochs:5.00\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  llen  loss    lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "      18     1    18 29.69       0          0 1.649    1  46.07    12 1.938 1e-06    12 19.79       0          0 6.946   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .5000         0                    5   30 49.48 1.653\n",
      "\n",
      "16:29:16 | creating task(s): internal\n",
      "16:29:16 | Loading ParlAI text data: /home/ckjellson/code/emely-models/ParlAI/data/internal/valid.txt\n",
      "16:29:16 | creating task(s): external\n",
      "16:29:16 | Loading ParlAI text data: /home/ckjellson/code/emely-models/ParlAI/data/external/valid.txt\n",
      "16:29:16 | running eval: valid\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ed6ada5990f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-1fb33c028198>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model_id)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mrun_blender_opts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mutators\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mTrainModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrun_blender_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"models/model-runs/{name}/run_opts.json\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/core/script.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/core/script.py\u001b[0m in \u001b[0;36m_run_kwargs\u001b[0;34m(cls, kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_from_parser_and_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/core/script.py\u001b[0m in \u001b[0;36m_run_from_parser_and_opt\u001b[0;34m(cls, opt, parser)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/scripts/train_model.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/scripts/train_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    845\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                         \u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                         \u001b[0mstop_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mStopTrainException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/scripts/train_model.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# run evaluation on valid set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         valid_report = self._run_eval(\n\u001b[0m\u001b[1;32m    500\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_worlds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation_max_exs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         )\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/scripts/train_model.py\u001b[0m in \u001b[0;36m_run_eval\u001b[0;34m(self, valid_worlds, opt, datatype, max_exs, write_log)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0mmax_exs_per_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_exs\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_worlds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mv_world\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_worlds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m             \u001b[0mtask_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_single_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_world\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_exs_per_worker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m             \u001b[0mreports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_report\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/scripts/train_model.py\u001b[0m in \u001b[0;36m_run_single_eval\u001b[0;34m(self, opt, valid_world, max_exs)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_exs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmax_exs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_cnt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mvalid_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparley\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'display_examples'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n~~'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/core/worlds.py\u001b[0m in \u001b[0;36mparley\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0macts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0macts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_counters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/core/torch_agent.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2105\u001b[0m         \u001b[0;31m# BatchWorld handles calling self_observe, but we're in a Hogwild or Interactive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2106\u001b[0m         \u001b[0;31m# world, so we need to handle this ourselves.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2107\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_observe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/core/torch_agent.py\u001b[0m in \u001b[0;36mbatch_act\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m   2201\u001b[0m                 \u001b[0;31m# save memory and compute by disabling autograd.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m                 \u001b[0;31m# use `with torch.enable_grad()` to gain back gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/core/torch_generator_agent.py\u001b[0m in \u001b[0;36meval_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m             \u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_truncate\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m             \u001b[0mbeam_preds_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbeam_preds_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_generation_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/core/torch_generator_agent.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, batch, beam_size, max_ts, prefix_tokens)\u001b[0m\n\u001b[1;32m   1108\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincr_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincr_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m             \u001b[0;31m# only need the final hidden state to make the word prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/agents/transformer/modules/decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, encoder_state, incr_state)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# --dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         tensor, new_incr_state = self.forward_layers(\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincr_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         )\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/agents/transformer/modules/decoder.py\u001b[0m in \u001b[0;36mforward_layers\u001b[0;34m(self, tensor, encoder_output, encoder_mask, incr_state)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 tensor, new_incr_state[idx] = layer(\n\u001b[0m\u001b[1;32m    189\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                     \u001b[0mencoder_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/agents/transformer/modules/decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, encoder_output, encoder_mask, incr_state)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;31m# don't peak into the future!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         x, final_self_attn_incr_state = self.self_attention(\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/agents/transformer/modules/attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask, incr_state, static_kv)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_key_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# Prepend incremental states. For each of the key, value, and mask, see if\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/emely-models/ParlAI/parlai/agents/transformer/modules/attention.py\u001b[0m in \u001b[0;36mprepare_head\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_per_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             tensor = (\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_per_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models are trained, now create docker images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Some utils to change the default files used in this notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "default_blender_opts = {\n",
    "    \"activation\": \"gelu\",\n",
    "    \"attention_dropout\": 0.0,\n",
    "    \"dict_lower\": True,\n",
    "    \"dict_tokenizer\": \"bpe\",\n",
    "    \"embedding_size\": 512,\n",
    "    \"evaltask\": \"internal,external\",\n",
    "    \"ffn_size\": 2048,\n",
    "    \"fp16\": True,\n",
    "    \"gradient_clip\": 0.1,\n",
    "    \"label_truncate\": 128,\n",
    "    \"learn_positional_embeddings\": True,\n",
    "    \"lr_scheduler\": \"reduceonplateau\",\n",
    "    \"metrics\": \"ppl,bleu-4,rouge-L\",\n",
    "    \"model\": \"transformer/generator\",\n",
    "    \"n_heads\": 16,\n",
    "    \"n_layers\": 8,\n",
    "    \"n_positions\": 512,\n",
    "    \"optimizer\": \"adamax\",\n",
    "    \"relu_dropout\": 0.0,\n",
    "    \"save_after_valid\": True,\n",
    "    \"skip_generation\": False,\n",
    "    \"stim\": 60,\n",
    "    \"tensorboard_log\": True,\n",
    "    \"text_truncate\": 512,\n",
    "    \"update_freq\": 1,\n",
    "    \"variant\": \"xlm\",\n",
    "    \"veps\": 0.25,\n",
    "    \"vme\": 20000,\n",
    "    \"vmm\": \"min\",\n",
    "    \"vmt\": \"ppl\",\n",
    "    \"vp\": 15,\n",
    "    \"wblog\": True\n",
    "}\n",
    "run_blender_opts = {'init_model': 'zoo:blender/blender_90M/model',\n",
    "                'dict_file': 'zoo:blender/blender_90M/model.dict',\n",
    "                'bs': 16,\n",
    "                'betas': '0.9,0.999',\n",
    "                'lr': 1e-06,\n",
    "                'dropout': 0.1,\n",
    "                'inference': 'beam',\n",
    "                'beam_size': 10,\n",
    "                'beam_min_length': 10,\n",
    "                'beam_block_ngram': 3,\n",
    "                'wandb_project': 'parlaiemely',\n",
    "                'task': 'internal,external,external-gpt3',\n",
    "                'multitask_weights': '6,3,3',\n",
    "                'mutators': None}\n",
    "\n",
    "with open(\"temp_opts/default_blender_opts.json\",\"w\") as file:\n",
    "    json.dump(default_blender_opts,file, sort_keys=True, indent=4)\n",
    "with open(\"temp_opts/run_blender_opts.json\",\"w\") as file:\n",
    "    json.dump(run_blender_opts,file, sort_keys=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('emelymodels': conda)"
  },
  "interpreter": {
   "hash": "f8da2b72f9ac3c32718e899b9529d2abac5ccc10881893810be77cced976bf1a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}