{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training Emely\n",
    "\n",
    "## Run this noteboook in Jupyter to work with WandB\n",
    "\n",
    "This notebook is for training Emely with different configurations.\n",
    "Use the blender_opts dictionary for the standard options.\n",
    "\n",
    "### Configuration\n",
    "\n",
    "The default options for training are located in settings/default_blender_opts.json and settings/run_blender_opts.json. The default_blender_opts are assumed to stay unchanged, while the run_blender_opts can be altered for each model instance.\n",
    "\n",
    "The current options that can be varied between models with default settings are:\n",
    "\n",
    "- init_model: \"zoo:blender/blender_90M/model\",\n",
    "- dict_file: \"zoo:blender/blender_90M/model.dict\",\n",
    "- bs: 16,\n",
    "- betas: \"0.9,0.999\",\n",
    "- lr: 1e-06,\n",
    "- dropout: 0.1,\n",
    "- inference: \"beam\",\n",
    "- beam_size: 10,\n",
    "- beam_min_length: 10,\n",
    "- beam_block_ngram: 3,\n",
    "- wandb_project: \"emely-v0.X\",\n",
    "- task: \"internal,external,external-gpt3\",\n",
    "- multitask_weights: \"6,3,3\",\n",
    "- mutators: null\n",
    "\n",
    "This notebook assumes the structure\n",
    "\n",
    "- root\n",
    "    - emely-models\n",
    "    - emely-testing\n",
    "\n",
    "To avoid conflicts with existing docker images it is recommended to run docker system prune or docker system prune --all before running this notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main options"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "n_models = 1\n",
    "wandb_project_name = \"emely-v0-4\"\n",
    "model_type = \"interview\"\n",
    "err = os.system(\"mkdir ../../models/emely-runs\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Imports\n",
    "import json\n",
    "from parlai.scripts.train_model import TrainModel\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import shutil\n",
    "import wandb\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import subprocess\n",
    "from subprocess import Popen\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Choose training settings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "with open(\"temp_opts/run_blender_opts.json\",\"r\") as file:\n",
    "    run_blender_opts = json.load(file)\n",
    "run_blender_opts[\"wandb_project\"] = wandb_project_name\n",
    "for i in range(n_models):\n",
    "    with open(\"temp_opts/model_\" + str(i+1) + \"_opts.json\",\"w\") as file:\n",
    "        json.dump(run_blender_opts, file, sort_keys=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Edit the options in the temp_opts files for the different models, then run training:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initiate WandB"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "wandb.init(project=wandb_project_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mckjellson\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ancient-moon-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ckjellson/emely-v0-4\" target=\"_blank\">https://wandb.ai/ckjellson/emely-v0-4</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ckjellson/emely-v0-4/runs/263gt3qr\" target=\"_blank\">https://wandb.ai/ckjellson/emely-v0-4/runs/263gt3qr</a><br/>\n",
       "                Run data is saved locally in <code>/home/ckjellson/code/emely-models/src/train/wandb/run-20210929_170219-263gt3qr</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<h1>Run(263gt3qr)</h1><iframe src=\"https://wandb.ai/ckjellson/emely-v0-4/runs/263gt3qr\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f3025b0e1c0>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define training function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def run_training(model_id):\n",
    "\n",
    "    with open(\"temp_opts/default_blender_opts.json\",\"r\") as file:\n",
    "        default_blender_opts = json.load(file)\n",
    "\n",
    "    with open(\"temp_opts/model_\" + str(model_id) + \"_opts.json\",\"r\") as file:\n",
    "        run_blender_opts = json.load(file)\n",
    "\n",
    "    # Set name for file and model run on wandb\n",
    "    if run_blender_opts[\"mutators\"] is not None:\n",
    "        name = f'blender-{run_blender_opts[\"task\"]}-{run_blender_opts[\"multitask_weights\"]}-{run_blender_opts[\"mutators\"]}-model-{model_id}'\n",
    "\n",
    "    else:\n",
    "        name = f'blender-{run_blender_opts[\"task\"]}-{run_blender_opts[\"multitask_weights\"]}-model-{model_id}'\n",
    "    \n",
    "    #%env WANDB_NAME=$name\n",
    "    mf = Path.cwd().parents[1].joinpath(f'models/emely-runs/{name}/model')\n",
    "    \n",
    "    # Finalize training opts\n",
    "    run_blender_opts[\"model_file\"] = mf.as_posix()\n",
    "    run_blender_opts[\"wandb_name\"] = name\n",
    "    run_blender_opts.update(default_blender_opts)\n",
    "\n",
    "    # Uncomment the following line to run for one epoch during testing\n",
    "    run_blender_opts[\"eps\"] = 1\n",
    "\n",
    "    if run_blender_opts[\"mutators\"] is None:\n",
    "        del run_blender_opts[\"mutators\"]\n",
    "    \n",
    "    TrainModel.main(**run_blender_opts)\n",
    "\n",
    "    os.system(f\"parlai vacuum -mf ../../models/emely-runs/{name}/model\")\n",
    "\n",
    "    with open(f\"../../models/emely-runs/{name}/run_opts.json\",\"w\") as file:\n",
    "        json.dump(run_blender_opts, file, sort_keys=False, indent=4)\n",
    "\n",
    "    return name\n",
    "\n",
    "model_names = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run the training in separate cells\n",
    "\n",
    "Only the models that are successfully generated will be appended to model_names, and used for testing."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model_names.append(run_training(1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "17:02:37 | building dictionary first...\n",
      "17:02:37 | No model with opt yet at: /home/ckjellson/code/emely-models/models/emely-runs/blender-minimal-1-model-1/model(.opt)\n",
      "17:02:37 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: /home/ckjellson/code/emely-models/ParlAI/data,eval_dynamic_batching: None,num_workers: 0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_steps: -1,load_from_checkpoint: True,tensorboard_logdir: None,wandb_log: True,wandb_name: blender-minimal-1-model-1,wandb_project: emely-v0-4,wandb_entity: None,mutators: None,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,beam_block_full_context: True,beam_delay: 30,beam_block_list_filename: None,temperature: 1.0,interactive_mode: False,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None\u001b[0m\n",
      "17:02:37 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n",
      "--show-advanced-args False --task internal:blended_skill_talk,wizard_of_wikipedia,convai2,empathetic_dialogues --numthreads 1 --multitask-weights 1.0,3.0,3.0,3.0 --evaltask None --num-epochs -1 --metrics default --tensorboard-log False --log-every-n-secs 2 --label-type response --include-knowledge True --include-checked-sentence True --include-knowledge-separator False --num-topics 5 --train-experiencer-only False --beam-size 10 --beam-min-length 20 --beam-context-block-ngram 3 --fp16-impl apex --learningrate 7.5e-06 --max-lr-steps -1 --parlai-home /private/home/edinan/ParlAI\u001b[0m\n",
      "17:02:37 | loading dictionary from /home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model.dict\n",
      "17:02:37 | num words = 54944\n",
      "17:02:38 | \u001b[33mDEPRECATED: XLM should only be used for backwards compatibility, as it involves a less-stable layernorm operation.\u001b[0m\n",
      "17:02:38 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
      "17:02:38 | Loading existing model params from /home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model\n",
      "17:02:38 | Opt:\n",
      "17:02:38 |     activation: gelu\n",
      "17:02:38 |     adafactor_eps: '(1e-30, 0.001)'\n",
      "17:02:38 |     adam_eps: 1e-08\n",
      "17:02:38 |     add_p1_after_newln: False\n",
      "17:02:38 |     aggregate_micro: False\n",
      "17:02:38 |     allow_missing_init_opts: False\n",
      "17:02:38 |     attention_dropout: 0.0\n",
      "17:02:38 |     batchsize: 16\n",
      "17:02:38 |     beam_block_full_context: True\n",
      "17:02:38 |     beam_block_list_filename: None\n",
      "17:02:38 |     beam_block_ngram: 3\n",
      "17:02:38 |     beam_context_block_ngram: -1\n",
      "17:02:38 |     beam_delay: 30\n",
      "17:02:38 |     beam_length_penalty: 0.65\n",
      "17:02:38 |     beam_min_length: 10\n",
      "17:02:38 |     beam_size: 1\n",
      "17:02:38 |     betas: '(0.9, 0.999)'\n",
      "17:02:38 |     bpe_add_prefix_space: None\n",
      "17:02:38 |     bpe_debug: False\n",
      "17:02:38 |     bpe_dropout: None\n",
      "17:02:38 |     bpe_merge: None\n",
      "17:02:38 |     bpe_vocab: None\n",
      "17:02:38 |     compute_tokenized_bleu: False\n",
      "17:02:38 |     datapath: /home/ckjellson/code/emely-models/ParlAI/data\n",
      "17:02:38 |     datatype: train\n",
      "17:02:38 |     delimiter: '\\n'\n",
      "17:02:38 |     dict_class: parlai.core.dict:DictionaryAgent\n",
      "17:02:38 |     dict_endtoken: __end__\n",
      "17:02:38 |     dict_file: /home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model.dict\n",
      "17:02:38 |     dict_include_test: False\n",
      "17:02:38 |     dict_include_valid: False\n",
      "17:02:38 |     dict_initpath: None\n",
      "17:02:38 |     dict_language: english\n",
      "17:02:38 |     dict_loaded: True\n",
      "17:02:38 |     dict_lower: True\n",
      "17:02:38 |     dict_max_ngram_size: -1\n",
      "17:02:38 |     dict_maxexs: -1\n",
      "17:02:38 |     dict_maxtokens: -1\n",
      "17:02:38 |     dict_minfreq: 0\n",
      "17:02:38 |     dict_nulltoken: __null__\n",
      "17:02:38 |     dict_starttoken: __start__\n",
      "17:02:38 |     dict_textfields: text,labels\n",
      "17:02:38 |     dict_tokenizer: bpe\n",
      "17:02:38 |     dict_unktoken: __unk__\n",
      "17:02:38 |     display_examples: False\n",
      "17:02:38 |     download_path: None\n",
      "17:02:38 |     dropout: 0.1\n",
      "17:02:38 |     dynamic_batching: None\n",
      "17:02:38 |     embedding_projection: random\n",
      "17:02:38 |     embedding_size: 512\n",
      "17:02:38 |     embedding_type: random\n",
      "17:02:38 |     embeddings_scale: True\n",
      "17:02:38 |     eval_batchsize: None\n",
      "17:02:38 |     eval_dynamic_batching: None\n",
      "17:02:38 |     evaltask: internal,external\n",
      "17:02:38 |     ffn_size: 2048\n",
      "17:02:38 |     force_fp16_tokens: False\n",
      "17:02:38 |     fp16: True\n",
      "17:02:38 |     fp16_impl: safe\n",
      "17:02:38 |     gpu: -1\n",
      "17:02:38 |     gradient_clip: 0.1\n",
      "17:02:38 |     hide_labels: False\n",
      "17:02:38 |     history_add_global_end_token: None\n",
      "17:02:38 |     history_reversed: False\n",
      "17:02:38 |     history_size: -1\n",
      "17:02:38 |     image_cropsize: 224\n",
      "17:02:38 |     image_mode: raw\n",
      "17:02:38 |     image_size: 256\n",
      "17:02:38 |     inference: beam\n",
      "17:02:38 |     init_model: /home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model\n",
      "17:02:38 |     init_opt: None\n",
      "17:02:38 |     interactive_mode: False\n",
      "17:02:38 |     invsqrt_lr_decay_gamma: -1\n",
      "17:02:38 |     is_debug: False\n",
      "17:02:38 |     label_truncate: 128\n",
      "17:02:38 |     learn_positional_embeddings: True\n",
      "17:02:38 |     learningrate: 1e-06\n",
      "17:02:38 |     load_from_checkpoint: True\n",
      "17:02:38 |     log_every_n_secs: -1\n",
      "17:02:38 |     log_every_n_steps: 50\n",
      "17:02:38 |     loglevel: info\n",
      "17:02:38 |     lr_scheduler: reduceonplateau\n",
      "17:02:38 |     lr_scheduler_decay: 0.5\n",
      "17:02:38 |     lr_scheduler_patience: 3\n",
      "17:02:38 |     max_train_steps: -1\n",
      "17:02:38 |     max_train_time: -1\n",
      "17:02:38 |     metrics: ppl,bleu-4,rouge-L\n",
      "17:02:38 |     model: transformer/generator\n",
      "17:02:38 |     model_file: /home/ckjellson/code/emely-models/models/emely-runs/blender-minimal-1-model-1/model\n",
      "17:02:38 |     model_parallel: False\n",
      "17:02:38 |     momentum: 0\n",
      "17:02:38 |     multitask_weights: (1.0,)\n",
      "17:02:38 |     mutators: None\n",
      "17:02:38 |     n_decoder_layers: -1\n",
      "17:02:38 |     n_encoder_layers: -1\n",
      "17:02:38 |     n_heads: 16\n",
      "17:02:38 |     n_layers: 8\n",
      "17:02:38 |     n_positions: 512\n",
      "17:02:38 |     n_segments: 0\n",
      "17:02:38 |     nesterov: True\n",
      "17:02:38 |     no_cuda: False\n",
      "17:02:38 |     num_epochs: 1.0\n",
      "17:02:38 |     num_workers: 0\n",
      "17:02:38 |     nus: (0.7,)\n",
      "17:02:38 |     optimizer: adamax\n",
      "17:02:38 |     output_scaling: 1.0\n",
      "17:02:38 |     override: \"{'init_model': 'zoo:blender/blender_90M/model', 'dict_file': '/home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model.dict', 'batchsize': 16, 'betas': (0.9, 0.999), 'learningrate': 1e-06, 'dropout': 0.1, 'inference': 'beam', 'beam_size': 1, 'beam_min_length': 10, 'beam_block_ngram': 3, 'wandb_project': 'emely-v0-4', 'task': 'minimal', 'multitask_weights': (1.0,), 'model_file': '/home/ckjellson/code/emely-models/models/emely-runs/blender-minimal-1-model-1/model', 'wandb_name': 'blender-minimal-1-model-1', 'activation': 'gelu', 'attention_dropout': 0.0, 'dict_lower': True, 'dict_tokenizer': 'bpe', 'embedding_size': 512, 'evaltask': 'internal,external', 'ffn_size': 2048, 'fp16': True, 'gradient_clip': 0.1, 'label_truncate': 128, 'learn_positional_embeddings': True, 'lr_scheduler': 'reduceonplateau', 'metrics': 'ppl,bleu-4,rouge-L', 'model': 'transformer/generator', 'n_heads': 16, 'n_layers': 8, 'n_positions': 512, 'optimizer': 'adamax', 'relu_dropout': 0.0, 'save_after_valid': True, 'skip_generation': False, 'save_every_n_secs': 60.0, 'tensorboard_log': True, 'text_truncate': 512, 'update_freq': 1, 'variant': 'xlm', 'validation_every_n_epochs': 0.25, 'validation_max_exs': 20000, 'validation_metric_mode': 'min', 'validation_metric': 'ppl', 'validation_patience': 15, 'wandb_log': True, 'num_epochs': 1.0}\"\n",
      "17:02:38 |     parlai_home: /home/ckjellson/code/emely-models/ParlAI\n",
      "17:02:38 |     person_tokens: False\n",
      "17:02:38 |     rank_candidates: False\n",
      "17:02:38 |     relu_dropout: 0.0\n",
      "17:02:38 |     save_after_valid: True\n",
      "17:02:38 |     save_every_n_secs: 60.0\n",
      "17:02:38 |     share_word_embeddings: True\n",
      "17:02:38 |     short_final_eval: False\n",
      "17:02:38 |     skip_generation: False\n",
      "17:02:38 |     special_tok_lst: None\n",
      "17:02:38 |     split_lines: False\n",
      "17:02:38 |     starttime: Sep29_17-02\n",
      "17:02:38 |     task: minimal\n",
      "17:02:38 |     temperature: 1.0\n",
      "17:02:38 |     tensorboard_log: True\n",
      "17:02:38 |     tensorboard_logdir: None\n",
      "17:02:38 |     text_truncate: 512\n",
      "17:02:38 |     topk: 10\n",
      "17:02:38 |     topp: 0.9\n",
      "17:02:38 |     truncate: -1\n",
      "17:02:38 |     update_freq: 1\n",
      "17:02:38 |     use_reply: label\n",
      "17:02:38 |     validation_cutoff: 1.0\n",
      "17:02:38 |     validation_every_n_epochs: 0.25\n",
      "17:02:38 |     validation_every_n_secs: -1\n",
      "17:02:38 |     validation_every_n_steps: -1\n",
      "17:02:38 |     validation_max_exs: 20000\n",
      "17:02:38 |     validation_metric: ppl\n",
      "17:02:38 |     validation_metric_mode: min\n",
      "17:02:38 |     validation_patience: 15\n",
      "17:02:38 |     validation_share_agent: False\n",
      "17:02:38 |     variant: xlm\n",
      "17:02:38 |     verbose: False\n",
      "17:02:38 |     wandb_entity: None\n",
      "17:02:38 |     wandb_log: True\n",
      "17:02:38 |     wandb_name: blender-minimal-1-model-1\n",
      "17:02:38 |     wandb_project: emely-v0-4\n",
      "17:02:38 |     warmup_rate: 0.0001\n",
      "17:02:38 |     warmup_updates: -1\n",
      "17:02:38 |     weight_decay: None\n",
      "17:02:38 | Current ParlAI commit: 744532e86e6a257acc8789472d4c705791739f10\n",
      "17:02:38 | Current internal commit: 744532e86e6a257acc8789472d4c705791739f10\n",
      "17:02:38 | Current fb commit: 744532e86e6a257acc8789472d4c705791739f10\n",
      "17:02:38 | creating task(s): minimal\n",
      "17:02:38 | Loading ParlAI text data: /home/ckjellson/code/emely-models/ParlAI/data/minimal/train.txt\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Finishing last run (ID:263gt3qr) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1449<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97cc20b525794b17a90bdd7e418b8d57"
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ckjellson/code/emely-models/src/train/wandb/run-20210929_170219-263gt3qr/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ckjellson/code/emely-models/src/train/wandb/run-20210929_170219-263gt3qr/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">ancient-moon-5</strong>: <a href=\"https://wandb.ai/ckjellson/emely-v0-4/runs/263gt3qr\" target=\"_blank\">https://wandb.ai/ckjellson/emely-v0-4/runs/263gt3qr</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:263gt3qr). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">blender-minimal-1-model-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ckjellson/emely-v0-4\" target=\"_blank\">https://wandb.ai/ckjellson/emely-v0-4</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ckjellson/emely-v0-4/runs/va5twxm8\" target=\"_blank\">https://wandb.ai/ckjellson/emely-v0-4/runs/va5twxm8</a><br/>\n",
       "                Run data is saved locally in <code>/home/ckjellson/code/emely-models/models/emely-runs/blender-minimal-1-model-1/wandb/run-20210929_170239-va5twxm8</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "17:02:46 | training...\n",
      "17:02:47 | time:9s total_exs:16 total_steps:1 epochs:16.00 time_left:0s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  llen  loss    lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "      18     1   288 209.9       0          0 11.61   16  47.43    12 2.106 1e-06   192 139.9       0          0 8.219   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .4531         0                    1  480 349.8 .7297\n",
      "\n",
      "17:02:47 | num_epochs completed:1.0 time elapsed:8.552588701248169s\n",
      "17:02:47 | Saving dictionary to /home/ckjellson/code/emely-models/models/emely-runs/blender-minimal-1-model-1/model.dict\n",
      "17:02:49 | \u001b[33mOverriding opt[\"init_model\"] to zoo:blender/blender_90M/model (previously: /home/ckjellson/code/emely-models/ParlAI/data/models/blender/blender_90M/model)\u001b[0m\n",
      "17:02:49 | \u001b[33mOverriding opt[\"betas\"] to (0.9, 0.999) (previously: [0.9, 0.999])\u001b[0m\n",
      "17:02:49 | \u001b[33mOverriding opt[\"multitask_weights\"] to (1.0,) (previously: [1.0])\u001b[0m\n",
      "17:02:49 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,eval_dynamic_batching: None,num_workers: 0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_steps: -1,tensorboard_logdir: None,wandb_log: True,wandb_name: blender-minimal-1-model-1,wandb_project: emely-v0-4,wandb_entity: None,mutators: None,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,beam_block_full_context: True,beam_delay: 30,beam_block_list_filename: None,temperature: 1.0,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,dict_loaded: True,download_path: None,verbose: False,datapath: /home/ckjellson/code/emely-models/ParlAI/data,load_from_checkpoint: True,interactive_mode: False\u001b[0m\n",
      "17:02:49 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n",
      "--show-advanced-args False --task internal:blended_skill_talk,wizard_of_wikipedia,convai2,empathetic_dialogues --numthreads 1 --multitask-weights 1.0,3.0,3.0,3.0 --evaltask None --num-epochs -1 --metrics default --tensorboard-log False --log-every-n-secs 2 --label-type response --include-knowledge True --include-checked-sentence True --include-knowledge-separator False --num-topics 5 --train-experiencer-only False --beam-size 10 --beam-min-length 20 --beam-context-block-ngram 3 --fp16-impl apex --force-fp16-tokens False --learningrate 7.5e-06 --max-lr-steps -1 --parlai-home /private/home/edinan/ParlAI\u001b[0m\n",
      "17:02:49 | loading dictionary from /home/ckjellson/code/emely-models/models/emely-runs/blender-minimal-1-model-1/model.dict\n",
      "17:02:49 | num words = 54944\n",
      "17:02:50 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
      "17:02:50 | Loading existing model params from /home/ckjellson/code/emely-models/models/emely-runs/blender-minimal-1-model-1/model\n",
      "17:02:50 | creating task(s): internal\n",
      "17:02:50 | Loading ParlAI text data: /home/ckjellson/code/emely-models/ParlAI/data/internal/valid.txt\n",
      "17:02:50 | creating task(s): external\n",
      "17:02:50 | Loading ParlAI text data: /home/ckjellson/code/emely-models/ParlAI/data/external/valid.txt\n",
      "17:02:50 | running eval: valid\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ckjellson/anaconda3/envs/emelymodels/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "17:02:53 | \u001b[33mROUGE requires nltk punkt tokenizer. Please run `python -c \"import nltk; nltk.download('punkt')`\u001b[0m\n",
      "17:03:19 | eval completed in 28.63s\n",
      "17:03:19 | \u001b[1mvalid:\n",
      "             accuracy    bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  llen  loss    lr  ltpb  ltps  ltrunc  \\\n",
      "   all              0 1.448e-06 53.69 635.2 279.9       0          0 6.218  171 .1321 14.68 2.825 1e-06   190 83.73       0   \n",
      "   external         0 1.846e-06 62.36                   0          0         44 .1261 15.89 3.094                         0   \n",
      "   internal         0 1.049e-06 45.02                   0          0        127 .1380 13.46 2.556                         0   \n",
      "             ltrunclen   ppl  token_acc  token_em  total_train_updates   tpb   tps  \n",
      "   all               0 17.47      .4262         0                    1 825.2 363.6  \n",
      "   external          0 22.06      .3991         0                                   \n",
      "   internal          0 12.89      .4532         0\n",
      "\u001b[0m\n",
      "17:03:19 | creating task(s): internal\n",
      "17:03:19 | Loading ParlAI text data: /home/ckjellson/code/emely-models/ParlAI/data/internal/test.txt\n",
      "17:03:19 | creating task(s): external\n",
      "17:03:19 | Loading ParlAI text data: /home/ckjellson/code/emely-models/ParlAI/data/external/test.txt\n",
      "17:03:19 | running eval: test\n",
      "17:03:49 | eval completed in 30.06s\n",
      "17:03:49 | \u001b[1mtest:\n",
      "             accuracy    bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  llen  loss    lr  ltpb  ltps  ltrunc  \\\n",
      "   all              0 1.448e-06 53.69 635.2 292.7       0          0 6.501  171 .1321 14.68 2.825 1e-06   190 87.54       0   \n",
      "   external         0 1.846e-06 62.36                   0          0         44 .1261 15.89 3.094                         0   \n",
      "   internal         0 1.049e-06 45.02                   0          0        127 .1380 13.46 2.556                         0   \n",
      "             ltrunclen   ppl  token_acc  token_em  total_train_updates   tpb   tps  \n",
      "   all               0 17.47      .4262         0                    1 825.2 380.2  \n",
      "   external          0 22.06      .3991         0                                   \n",
      "   internal          0 12.89      .4532         0\n",
      "\u001b[0m\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1541<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b908d66455294ea7ad3fe8f8ea80cf97"
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ckjellson/code/emely-models/models/emely-runs/blender-minimal-1-model-1/wandb/run-20210929_170239-va5twxm8/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ckjellson/code/emely-models/models/emely-runs/blender-minimal-1-model-1/wandb/run-20210929_170239-va5twxm8/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>exs/train</td><td>16</td></tr><tr><td>clen/train</td><td>18.0</td></tr><tr><td>ctrunc/train</td><td>0.0</td></tr><tr><td>ctrunclen/train</td><td>0.0</td></tr><tr><td>llen/train</td><td>12.0</td></tr><tr><td>ltrunc/train</td><td>0.0</td></tr><tr><td>ltrunclen/train</td><td>0.0</td></tr><tr><td>loss/train</td><td>2.10648</td></tr><tr><td>ppl/train</td><td>8.21923</td></tr><tr><td>token_acc/train</td><td>0.45312</td></tr><tr><td>token_em/train</td><td>0.0</td></tr><tr><td>exps/train</td><td>11.60691</td></tr><tr><td>ltpb/train</td><td>192.0</td></tr><tr><td>ltps/train</td><td>139.93068</td></tr><tr><td>ctpb/train</td><td>288.0</td></tr><tr><td>ctps/train</td><td>209.8954</td></tr><tr><td>tpb/train</td><td>480.0</td></tr><tr><td>tps/train</td><td>349.82335</td></tr><tr><td>ups/train</td><td>0.72973</td></tr><tr><td>gnorm/train</td><td>47.4255</td></tr><tr><td>clip/train</td><td>1.0</td></tr><tr><td>lr/train</td><td>0.0</td></tr><tr><td>total_train_updates/train</td><td>1</td></tr><tr><td>custom_step</td><td>1</td></tr><tr><td>_runtime</td><td>5</td></tr><tr><td>_timestamp</td><td>1632927767</td></tr><tr><td>_step</td><td>0</td></tr><tr><td>internal/exs/valid</td><td>127</td></tr><tr><td>exs/valid</td><td>171</td></tr><tr><td>internal/accuracy/valid</td><td>0.0</td></tr><tr><td>internal/f1/valid</td><td>0.13798</td></tr><tr><td>internal/bleu-4/valid</td><td>0.0</td></tr><tr><td>internal/clen/valid</td><td>45.01575</td></tr><tr><td>internal/ctrunc/valid</td><td>0.0</td></tr><tr><td>internal/ctrunclen/valid</td><td>0.0</td></tr><tr><td>internal/llen/valid</td><td>13.46457</td></tr><tr><td>internal/ltrunc/valid</td><td>0.0</td></tr><tr><td>internal/ltrunclen/valid</td><td>0.0</td></tr><tr><td>internal/loss/valid</td><td>2.55608</td></tr><tr><td>internal/ppl/valid</td><td>12.88523</td></tr><tr><td>internal/token_acc/valid</td><td>0.45322</td></tr><tr><td>internal/token_em/valid</td><td>0.0</td></tr><tr><td>exps/valid</td><td>6.21822</td></tr><tr><td>ltpb/valid</td><td>190.0</td></tr><tr><td>ltps/valid</td><td>83.72587</td></tr><tr><td>ctpb/valid</td><td>635.22222</td></tr><tr><td>ctps/valid</td><td>279.91875</td></tr><tr><td>tpb/valid</td><td>825.22222</td></tr><tr><td>tps/valid</td><td>363.64459</td></tr><tr><td>lr/valid</td><td>0.0</td></tr><tr><td>total_train_updates/valid</td><td>1</td></tr><tr><td>external/exs/valid</td><td>44</td></tr><tr><td>external/accuracy/valid</td><td>0.0</td></tr><tr><td>external/f1/valid</td><td>0.12614</td></tr><tr><td>external/bleu-4/valid</td><td>0.0</td></tr><tr><td>external/clen/valid</td><td>62.36364</td></tr><tr><td>external/ctrunc/valid</td><td>0.0</td></tr><tr><td>external/ctrunclen/valid</td><td>0.0</td></tr><tr><td>external/llen/valid</td><td>15.88636</td></tr><tr><td>external/ltrunc/valid</td><td>0.0</td></tr><tr><td>external/ltrunclen/valid</td><td>0.0</td></tr><tr><td>external/loss/valid</td><td>3.09388</td></tr><tr><td>external/ppl/valid</td><td>22.06259</td></tr><tr><td>external/token_acc/valid</td><td>0.39914</td></tr><tr><td>external/token_em/valid</td><td>0.0</td></tr><tr><td>accuracy/valid</td><td>0.0</td></tr><tr><td>f1/valid</td><td>0.13206</td></tr><tr><td>bleu-4/valid</td><td>0.0</td></tr><tr><td>clen/valid</td><td>53.68969</td></tr><tr><td>ctrunc/valid</td><td>0.0</td></tr><tr><td>ctrunclen/valid</td><td>0.0</td></tr><tr><td>llen/valid</td><td>14.67547</td></tr><tr><td>ltrunc/valid</td><td>0.0</td></tr><tr><td>ltrunclen/valid</td><td>0.0</td></tr><tr><td>loss/valid</td><td>2.82498</td></tr><tr><td>ppl/valid</td><td>17.47391</td></tr><tr><td>token_acc/valid</td><td>0.42618</td></tr><tr><td>token_em/valid</td><td>0.0</td></tr><tr><td>internal/exs/test</td><td>127</td></tr><tr><td>exs/test</td><td>171</td></tr><tr><td>internal/accuracy/test</td><td>0.0</td></tr><tr><td>internal/f1/test</td><td>0.13798</td></tr><tr><td>internal/bleu-4/test</td><td>0.0</td></tr><tr><td>internal/clen/test</td><td>45.01575</td></tr><tr><td>internal/ctrunc/test</td><td>0.0</td></tr><tr><td>internal/ctrunclen/test</td><td>0.0</td></tr><tr><td>internal/llen/test</td><td>13.46457</td></tr><tr><td>internal/ltrunc/test</td><td>0.0</td></tr><tr><td>internal/ltrunclen/test</td><td>0.0</td></tr><tr><td>internal/loss/test</td><td>2.55608</td></tr><tr><td>internal/ppl/test</td><td>12.88523</td></tr><tr><td>internal/token_acc/test</td><td>0.45322</td></tr><tr><td>internal/token_em/test</td><td>0.0</td></tr><tr><td>exps/test</td><td>6.50121</td></tr><tr><td>ltpb/test</td><td>190.0</td></tr><tr><td>ltps/test</td><td>87.53634</td></tr><tr><td>ctpb/test</td><td>635.22222</td></tr><tr><td>ctps/test</td><td>292.65843</td></tr><tr><td>tpb/test</td><td>825.22222</td></tr><tr><td>tps/test</td><td>380.1954</td></tr><tr><td>lr/test</td><td>0.0</td></tr><tr><td>total_train_updates/test</td><td>1</td></tr><tr><td>external/exs/test</td><td>44</td></tr><tr><td>external/accuracy/test</td><td>0.0</td></tr><tr><td>external/f1/test</td><td>0.12614</td></tr><tr><td>external/bleu-4/test</td><td>0.0</td></tr><tr><td>external/clen/test</td><td>62.36364</td></tr><tr><td>external/ctrunc/test</td><td>0.0</td></tr><tr><td>external/ctrunclen/test</td><td>0.0</td></tr><tr><td>external/llen/test</td><td>15.88636</td></tr><tr><td>external/ltrunc/test</td><td>0.0</td></tr><tr><td>external/ltrunclen/test</td><td>0.0</td></tr><tr><td>external/loss/test</td><td>3.09388</td></tr><tr><td>external/ppl/test</td><td>22.06259</td></tr><tr><td>external/token_acc/test</td><td>0.39914</td></tr><tr><td>external/token_em/test</td><td>0.0</td></tr><tr><td>accuracy/test</td><td>0.0</td></tr><tr><td>f1/test</td><td>0.13206</td></tr><tr><td>bleu-4/test</td><td>0.0</td></tr><tr><td>clen/test</td><td>53.68969</td></tr><tr><td>ctrunc/test</td><td>0.0</td></tr><tr><td>ctrunclen/test</td><td>0.0</td></tr><tr><td>llen/test</td><td>14.67547</td></tr><tr><td>ltrunc/test</td><td>0.0</td></tr><tr><td>ltrunclen/test</td><td>0.0</td></tr><tr><td>loss/test</td><td>2.82498</td></tr><tr><td>ppl/test</td><td>17.47391</td></tr><tr><td>token_acc/test</td><td>0.42618</td></tr><tr><td>token_em/test</td><td>0.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>exs/train</td><td>▁</td></tr><tr><td>clen/train</td><td>▁</td></tr><tr><td>ctrunc/train</td><td>▁</td></tr><tr><td>ctrunclen/train</td><td>▁</td></tr><tr><td>llen/train</td><td>▁</td></tr><tr><td>ltrunc/train</td><td>▁</td></tr><tr><td>ltrunclen/train</td><td>▁</td></tr><tr><td>loss/train</td><td>▁</td></tr><tr><td>ppl/train</td><td>▁</td></tr><tr><td>token_acc/train</td><td>▁</td></tr><tr><td>token_em/train</td><td>▁</td></tr><tr><td>exps/train</td><td>▁</td></tr><tr><td>ltpb/train</td><td>▁</td></tr><tr><td>ltps/train</td><td>▁</td></tr><tr><td>ctpb/train</td><td>▁</td></tr><tr><td>ctps/train</td><td>▁</td></tr><tr><td>tpb/train</td><td>▁</td></tr><tr><td>tps/train</td><td>▁</td></tr><tr><td>ups/train</td><td>▁</td></tr><tr><td>gnorm/train</td><td>▁</td></tr><tr><td>clip/train</td><td>▁</td></tr><tr><td>lr/train</td><td>▁</td></tr><tr><td>total_train_updates/train</td><td>▁</td></tr><tr><td>custom_step</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">blender-minimal-1-model-1</strong>: <a href=\"https://wandb.ai/ckjellson/emely-v0-4/runs/va5twxm8\" target=\"_blank\">https://wandb.ai/ckjellson/emely-v0-4/runs/va5twxm8</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models are trained, now create docker images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "image_names = []\n",
    "for name in model_names:\n",
    "    try:\n",
    "        # Store the Dockerfile that is used in the model directory\n",
    "        with open(f\"../{model_type}/Dockerfile\",\"r\") as file:\n",
    "            lines = file.readlines()\n",
    "        lines[4] = f\"COPY models/emely-runs/{name} ./models/interview-model\\n\"\n",
    "        dockerfile = \"\".join(lines)\n",
    "        with open(f\"../../models/emely-runs/{name}/Dockerfile\",\"w\") as file:\n",
    "            file.write(dockerfile)\n",
    "        \n",
    "        # Create docker image\n",
    "        err = os.system(f\"cp ../../models/emely-runs/{name}/Dockerfile ../../Dockerfile\")\n",
    "        err = os.system(f\"docker build -t {name} ../..\")\n",
    "        err = os.system(f\"rm ../../Dockerfile\")\n",
    "\n",
    "        image_names.append(name)\n",
    "    except:\n",
    "        print(f\"Error generating docker-image for model {name}\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run testing (not yet working)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "tested_names = []\n",
    "image_names = \"blender-minimal-1-model_1\"\n",
    "#print(os.system(f\"conda activate {testenv}\"))\n",
    "for name in image_names:\n",
    "    #try:\n",
    "    p1 = Popen(\"/bin/bash\", stdin=subprocess.PIPE, stdout=subprocess.PIPE, encoding='utf8')\n",
    "    p2 = Popen(\"/bin/bash\", stdin=subprocess.PIPE, stdout=subprocess.PIPE, encoding='utf8')\n",
    "\n",
    "    out,err = p1.communicate(f\"docker run --name {name} -p 8080:8080 {name}\")\n",
    "    print(out)\n",
    "    print(err)\n",
    "    time.sleep(5)\n",
    "    out,err = p2.communicate(f\"conda activate {testenv} ; python ../../../emely-testing/main.py\")\n",
    "    print(err)\n",
    "    print(out)\n",
    "    while p2.poll() is not None:\n",
    "        out = p2.stdout\n",
    "        #print(out)\n",
    "    print(out)\n",
    "\n",
    "    p2.kill()\n",
    "    p1.kill()\n",
    "    # p2 = Popen(\"python ../../../emely-testing/main.py\")\n",
    "\n",
    "    # while True:\n",
    "    #     if p2.poll() is None:\n",
    "    #         break\n",
    "\n",
    "    print(os.system(f\"docker stop {name}\"))\n",
    "    print(os.system(f\"docker rm {name}\"))\n",
    "    # tested_names.append(name)\n",
    "    #except:\n",
    "    #    print(f\"Error testing model {name}\")\n",
    "\n",
    "#docker run --name blender-minimal-1-model_1  -p 8080:8080 blender-minimal-1-model_1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Final clean-up"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "print(f\"Successfully trained, dockerized and tested models:\")\n",
    "for name in tested_names:\n",
    "    print(f\"{name}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully trained, dockerized and tested models:\n",
      "skej\n",
      "skej\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "for i in range(len(model_names)):\n",
    "    os.system(f\"rm temp_opts/model_{str(i+1)}_opts.json\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# --- End of pipeline ---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Some utils to change the default files used in this notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "default_blender_opts = {\n",
    "    \"activation\": \"gelu\",\n",
    "    \"attention_dropout\": 0.0,\n",
    "    \"dict_lower\": True,\n",
    "    \"dict_tokenizer\": \"bpe\",\n",
    "    \"embedding_size\": 512,\n",
    "    \"evaltask\": \"internal,external\",\n",
    "    \"ffn_size\": 2048,\n",
    "    \"fp16\": True,\n",
    "    \"gradient_clip\": 0.1,\n",
    "    \"label_truncate\": 128,\n",
    "    \"learn_positional_embeddings\": True,\n",
    "    \"lr_scheduler\": \"reduceonplateau\",\n",
    "    \"metrics\": \"ppl,bleu-4,rouge-L\",\n",
    "    \"model\": \"transformer/generator\",\n",
    "    \"n_heads\": 16,\n",
    "    \"n_layers\": 8,\n",
    "    \"n_positions\": 512,\n",
    "    \"optimizer\": \"adamax\",\n",
    "    \"relu_dropout\": 0.0,\n",
    "    \"save_after_valid\": True,\n",
    "    \"skip_generation\": False,\n",
    "    \"stim\": 60,\n",
    "    \"tensorboard_log\": True,\n",
    "    \"text_truncate\": 512,\n",
    "    \"update_freq\": 1,\n",
    "    \"variant\": \"xlm\",\n",
    "    \"veps\": 0.25,\n",
    "    \"vme\": 20000,\n",
    "    \"vmm\": \"min\",\n",
    "    \"vmt\": \"ppl\",\n",
    "    \"vp\": 15,\n",
    "    \"wblog\": True\n",
    "}\n",
    "run_blender_opts = {\n",
    "    'init_model': 'zoo:blender/blender_90M/model',\n",
    "    'dict_file': 'zoo:blender/blender_90M/model.dict',\n",
    "    'bs': 16,\n",
    "    'betas': '0.9,0.999',\n",
    "    'lr': 1e-06,\n",
    "    'dropout': 0.1,\n",
    "    'inference': 'beam',\n",
    "    'beam_size': 10,\n",
    "    'beam_min_length': 10,\n",
    "    'beam_block_ngram': 3,\n",
    "    'wandb_project': 'parlaiemely',\n",
    "    'task': 'internal,external,external-gpt3',\n",
    "    'multitask_weights': '6,3,3',\n",
    "    'mutators': None\n",
    "}\n",
    "\n",
    "with open(\"temp_opts/default_blender_opts.json\",\"w\") as file:\n",
    "    json.dump(default_blender_opts,file, sort_keys=True, indent=4)\n",
    "with open(\"temp_opts/run_blender_opts.json\",\"w\") as file:\n",
    "    json.dump(run_blender_opts,file, sort_keys=False, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('emelymodels': conda)"
  },
  "interpreter": {
   "hash": "f8da2b72f9ac3c32718e899b9529d2abac5ccc10881893810be77cced976bf1a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}